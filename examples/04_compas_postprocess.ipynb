{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "from aif360.datasets import BinaryLabelDataset,CompasDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# TODO: change the import method\n",
    "import sys\n",
    "import os\n",
    "repo_root = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, repo_root)\n",
    "repair_folder = os.path.join(repo_root, \"humancompatible\", \"repair\")\n",
    "sys.path.insert(0, repair_folder)\n",
    "from humancompatible.repair.cost import *\n",
    "from humancompatible.repair.coupling_utils import *\n",
    "from humancompatible.repair.data_analysis import *\n",
    "from humancompatible.repair.group_blind_repair import *\n",
    "from humancompatible.repair.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path=os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROCpostprocess:\n",
    "    def __init__(self,X_val,y_val,var_list,prediction_model,favorable_label):\n",
    "        self.X_val =X_val\n",
    "        self.y_val =y_val\n",
    "        self.model = prediction_model\n",
    "        self.positive_index = 1 # positive label\n",
    "        self.var_list = var_list\n",
    "        self.var_dim=len(self.var_list)\n",
    "        self.ROC = self.buildROCusingval()\n",
    "        self.favorable_label = favorable_label\n",
    "\n",
    "    def buildbinarydata(self,X,y):\n",
    "        df=pd.DataFrame(np.concatenate((X,y.reshape(-1,1)), axis=1),columns=self.var_list+['S','W','Y'])\n",
    "        binaryLabelDataset = BinaryLabelDataset(\n",
    "                            # favorable_label=self.favorable_label,\n",
    "                            # unfavorable_label=0,\n",
    "                            df=df[self.var_list+['S','W','Y']], #df_test.drop('X',axis=1), #[x_list+['S','W','Y']],\n",
    "                            label_names=['Y'],\n",
    "                            instance_weights_name=['W'],\n",
    "                            protected_attribute_names=['S'],\n",
    "                            privileged_protected_attributes=[np.array([1.0])],\n",
    "                            unprivileged_protected_attributes=[np.array([0.])])\n",
    "        return binaryLabelDataset,df\n",
    "\n",
    "    def buildROCusingval(self):\n",
    "        dataset_val = self.buildbinarydata(self.X_val,self.y_val)[0]\n",
    "        dataset_val_pred = dataset_val.copy(deepcopy=True)\n",
    "        dataset_val_pred.scores = self.model.predict_proba(dataset_val.features[:,0:self.var_dim])[:,self.positive_index].reshape(-1,1)\n",
    "        privileged_groups = [{'S': 1}]\n",
    "        unprivileged_groups = [{'S': 0}]\n",
    "        # Metric used (should be one of allowed_metrics)\n",
    "        metric_name = \"Statistical parity difference\"\n",
    "        # Upper and lower bound on the fairness metric used\n",
    "        metric_ub = 0.05\n",
    "        metric_lb = -0.05\n",
    "        ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                        privileged_groups=privileged_groups, \n",
    "                                        low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                        num_class_thresh=50, num_ROC_margin=10,\n",
    "                                        metric_name=metric_name,\n",
    "                                        metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "        ROC = ROC.fit(dataset_val, dataset_val_pred)\n",
    "        print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "        print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)\n",
    "        return ROC\n",
    "\n",
    "    def postprocess(self,X_test,y_test,tv_origin): # the tv distance won't change\n",
    "        dataset_test_pred,df_test = self.buildbinarydata(X_test,y_test) #.copy(deepcopy=True)\n",
    "        dataset_test_pred.scores = self.model.predict_proba(X_test[:,0:self.var_dim])[:,self.positive_index].reshape(-1,1)\n",
    "        dataset_test_pred_transf = self.ROC.predict(dataset_test_pred)\n",
    "        y_pred = dataset_test_pred_transf.labels\n",
    "        # return dataset_test_pred_transf.convert_to_dataframe()[0]\n",
    "\n",
    "        di = DisparateImpact_postprocess(df_test,y_pred,favorable_label=self.favorable_label)\n",
    "        f1_macro = f1_score(df_test['Y'], y_pred, average='macro',sample_weight=df_test['W'])\n",
    "        f1_micro = f1_score(df_test['Y'], y_pred, average='micro',sample_weight=df_test['W'])\n",
    "        f1_weighted = f1_score(df_test['Y'], y_pred, average='weighted',sample_weight=df_test['W'])\n",
    "        new_row=pd.Series({'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,\n",
    "                           'TV distance':tv_origin,'method':'ROC'})\n",
    "        return new_row.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projpostprocess:\n",
    "    \n",
    "    def __init__(self,X_test,y_test,x_list,var_list,prediction_model,K,e,thresh,favorable_label=1):\n",
    "        self.model = prediction_model\n",
    "        self.K=K\n",
    "        self.e=e\n",
    "        self.x_list=x_list\n",
    "        self.var_list=var_list\n",
    "        self.var_dim=len(var_list)\n",
    "        self.favorable_label = favorable_label\n",
    "\n",
    "        df_test=pd.DataFrame(np.concatenate((X_test,y_test.reshape(-1,1)), axis=1),columns=var_list+['S','W','Y'])\n",
    "        df_test=df_test.groupby(by=var_list+['S','Y'],as_index=False).sum()\n",
    "        if len(x_list)>1:\n",
    "            df_test['X'] = list(zip(*[df_test[c] for c in x_list]))\n",
    "            self.x_range=sorted(set(df_test['X']))\n",
    "            weight=list(1/(df_test[x_list].max()-df_test[x_list].min())) # because 'education-num' range from 1 to 16 while others 1 to 4\n",
    "            self.C=c_generate_higher(self.x_range,weight)\n",
    "        else:\n",
    "            df_test['X']=df_test[x_list]\n",
    "            self.x_range=sorted(set(df_test['X']))\n",
    "            self.C=c_generate(self.x_range)\n",
    "        self.df_test = df_test\n",
    "        self.var_range=list(pd.pivot_table(df_test,index=var_list,values=['S','W','Y']).index)\n",
    "        self.distribution_generator()\n",
    "        \n",
    "        if thresh == 'auto':\n",
    "            self.thresh_generator()\n",
    "        else:\n",
    "            self.thresh=thresh\n",
    "\n",
    "    def distribution_generator(self):\n",
    "        bin=len(self.x_range)\n",
    "        dist=rdata_analysis(self.df_test,self.x_range,'X')\n",
    "        \n",
    "        dist['v']=[(dist['x_0'][i]-dist['x_1'][i])/dist['x'][i] for i in range(bin)]\n",
    "        \n",
    "        dist['t_x']=dist['x'] # #dist['x'] #dist['x_0']*0.5+dist['x_1']*0.5 \n",
    "        self.px=np.matrix(dist['x']).T\n",
    "        self.ptx=np.matrix(dist['t_x']).T\n",
    "        if np.any(dist['x_0']==0): \n",
    "            self.p0=np.matrix((dist['x_0']+1.0e-9)/sum(dist['x_0']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p0=np.matrix(dist['x_0']).T \n",
    "        if np.any(dist['x_1']==0):\n",
    "            self.p1=np.matrix((dist['x_1']+1.0e-9)/sum(dist['x_1']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p1=np.matrix(dist['x_1']).T \n",
    "        self.V=np.matrix(dist['v']).T\n",
    "        self.tv_origin=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "        # return px,ptx,V,p0,p1\n",
    "    \n",
    "    def _run_method(self, method, C, eps, px, ptx, K, V=None, theta=None):\n",
    "        group_blind = GroupBlindRepair(C, px, ptx, V=V, epsilon=eps, K=K)\n",
    "        if method == \"baseline\":\n",
    "            group_blind.fit_baseline()\n",
    "        elif method == \"partial_repair\":\n",
    "            group_blind.fit_partial(theta)\n",
    "        elif method == \"total_repair\":\n",
    "            group_blind.fit_total()\n",
    "        return group_blind.coupling_matrix()\n",
    "\n",
    "    def coupling_generator(self,method,para=None):\n",
    "        if method == 'unconstrained':\n",
    "            coupling=self._run_method(method=\"baseline\", C=self.C, eps=self.e, px=self.px, ptx=self.ptx, K=self.K)\n",
    "        elif method == 'barycentre':\n",
    "            coupling=self._run_method(method=\"baseline\", C=self.C, eps=self.e, px=self.p0, ptx=self.p1, K=self.K)\n",
    "        elif method == 'partial':\n",
    "            coupling=self._run_method(method=\"partial_repair\", C=self.C, eps=self.e, px=self.px, ptx=self.ptx, V=self.V, theta=para, K=self.K)\n",
    "        return coupling\n",
    "\n",
    "    def postprocess(self,method,para=None):\n",
    "        if method == 'origin':\n",
    "            y_pred=self.model.predict(np.array(self.df_test[self.var_list]))\n",
    "            tv = self.tv_origin\n",
    "        else:\n",
    "            coupling = self.coupling_generator(method,para)\n",
    "            if (method == 'unconstrained') or (method == 'partial'):\n",
    "                y_pred=postprocess(self.df_test,coupling,self.x_list,self.x_range,self.var_list,self.var_range,self.model,self.thresh)\n",
    "                tv=assess_tv(self.df_test,coupling,self.x_range,self.x_list,self.var_list)\n",
    "                if (para != None) and (method == 'partial'):\n",
    "                    method = method+'_'+str(para)\n",
    "            elif method == 'barycentre':\n",
    "                y_pred,tv=postprocess_bary(self.df_test,coupling,self.x_list,self.x_range,self.var_list,self.var_range,self.model,self.thresh)\n",
    "            else:\n",
    "                print('Unknown method')\n",
    "\n",
    "        di = DisparateImpact_postprocess(self.df_test,y_pred,favorable_label=self.favorable_label)\n",
    "        f1_macro = f1_score(self.df_test['Y'], y_pred, average='macro',sample_weight=self.df_test['W'])\n",
    "        f1_micro = f1_score(self.df_test['Y'], y_pred, average='micro',sample_weight=self.df_test['W'])\n",
    "        f1_weighted = f1_score(self.df_test['Y'], y_pred, average='weighted',sample_weight=self.df_test['W'])\n",
    "\n",
    "        new_row=pd.Series({'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,\n",
    "                           'TV distance':tv,'method':method})\n",
    "        return new_row.to_frame().T\n",
    "    \n",
    "    def thresh_generator(self):\n",
    "        num_thresh = 10\n",
    "        ba_arr = np.zeros(num_thresh)\n",
    "        ba_arr1 = np.zeros(num_thresh)\n",
    "        class_thresh_arr = np.linspace(0.01, 0.1, num_thresh)\n",
    "        coupling=self.coupling_generator('partial',para=1e-2)\n",
    "    \n",
    "        for idx, thresh in enumerate(class_thresh_arr):\n",
    "            y_pred=postprocess(self.df_test,coupling,self.x_list,self.x_range,self.var_list,self.var_range,self.model,thresh)\n",
    "            ba_arr[idx] = DisparateImpact_postprocess(self.df_test,y_pred,favorable_label=self.favorable_label)\n",
    "            ba_arr1[idx] = f1_score(self.df_test['Y'], y_pred, average='macro',sample_weight=self.df_test['W'])\n",
    "\n",
    "        best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "        best_thresh = class_thresh_arr[best_ind]\n",
    "        print(\"Optional threshold = \",class_thresh_arr)\n",
    "        print(\"Disparate Impact = \",ba_arr)\n",
    "        print(\"f1 scores = \",ba_arr1)\n",
    "        self.thresh = best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'juv_fel_count': np.float64(0.03210337325453563),\n",
       " 'juv_misd_count': np.float64(0.04323143324022939),\n",
       " 'juv_other_count': np.float64(0.021763780679615215),\n",
       " 'priors_count': np.float64(0.12622233191661625),\n",
       " 'age_cat=25 - 45': np.float64(0.054431947619680315),\n",
       " 'age_cat=Greater than 45': np.float64(0.13519019921101838),\n",
       " 'age_cat=Less than 25': np.float64(0.08075825159133806),\n",
       " 'c_charge_degree=F': np.float64(0.07840757396162046),\n",
       " 'c_charge_degree=M': np.float64(0.07840757396162046)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa = 'race'\n",
    "label_map = {1.0: 'Did recid.', 0.0: 'No recid.'}\n",
    "protected_attribute_maps = {1.0: 'Caucasian', 0.0: 'African-American'}\n",
    "favorable_label = 0\n",
    "privileged_groups = [{pa: 1}]\n",
    "unprivileged_groups = [{pa: 0}]\n",
    "cd = CompasDataset(protected_attribute_names=[pa],privileged_classes=[['Caucasian'],[1]], \n",
    "                    metadata={'label_map': label_map,'protected_attribute_maps': protected_attribute_maps},\n",
    "                    features_to_drop=['age', 'sex', 'c_charge_desc'])\n",
    "train,test = cd.split([0.6], shuffle=True) #len(test.instance_names) = 2057\n",
    "var_list = cd.feature_names.copy()\n",
    "var_list.remove(pa)\n",
    "var_dim=len(var_list)\n",
    "\n",
    "K=200\n",
    "e=0.01\n",
    "thresh=0.05\n",
    "\n",
    "messydata=cd.convert_to_dataframe()[0]\n",
    "messydata=messydata.rename(columns={pa:'S',cd.label_names[0]:'Y'})\n",
    "messydata=messydata[(messydata['S']==1)|(messydata['S']==0)]\n",
    "for col in var_list+['S','Y']:\n",
    "    messydata[col]=messydata[col].astype('category')\n",
    "messydata['W']=cd.instance_weights\n",
    "X=messydata[var_list+['S','W']].to_numpy() # [X,S,W]\n",
    "y=messydata['Y'].to_numpy() #[Y]\n",
    "tv_dist=dict()\n",
    "for x_name in var_list:\n",
    "    x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "    dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "    tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "x_list=[]\n",
    "for key,val in tv_dist.items():\n",
    "    if val>0.1:\n",
    "        x_list+=[key]        \n",
    "tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['priors_count', 'age_cat=Greater than 45']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraints) = 0.2100\n",
      "Optimal ROC margin = 0.0000\n",
      "Optimal classification threshold (with fairness constraints) = 0.7300\n",
      "Optimal ROC margin = 0.0000\n",
      "Optimal classification threshold (with fairness constraints) = 0.7100\n",
      "Optimal ROC margin = 0.0000\n",
      "Optimal classification threshold (with fairness constraints) = 0.6900\n",
      "Optimal ROC margin = 0.0000\n",
      "Optimal classification threshold (with fairness constraints) = 0.7500\n",
      "Optimal ROC margin = 0.0000\n",
      "Optimal classification threshold (with fairness constraints) = 0.7300\n",
      "Optimal ROC margin = 0.0000\n",
      "Optimal classification threshold (with fairness constraints) = 0.7500\n",
      "Optimal ROC margin = 0.0000\n",
      "Optimal classification threshold (with fairness constraints) = 0.7500\n",
      "Optimal ROC margin = 0.0000\n",
      "Optimal classification threshold (with fairness constraints) = 0.7500\n",
      "Optimal ROC margin = 0.0000\n",
      "Optimal classification threshold (with fairness constraints) = 0.7500\n",
      "Optimal ROC margin = 0.0000\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','unconstrained','barycentre','partial','ROC'] # Place ROC in the end\n",
    "report=pd.DataFrame(columns=['DI','f1 macro','f1 micro','f1 weighted','TV distance','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "    clf=RandomForestClassifier(max_depth=5).fit(X_train[:,0:var_dim],y_train)\n",
    "    projpost = Projpostprocess(X_test,y_test,x_list,var_list,clf,K,e,thresh,favorable_label)\n",
    "    for method in methods[:-1]:\n",
    "        # report = pd.concat([report,projpost.postprocess(method,para=1e-2)], ignore_index=True)\n",
    "        report = pd.concat([report,projpost.postprocess(method,para=1e-3)], ignore_index=True)\n",
    "\n",
    "    ROCpost = ROCpostprocess(X_val,y_val,var_list,clf,favorable_label) # use validation set to train a ROC model\n",
    "    report = pd.concat([report,ROCpost.postprocess(X_test,y_test,tv_origin=projpost.tv_origin)], ignore_index=True)\n",
    "\n",
    "report.to_csv(path+'/data/report_postprocess_compas_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report.to_csv(path+'/data/report_postprocess_compas_'+str(pa)+'_'+str(thresh)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>TV distance</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.791576</td>\n",
       "      <td>0.660325</td>\n",
       "      <td>0.668287</td>\n",
       "      <td>0.666665</td>\n",
       "      <td>0.16428</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786599</td>\n",
       "      <td>0.662478</td>\n",
       "      <td>0.668692</td>\n",
       "      <td>0.668061</td>\n",
       "      <td>0.159199</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.216749</td>\n",
       "      <td>0.613693</td>\n",
       "      <td>0.614419</td>\n",
       "      <td>0.615734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.012246</td>\n",
       "      <td>0.542354</td>\n",
       "      <td>0.549615</td>\n",
       "      <td>0.535326</td>\n",
       "      <td>0.022066</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.414232</td>\n",
       "      <td>0.417377</td>\n",
       "      <td>0.492912</td>\n",
       "      <td>0.391802</td>\n",
       "      <td>0.16428</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.747492</td>\n",
       "      <td>0.666596</td>\n",
       "      <td>0.672337</td>\n",
       "      <td>0.671185</td>\n",
       "      <td>0.184545</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.747492</td>\n",
       "      <td>0.666596</td>\n",
       "      <td>0.672337</td>\n",
       "      <td>0.671185</td>\n",
       "      <td>0.18035</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.157182</td>\n",
       "      <td>0.616202</td>\n",
       "      <td>0.616444</td>\n",
       "      <td>0.617213</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.880941</td>\n",
       "      <td>0.563112</td>\n",
       "      <td>0.571891</td>\n",
       "      <td>0.556615</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.96276</td>\n",
       "      <td>0.424195</td>\n",
       "      <td>0.573917</td>\n",
       "      <td>0.454995</td>\n",
       "      <td>0.184545</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.792444</td>\n",
       "      <td>0.655671</td>\n",
       "      <td>0.666262</td>\n",
       "      <td>0.663376</td>\n",
       "      <td>0.181719</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.748714</td>\n",
       "      <td>0.655621</td>\n",
       "      <td>0.657351</td>\n",
       "      <td>0.658735</td>\n",
       "      <td>0.177104</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.230354</td>\n",
       "      <td>0.614093</td>\n",
       "      <td>0.615634</td>\n",
       "      <td>0.617204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.055424</td>\n",
       "      <td>0.566496</td>\n",
       "      <td>0.567436</td>\n",
       "      <td>0.56392</td>\n",
       "      <td>0.021305</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.966396</td>\n",
       "      <td>0.460891</td>\n",
       "      <td>0.592953</td>\n",
       "      <td>0.494933</td>\n",
       "      <td>0.181719</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.787158</td>\n",
       "      <td>0.667723</td>\n",
       "      <td>0.674362</td>\n",
       "      <td>0.671471</td>\n",
       "      <td>0.156148</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.78581</td>\n",
       "      <td>0.667877</td>\n",
       "      <td>0.674362</td>\n",
       "      <td>0.67158</td>\n",
       "      <td>0.152514</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.16148</td>\n",
       "      <td>0.621518</td>\n",
       "      <td>0.622114</td>\n",
       "      <td>0.622717</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.002238</td>\n",
       "      <td>0.581261</td>\n",
       "      <td>0.582827</td>\n",
       "      <td>0.579217</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.930342</td>\n",
       "      <td>0.496536</td>\n",
       "      <td>0.595383</td>\n",
       "      <td>0.514336</td>\n",
       "      <td>0.156148</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.821177</td>\n",
       "      <td>0.657411</td>\n",
       "      <td>0.669097</td>\n",
       "      <td>0.662408</td>\n",
       "      <td>0.166808</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.815292</td>\n",
       "      <td>0.662249</td>\n",
       "      <td>0.668692</td>\n",
       "      <td>0.665933</td>\n",
       "      <td>0.16176</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.22943</td>\n",
       "      <td>0.614191</td>\n",
       "      <td>0.617254</td>\n",
       "      <td>0.616906</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.010093</td>\n",
       "      <td>0.577222</td>\n",
       "      <td>0.577562</td>\n",
       "      <td>0.576275</td>\n",
       "      <td>0.020344</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.983281</td>\n",
       "      <td>0.423257</td>\n",
       "      <td>0.566626</td>\n",
       "      <td>0.445968</td>\n",
       "      <td>0.166808</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.773963</td>\n",
       "      <td>0.663508</td>\n",
       "      <td>0.672742</td>\n",
       "      <td>0.668769</td>\n",
       "      <td>0.159243</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.773824</td>\n",
       "      <td>0.664987</td>\n",
       "      <td>0.673957</td>\n",
       "      <td>0.67016</td>\n",
       "      <td>0.156856</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.130926</td>\n",
       "      <td>0.615333</td>\n",
       "      <td>0.616849</td>\n",
       "      <td>0.617612</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.003528</td>\n",
       "      <td>0.582777</td>\n",
       "      <td>0.582827</td>\n",
       "      <td>0.582347</td>\n",
       "      <td>0.021128</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.943737</td>\n",
       "      <td>0.454583</td>\n",
       "      <td>0.583637</td>\n",
       "      <td>0.47962</td>\n",
       "      <td>0.159243</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.749559</td>\n",
       "      <td>0.661834</td>\n",
       "      <td>0.671527</td>\n",
       "      <td>0.668443</td>\n",
       "      <td>0.195068</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.664953</td>\n",
       "      <td>0.661208</td>\n",
       "      <td>0.661401</td>\n",
       "      <td>0.662142</td>\n",
       "      <td>0.187357</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.231022</td>\n",
       "      <td>0.616407</td>\n",
       "      <td>0.617254</td>\n",
       "      <td>0.618488</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.837118</td>\n",
       "      <td>0.554788</td>\n",
       "      <td>0.561361</td>\n",
       "      <td>0.548543</td>\n",
       "      <td>0.020564</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.969034</td>\n",
       "      <td>0.427632</td>\n",
       "      <td>0.583637</td>\n",
       "      <td>0.462125</td>\n",
       "      <td>0.195068</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.792685</td>\n",
       "      <td>0.649821</td>\n",
       "      <td>0.660591</td>\n",
       "      <td>0.655119</td>\n",
       "      <td>0.191316</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.77801</td>\n",
       "      <td>0.662253</td>\n",
       "      <td>0.668287</td>\n",
       "      <td>0.666148</td>\n",
       "      <td>0.185667</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.157098</td>\n",
       "      <td>0.600101</td>\n",
       "      <td>0.602673</td>\n",
       "      <td>0.602868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.869221</td>\n",
       "      <td>0.569687</td>\n",
       "      <td>0.577562</td>\n",
       "      <td>0.564665</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.959102</td>\n",
       "      <td>0.442667</td>\n",
       "      <td>0.574322</td>\n",
       "      <td>0.466036</td>\n",
       "      <td>0.191316</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.792738</td>\n",
       "      <td>0.669768</td>\n",
       "      <td>0.678007</td>\n",
       "      <td>0.674014</td>\n",
       "      <td>0.1734</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.73634</td>\n",
       "      <td>0.68127</td>\n",
       "      <td>0.682463</td>\n",
       "      <td>0.682857</td>\n",
       "      <td>0.16784</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.193175</td>\n",
       "      <td>0.622361</td>\n",
       "      <td>0.623329</td>\n",
       "      <td>0.623918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.885095</td>\n",
       "      <td>0.625484</td>\n",
       "      <td>0.625759</td>\n",
       "      <td>0.624656</td>\n",
       "      <td>0.020555</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.970555</td>\n",
       "      <td>0.426029</td>\n",
       "      <td>0.568246</td>\n",
       "      <td>0.449289</td>\n",
       "      <td>0.1734</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.8048</td>\n",
       "      <td>0.66312</td>\n",
       "      <td>0.675172</td>\n",
       "      <td>0.669288</td>\n",
       "      <td>0.193543</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.801143</td>\n",
       "      <td>0.675151</td>\n",
       "      <td>0.682058</td>\n",
       "      <td>0.679736</td>\n",
       "      <td>0.180557</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.191015</td>\n",
       "      <td>0.621342</td>\n",
       "      <td>0.624949</td>\n",
       "      <td>0.624919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.921393</td>\n",
       "      <td>0.59436</td>\n",
       "      <td>0.595383</td>\n",
       "      <td>0.592388</td>\n",
       "      <td>0.020842</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.961688</td>\n",
       "      <td>0.427203</td>\n",
       "      <td>0.574727</td>\n",
       "      <td>0.455342</td>\n",
       "      <td>0.193543</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DI  f1 macro  f1 micro f1 weighted TV distance         method\n",
       "0   0.791576  0.660325  0.668287    0.666665     0.16428         origin\n",
       "1   0.786599  0.662478  0.668692    0.668061    0.159199  unconstrained\n",
       "2   1.216749  0.613693  0.614419    0.615734         0.0     barycentre\n",
       "3   1.012246  0.542354  0.549615    0.535326    0.022066  partial_0.001\n",
       "4   0.414232  0.417377  0.492912    0.391802     0.16428            ROC\n",
       "5   0.747492  0.666596  0.672337    0.671185    0.184545         origin\n",
       "6   0.747492  0.666596  0.672337    0.671185     0.18035  unconstrained\n",
       "7   1.157182  0.616202  0.616444    0.617213    0.000005     barycentre\n",
       "8   0.880941  0.563112  0.571891    0.556615    0.018298  partial_0.001\n",
       "9    0.96276  0.424195  0.573917    0.454995    0.184545            ROC\n",
       "10  0.792444  0.655671  0.666262    0.663376    0.181719         origin\n",
       "11  0.748714  0.655621  0.657351    0.658735    0.177104  unconstrained\n",
       "12  1.230354  0.614093  0.615634    0.617204         0.0     barycentre\n",
       "13  1.055424  0.566496  0.567436     0.56392    0.021305  partial_0.001\n",
       "14  0.966396  0.460891  0.592953    0.494933    0.181719            ROC\n",
       "15  0.787158  0.667723  0.674362    0.671471    0.156148         origin\n",
       "16   0.78581  0.667877  0.674362     0.67158    0.152514  unconstrained\n",
       "17   1.16148  0.621518  0.622114    0.622717    0.000174     barycentre\n",
       "18  1.002238  0.581261  0.582827    0.579217    0.021636  partial_0.001\n",
       "19  0.930342  0.496536  0.595383    0.514336    0.156148            ROC\n",
       "20  0.821177  0.657411  0.669097    0.662408    0.166808         origin\n",
       "21  0.815292  0.662249  0.668692    0.665933     0.16176  unconstrained\n",
       "22   1.22943  0.614191  0.617254    0.616906    0.000003     barycentre\n",
       "23  1.010093  0.577222  0.577562    0.576275    0.020344  partial_0.001\n",
       "24  0.983281  0.423257  0.566626    0.445968    0.166808            ROC\n",
       "25  0.773963  0.663508  0.672742    0.668769    0.159243         origin\n",
       "26  0.773824  0.664987  0.673957     0.67016    0.156856  unconstrained\n",
       "27  1.130926  0.615333  0.616849    0.617612    0.000486     barycentre\n",
       "28  1.003528  0.582777  0.582827    0.582347    0.021128  partial_0.001\n",
       "29  0.943737  0.454583  0.583637     0.47962    0.159243            ROC\n",
       "30  0.749559  0.661834  0.671527    0.668443    0.195068         origin\n",
       "31  0.664953  0.661208  0.661401    0.662142    0.187357  unconstrained\n",
       "32  1.231022  0.616407  0.617254    0.618488    0.000083     barycentre\n",
       "33  0.837118  0.554788  0.561361    0.548543    0.020564  partial_0.001\n",
       "34  0.969034  0.427632  0.583637    0.462125    0.195068            ROC\n",
       "35  0.792685  0.649821  0.660591    0.655119    0.191316         origin\n",
       "36   0.77801  0.662253  0.668287    0.666148    0.185667  unconstrained\n",
       "37  1.157098  0.600101  0.602673    0.602868         0.0     barycentre\n",
       "38  0.869221  0.569687  0.577562    0.564665    0.021049  partial_0.001\n",
       "39  0.959102  0.442667  0.574322    0.466036    0.191316            ROC\n",
       "40  0.792738  0.669768  0.678007    0.674014      0.1734         origin\n",
       "41   0.73634   0.68127  0.682463    0.682857     0.16784  unconstrained\n",
       "42  1.193175  0.622361  0.623329    0.623918         0.0     barycentre\n",
       "43  0.885095  0.625484  0.625759    0.624656    0.020555  partial_0.001\n",
       "44  0.970555  0.426029  0.568246    0.449289      0.1734            ROC\n",
       "45    0.8048   0.66312  0.675172    0.669288    0.193543         origin\n",
       "46  0.801143  0.675151  0.682058    0.679736    0.180557  unconstrained\n",
       "47  1.191015  0.621342  0.624949    0.624919         0.0     barycentre\n",
       "48  0.921393   0.59436  0.595383    0.592388    0.020842  partial_0.001\n",
       "49  0.961688  0.427203  0.574727    0.455342    0.193543            ROC"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optional threshold =  [0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1 ]\n",
      "Disparate Impact =  [1.05363777 1.07318267 1.03479367 1.04258146 1.04289114 1.04289114\n",
      " 1.04289114 1.04289114 1.04289114 1.04621951]\n",
      "f1 scores =  [0.5881506  0.58919195 0.60817515 0.61282296 0.61289073 0.61289073\n",
      " 0.61289073 0.61289073 0.61289073 0.61296098]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.020000000000000004)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valpost = Projpostprocess(X_val,y_val,x_list,var_list,clf,K,e,'auto')\n",
    "valpost.thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features ['juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'age_cat=25 - 45', 'age_cat=Greater than 45', 'age_cat=Less than 25', 'c_charge_degree=F', 'c_charge_degree=M']\n",
      "mean importances [0.03015438 0.05415397 0.09178521 0.58346986 0.03201751 0.07224923\n",
      " 0.0813919  0.02814602 0.02663192]\n"
     ]
    }
   ],
   "source": [
    "# Compute average feature importance\n",
    "importance=[]\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "    clf=RandomForestClassifier(max_depth=5).fit(X_train[:,0:var_dim],y_train)\n",
    "    importance.append(list(clf.feature_importances_))\n",
    "importance=np.array(importance)\n",
    "print(\"features\", var_list)\n",
    "print(\"mean importances\", importance.mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
