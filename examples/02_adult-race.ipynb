{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness Post-Processing on the Adult Income Dataset\n",
    "\n",
    "In this notebook we compare several post-processing techniques on the well-known \"Adult\" dataset to  \n",
    "reduce demographic disparities in a binary income prediction task. \n",
    "\n",
    "We’ll walk through:  \n",
    "\n",
    "1. Imports & configuration\n",
    "\n",
    "2. Utility functions (data loading, feature selection)\n",
    "\n",
    "3. Training / post‑processing loop\n",
    "\n",
    "4. Result summary & feature importance\n",
    "\n",
    "5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1  Imports & basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "from aif360.datasets import BinaryLabelDataset, AdultDataset\n",
    "\n",
    "from humancompatible.repair.methods.data_analysis import rdata_analysis\n",
    "from humancompatible.repair.postprocess.roc_postprocess import ROCpostprocess\n",
    "from humancompatible.repair.postprocess.proj_postprocess import Projpostprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve turned off FutureWarning noise so we can focus on the core outputs. Next up, we’ll write a couple of utility functions to:\n",
    "\n",
    "1. **Load & clean** the Adult dataset (apply binning, encode labels).\n",
    "\n",
    "2. **Compute TV distances** to pick out the most imbalanced features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  Utility helpers\n",
    "\n",
    "Below are three helper functions:\n",
    "\n",
    "- **`load_data`**: merges train/test, binning continuous features, encodes sensitive (`S`) & target (`Y`).\n",
    "\n",
    "- **`categorise`**: assigns numeric bins for age, hours-per-week, capital gain/loss.\n",
    "\n",
    "- **`choose_x`**: measures total-variation distance for each feature to detect imbalance and returns a shortlist for repair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path,var_list,pa):\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education',\n",
    "                'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "                'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                'native-country', 'Y']\n",
    "    na_values=['?']\n",
    "    pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "    label_dict={'>50K.':1,'>50K':1,'<=50K.':0,'<=50K':0}\n",
    "    train_path = os.path.join(data_path, 'adult.data')\n",
    "    test_path = os.path.join(data_path, 'adult.test')\n",
    "    train = pd.read_csv(train_path, header=None,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    test = pd.read_csv(test_path, header=0,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    messydata = pd.concat([test, train], ignore_index=True)[var_list+[pa,'Y']]\n",
    "    messydata=messydata.rename(columns={pa:'S'})\n",
    "    messydata['S']=messydata['S'].replace(pa_dict)\n",
    "    messydata['Y']=messydata['Y'].replace(label_dict)\n",
    "    messydata=messydata[(messydata['S']==0)|(messydata['S']==1)]\n",
    "    for col in var_list+['S','Y']:\n",
    "        messydata[col]=messydata[col].astype('int64')\n",
    "    messydata['W']=1\n",
    "    bins_capitalgain=[100,3500,7500,10000]\n",
    "    bins_capitalloss=[100,1600,1900,2200]\n",
    "    bins_age=[26,36,46,56]\n",
    "    bins_hours=[21,36,46,61]\n",
    "\n",
    "    messydata=categerise(messydata,'age',bins_age)\n",
    "    messydata=categerise(messydata,'hours-per-week',bins_hours)\n",
    "    messydata=categerise(messydata,'capital-gain',bins_capitalgain)\n",
    "    messydata=categerise(messydata,'capital-loss',bins_capitalloss)\n",
    "    \n",
    "    return messydata\n",
    "\n",
    "def categerise(df,col,bins):\n",
    "    for i in range(len(bins)+1):\n",
    "        if i == 0:\n",
    "            df.loc[df[col] < bins[i], col] = i\n",
    "        elif i == len(bins):\n",
    "            df.loc[df[col] >= bins[i-1], col] = i\n",
    "        else:\n",
    "            df.loc[(df[col] >= bins[i-1])& (df[col] < bins[i]), col] = i        \n",
    "    return df\n",
    "\n",
    "def choose_x(var_list,messydata):\n",
    "    tv_dist=dict()\n",
    "    for x_name in var_list:\n",
    "        x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "        dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "        tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    x_list=[]\n",
    "    for key,val in tv_dist.items():\n",
    "        if val>0.1:\n",
    "            x_list+=[key]  \n",
    "    return x_list,tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='..//data//adult'\n",
    "var_list=['hours-per-week','age','capital-gain','capital-loss','education-num'] #\n",
    "pa='race'\n",
    "favorable_label = 1\n",
    "var_dim=len(var_list)\n",
    "\n",
    "K=200\n",
    "e=0.01\n",
    "\n",
    "if pa == 'sex':\n",
    "    thresh=0.05\n",
    "elif pa == 'race':\n",
    "    thresh=0.05\n",
    "\n",
    "messydata = load_data(data_path,var_list,pa)\n",
    "x_list,tv_dist = choose_x(var_list,messydata)\n",
    "\n",
    "X=messydata[var_list+['S','W']].to_numpy() # [X,S,W]\n",
    "y=messydata['Y'].to_numpy() #[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hours-per-week': np.float64(0.12216173195089294),\n",
       " 'age': np.float64(0.04149230147335384),\n",
       " 'capital-gain': np.float64(0.026764553949230142),\n",
       " 'capital-loss': np.float64(0.014217783478743178),\n",
       " 'education-num': np.float64(0.11867963282506956)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see which features differ most across the sensitive groups:\n",
    "\n",
    "- **hours-per-week** and **education-num** stand out  \n",
    "\n",
    "- These will be the coordinates along which we apply our post-processing repairs\n",
    "\n",
    "With `X, y` ready, we now move on to the main experiment loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  Training & post‑processing experiment\n",
    "\n",
    "Here we’ll:\n",
    "\n",
    "1. Split data (train/val/test).  \n",
    "\n",
    "2. Fit a Random Forest baseline.  \n",
    "\n",
    "3. Apply four post-processing strategies:\n",
    "   - **origin** (no fairness correction)  \n",
    "   - **unconstrained** (repair without thresholding)  \n",
    "   - **barycentre** (optimal transport-based repair)  \n",
    "   - **partial** (partial coupling)  \n",
    "   - **ROC** (learn an ROC-based thresholding on the validation set)\n",
    "\n",
    "We repeat this 10x to smooth out randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraints) = 0.1900\n",
      "Optimal ROC margin = 0.0211\n",
      "Optimal classification threshold (with fairness constraints) = 0.1900\n",
      "Optimal ROC margin = 0.0211\n",
      "Optimal classification threshold (with fairness constraints) = 0.2500\n",
      "Optimal ROC margin = 0.0278\n",
      "Optimal classification threshold (with fairness constraints) = 0.2500\n",
      "Optimal ROC margin = 0.0278\n",
      "Optimal classification threshold (with fairness constraints) = 0.2300\n",
      "Optimal ROC margin = 0.0256\n",
      "Optimal classification threshold (with fairness constraints) = 0.1700\n",
      "Optimal ROC margin = 0.0189\n",
      "Optimal classification threshold (with fairness constraints) = 0.2500\n",
      "Optimal ROC margin = 0.0278\n",
      "Optimal classification threshold (with fairness constraints) = 0.1900\n",
      "Optimal ROC margin = 0.0211\n",
      "Optimal classification threshold (with fairness constraints) = 0.1900\n",
      "Optimal ROC margin = 0.0211\n",
      "Optimal classification threshold (with fairness constraints) = 0.1900\n",
      "Optimal ROC margin = 0.0211\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','unconstrained','barycentre','partial','ROC'] # Place ROC in the end\n",
    "report=pd.DataFrame(columns=['DI','f1 macro','f1 micro','f1 weighted','TV distance','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "    clf=RandomForestClassifier(max_depth=5).fit(X_train[:,0:var_dim],y_train)\n",
    "    projpost = Projpostprocess(X_test,y_test,x_list,var_list,clf,K,e,thresh,favorable_label,linspace_range=(0.01,0.1),theta=1e-2)\n",
    "    for method in methods[:-1]:\n",
    "        # report = pd.concat([report,projpost.postprocess(method,para=1e-2)], ignore_index=True)\n",
    "        report = pd.concat([report,projpost.postprocess(method,para=1e-3)], ignore_index=True)\n",
    "\n",
    "    ROCpost = ROCpostprocess(X_val,y_val,var_list,clf,favorable_label) # use validation set to train a ROC model\n",
    "    report = pd.concat([report,ROCpost.postprocess(X_test,y_test,tv_origin=projpost.tv_origin)], ignore_index=True)\n",
    "\n",
    "report.to_csv('../data/report_postprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logs above show, for each fold, the selected decision threshold and ROC margin needed to satisfy our fairness constraint. \n",
    "\n",
    "Lower margins indicate less aggressive adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s aggregate results across our folds.  In the table below:\n",
    "\n",
    "- **DI** (Disparate Impact): ratio of favourable outcomes  \n",
    "\n",
    "- **F1** (macro/micro/weighted): classification quality  \n",
    "\n",
    "- **TV distance**: remaining distribution gap on the repaired features  \n",
    "\n",
    "- **method**: which post-processor was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>TV distance</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.404169</td>\n",
       "      <td>0.684183</td>\n",
       "      <td>0.817321</td>\n",
       "      <td>0.790214</td>\n",
       "      <td>0.198494</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.404169</td>\n",
       "      <td>0.684183</td>\n",
       "      <td>0.817321</td>\n",
       "      <td>0.790214</td>\n",
       "      <td>0.198317</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.443225</td>\n",
       "      <td>0.67819</td>\n",
       "      <td>0.80957</td>\n",
       "      <td>0.784514</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.949082</td>\n",
       "      <td>0.634739</td>\n",
       "      <td>0.706012</td>\n",
       "      <td>0.71817</td>\n",
       "      <td>0.027697</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.050704</td>\n",
       "      <td>0.681661</td>\n",
       "      <td>0.718661</td>\n",
       "      <td>0.73778</td>\n",
       "      <td>0.198494</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.685506</td>\n",
       "      <td>0.81802</td>\n",
       "      <td>0.790891</td>\n",
       "      <td>0.179957</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.685506</td>\n",
       "      <td>0.81802</td>\n",
       "      <td>0.790891</td>\n",
       "      <td>0.179799</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.546003</td>\n",
       "      <td>0.68186</td>\n",
       "      <td>0.808978</td>\n",
       "      <td>0.785674</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.082815</td>\n",
       "      <td>0.620157</td>\n",
       "      <td>0.694655</td>\n",
       "      <td>0.706996</td>\n",
       "      <td>0.024951</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.904747</td>\n",
       "      <td>0.64546</td>\n",
       "      <td>0.66812</td>\n",
       "      <td>0.69173</td>\n",
       "      <td>0.179957</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.472211</td>\n",
       "      <td>0.689621</td>\n",
       "      <td>0.820119</td>\n",
       "      <td>0.79501</td>\n",
       "      <td>0.190227</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.472211</td>\n",
       "      <td>0.689621</td>\n",
       "      <td>0.820119</td>\n",
       "      <td>0.79501</td>\n",
       "      <td>0.190058</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.499855</td>\n",
       "      <td>0.686173</td>\n",
       "      <td>0.814791</td>\n",
       "      <td>0.791379</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.028549</td>\n",
       "      <td>0.63809</td>\n",
       "      <td>0.712794</td>\n",
       "      <td>0.724193</td>\n",
       "      <td>0.023464</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.986754</td>\n",
       "      <td>0.717138</td>\n",
       "      <td>0.776414</td>\n",
       "      <td>0.784945</td>\n",
       "      <td>0.190227</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.414965</td>\n",
       "      <td>0.686339</td>\n",
       "      <td>0.81802</td>\n",
       "      <td>0.792741</td>\n",
       "      <td>0.202326</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.414965</td>\n",
       "      <td>0.686339</td>\n",
       "      <td>0.81802</td>\n",
       "      <td>0.792741</td>\n",
       "      <td>0.202189</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.394881</td>\n",
       "      <td>0.683511</td>\n",
       "      <td>0.807632</td>\n",
       "      <td>0.787278</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.900939</td>\n",
       "      <td>0.639379</td>\n",
       "      <td>0.711664</td>\n",
       "      <td>0.723908</td>\n",
       "      <td>0.02605</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.909795</td>\n",
       "      <td>0.715092</td>\n",
       "      <td>0.77453</td>\n",
       "      <td>0.783223</td>\n",
       "      <td>0.202326</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.499933</td>\n",
       "      <td>0.690772</td>\n",
       "      <td>0.820873</td>\n",
       "      <td>0.795524</td>\n",
       "      <td>0.198238</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.499933</td>\n",
       "      <td>0.690772</td>\n",
       "      <td>0.820873</td>\n",
       "      <td>0.795524</td>\n",
       "      <td>0.198166</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.574749</td>\n",
       "      <td>0.68438</td>\n",
       "      <td>0.812799</td>\n",
       "      <td>0.789523</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.088008</td>\n",
       "      <td>0.617143</td>\n",
       "      <td>0.695516</td>\n",
       "      <td>0.707609</td>\n",
       "      <td>0.027055</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.80689</td>\n",
       "      <td>0.697682</td>\n",
       "      <td>0.749556</td>\n",
       "      <td>0.763084</td>\n",
       "      <td>0.198238</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.457301</td>\n",
       "      <td>0.685157</td>\n",
       "      <td>0.813714</td>\n",
       "      <td>0.78778</td>\n",
       "      <td>0.194767</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.457301</td>\n",
       "      <td>0.685157</td>\n",
       "      <td>0.813714</td>\n",
       "      <td>0.78778</td>\n",
       "      <td>0.194642</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.466463</td>\n",
       "      <td>0.684193</td>\n",
       "      <td>0.808601</td>\n",
       "      <td>0.785301</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.022927</td>\n",
       "      <td>0.633672</td>\n",
       "      <td>0.690134</td>\n",
       "      <td>0.707032</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.943934</td>\n",
       "      <td>0.640682</td>\n",
       "      <td>0.658593</td>\n",
       "      <td>0.681603</td>\n",
       "      <td>0.194767</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.460538</td>\n",
       "      <td>0.685459</td>\n",
       "      <td>0.817751</td>\n",
       "      <td>0.790522</td>\n",
       "      <td>0.179913</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.460538</td>\n",
       "      <td>0.685459</td>\n",
       "      <td>0.817751</td>\n",
       "      <td>0.790522</td>\n",
       "      <td>0.179759</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.565534</td>\n",
       "      <td>0.678726</td>\n",
       "      <td>0.810108</td>\n",
       "      <td>0.784542</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.977886</td>\n",
       "      <td>0.631343</td>\n",
       "      <td>0.70499</td>\n",
       "      <td>0.716209</td>\n",
       "      <td>0.026182</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.075186</td>\n",
       "      <td>0.723066</td>\n",
       "      <td>0.788471</td>\n",
       "      <td>0.792383</td>\n",
       "      <td>0.179913</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.481374</td>\n",
       "      <td>0.686835</td>\n",
       "      <td>0.818505</td>\n",
       "      <td>0.792667</td>\n",
       "      <td>0.195507</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.481374</td>\n",
       "      <td>0.686835</td>\n",
       "      <td>0.818505</td>\n",
       "      <td>0.792667</td>\n",
       "      <td>0.19537</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.523794</td>\n",
       "      <td>0.684765</td>\n",
       "      <td>0.810808</td>\n",
       "      <td>0.788653</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.984443</td>\n",
       "      <td>0.636379</td>\n",
       "      <td>0.706281</td>\n",
       "      <td>0.719471</td>\n",
       "      <td>0.025687</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.052206</td>\n",
       "      <td>0.677616</td>\n",
       "      <td>0.713171</td>\n",
       "      <td>0.733415</td>\n",
       "      <td>0.195507</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.459982</td>\n",
       "      <td>0.682582</td>\n",
       "      <td>0.815221</td>\n",
       "      <td>0.78897</td>\n",
       "      <td>0.195707</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.459982</td>\n",
       "      <td>0.682582</td>\n",
       "      <td>0.815221</td>\n",
       "      <td>0.78897</td>\n",
       "      <td>0.195567</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.438366</td>\n",
       "      <td>0.663059</td>\n",
       "      <td>0.805479</td>\n",
       "      <td>0.776639</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.01816</td>\n",
       "      <td>0.629088</td>\n",
       "      <td>0.696593</td>\n",
       "      <td>0.711131</td>\n",
       "      <td>0.024826</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.114352</td>\n",
       "      <td>0.670247</td>\n",
       "      <td>0.705689</td>\n",
       "      <td>0.726299</td>\n",
       "      <td>0.195707</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.365476</td>\n",
       "      <td>0.681455</td>\n",
       "      <td>0.816836</td>\n",
       "      <td>0.789239</td>\n",
       "      <td>0.201967</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.365476</td>\n",
       "      <td>0.681455</td>\n",
       "      <td>0.816836</td>\n",
       "      <td>0.789239</td>\n",
       "      <td>0.201786</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.370821</td>\n",
       "      <td>0.674988</td>\n",
       "      <td>0.809785</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.923594</td>\n",
       "      <td>0.643206</td>\n",
       "      <td>0.717046</td>\n",
       "      <td>0.727451</td>\n",
       "      <td>0.025664</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.998919</td>\n",
       "      <td>0.677666</td>\n",
       "      <td>0.712848</td>\n",
       "      <td>0.732938</td>\n",
       "      <td>0.201967</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DI  f1 macro  f1 micro f1 weighted TV distance         method\n",
       "0   0.404169  0.684183  0.817321    0.790214    0.198494         origin\n",
       "1   0.404169  0.684183  0.817321    0.790214    0.198317  unconstrained\n",
       "2   0.443225   0.67819   0.80957    0.784514    0.000433     barycentre\n",
       "3   0.949082  0.634739  0.706012     0.71817    0.027697  partial_0.001\n",
       "4   1.050704  0.681661  0.718661     0.73778    0.198494            ROC\n",
       "5   0.535714  0.685506   0.81802    0.790891    0.179957         origin\n",
       "6   0.535714  0.685506   0.81802    0.790891    0.179799  unconstrained\n",
       "7   0.546003   0.68186  0.808978    0.785674    0.000015     barycentre\n",
       "8   1.082815  0.620157  0.694655    0.706996    0.024951  partial_0.001\n",
       "9   0.904747   0.64546   0.66812     0.69173    0.179957            ROC\n",
       "10  0.472211  0.689621  0.820119     0.79501    0.190227         origin\n",
       "11  0.472211  0.689621  0.820119     0.79501    0.190058  unconstrained\n",
       "12  0.499855  0.686173  0.814791    0.791379    0.000251     barycentre\n",
       "13  1.028549   0.63809  0.712794    0.724193    0.023464  partial_0.001\n",
       "14  0.986754  0.717138  0.776414    0.784945    0.190227            ROC\n",
       "15  0.414965  0.686339   0.81802    0.792741    0.202326         origin\n",
       "16  0.414965  0.686339   0.81802    0.792741    0.202189  unconstrained\n",
       "17  0.394881  0.683511  0.807632    0.787278    0.000004     barycentre\n",
       "18  0.900939  0.639379  0.711664    0.723908     0.02605  partial_0.001\n",
       "19  0.909795  0.715092   0.77453    0.783223    0.202326            ROC\n",
       "20  0.499933  0.690772  0.820873    0.795524    0.198238         origin\n",
       "21  0.499933  0.690772  0.820873    0.795524    0.198166  unconstrained\n",
       "22  0.574749   0.68438  0.812799    0.789523    0.000053     barycentre\n",
       "23  1.088008  0.617143  0.695516    0.707609    0.027055  partial_0.001\n",
       "24   0.80689  0.697682  0.749556    0.763084    0.198238            ROC\n",
       "25  0.457301  0.685157  0.813714     0.78778    0.194767         origin\n",
       "26  0.457301  0.685157  0.813714     0.78778    0.194642  unconstrained\n",
       "27  0.466463  0.684193  0.808601    0.785301    0.000037     barycentre\n",
       "28  1.022927  0.633672  0.690134    0.707032    0.025641  partial_0.001\n",
       "29  0.943934  0.640682  0.658593    0.681603    0.194767            ROC\n",
       "30  0.460538  0.685459  0.817751    0.790522    0.179913         origin\n",
       "31  0.460538  0.685459  0.817751    0.790522    0.179759  unconstrained\n",
       "32  0.565534  0.678726  0.810108    0.784542    0.000351     barycentre\n",
       "33  0.977886  0.631343   0.70499    0.716209    0.026182  partial_0.001\n",
       "34  1.075186  0.723066  0.788471    0.792383    0.179913            ROC\n",
       "35  0.481374  0.686835  0.818505    0.792667    0.195507         origin\n",
       "36  0.481374  0.686835  0.818505    0.792667     0.19537  unconstrained\n",
       "37  0.523794  0.684765  0.810808    0.788653    0.000222     barycentre\n",
       "38  0.984443  0.636379  0.706281    0.719471    0.025687  partial_0.001\n",
       "39  1.052206  0.677616  0.713171    0.733415    0.195507            ROC\n",
       "40  0.459982  0.682582  0.815221     0.78897    0.195707         origin\n",
       "41  0.459982  0.682582  0.815221     0.78897    0.195567  unconstrained\n",
       "42  0.438366  0.663059  0.805479    0.776639    0.000484     barycentre\n",
       "43   1.01816  0.629088  0.696593    0.711131    0.024826  partial_0.001\n",
       "44  1.114352  0.670247  0.705689    0.726299    0.195707            ROC\n",
       "45  0.365476  0.681455  0.816836    0.789239    0.201967         origin\n",
       "46  0.365476  0.681455  0.816836    0.789239    0.201786  unconstrained\n",
       "47  0.370821  0.674988  0.809785    0.783626    0.000597     barycentre\n",
       "48  0.923594  0.643206  0.717046    0.727451    0.025664  partial_0.001\n",
       "49  0.998919  0.677666  0.712848    0.732938    0.201967            ROC"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4  Compute average feature importance\n",
    "\n",
    "Finally, we will revisit our random-forest baseline to see which features drive the income prediction the most.\n",
    "\n",
    "This helps contextualize which attributes the model relies on - and which we may want to protect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance=[]\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "    clf=RandomForestClassifier(max_depth=5).fit(X_train[:,0:var_dim],y_train)\n",
    "    importance.append(list(clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features ['hours-per-week', 'age', 'capital-gain', 'capital-loss', 'education-num']\n",
      "mean importances [0.09362191 0.20273629 0.33469304 0.04819054 0.32075823]\n"
     ]
    }
   ],
   "source": [
    "importance=np.array(importance)\n",
    "print(\"features\", var_list)\n",
    "print(\"mean importances\", importance.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Conclusions\n",
    "\n",
    "Our **baseline** (origin/unconstrained) shows the best accuracy but also the biggest gap between protected groups. \n",
    "\n",
    "The **barycentre** method virtually erases that gap - but does so by flipping a lot of predictions, which could feel jarring in practice. \n",
    "\n",
    "With **partial repair**, you get a handy dial: small tweaks nudge toward parity with minimal impact, while larger tweaks tighten fairness at a greater cost. \n",
    "\n",
    "And **ROC post-processing** strikes a nice compromise, cutting disparity quite a bit while keeping f-scores close to where we started.\n",
    "\n",
    "Looking at feature importance reminds us what the model \"cares about\" most: **capital gain** and **education level** top the list, with **age** not far behind. If you’re worried about proxying sensitive traits, these are the variables to think hard about - either by guarding them or by designing even earlier interventions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
