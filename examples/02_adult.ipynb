{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "from aif360.datasets import BinaryLabelDataset, AdultDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# TODO: change the import method\n",
    "import sys\n",
    "import os\n",
    "repo_root = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, repo_root)\n",
    "repair_folder = os.path.join(repo_root, \"humancompatible\", \"repair\")\n",
    "sys.path.insert(0, repair_folder)\n",
    "from humancompatible.repair.cost import *\n",
    "from humancompatible.repair.coupling_utils import *\n",
    "from humancompatible.repair.data_analysis import *\n",
    "from humancompatible.repair.group_blind_repair import *\n",
    "from humancompatible.repair.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path=os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROCpostprocess:\n",
    "    def __init__(self,X_val,y_val,var_list,prediction_model,favorable_label):\n",
    "        self.X_val =X_val\n",
    "        self.y_val =y_val\n",
    "        self.model = prediction_model\n",
    "        self.positive_index = 1 # positive label\n",
    "        self.var_list = var_list\n",
    "        self.var_dim=len(self.var_list)\n",
    "        self.ROC = self.buildROCusingval()\n",
    "        self.favorable_label = favorable_label\n",
    "\n",
    "    def buildbinarydata(self,X,y):\n",
    "        df=pd.DataFrame(np.concatenate((X,y.reshape(-1,1)), axis=1),columns=self.var_list+['S','W','Y'])\n",
    "        binaryLabelDataset = BinaryLabelDataset(\n",
    "                            # favorable_label=self.favorable_label,\n",
    "                            # unfavorable_label=0,\n",
    "                            df=df[self.var_list+['S','W','Y']], #df_test.drop('X',axis=1), #[x_list+['S','W','Y']],\n",
    "                            label_names=['Y'],\n",
    "                            instance_weights_name=['W'],\n",
    "                            protected_attribute_names=['S'],\n",
    "                            privileged_protected_attributes=[np.array([1.0])],\n",
    "                            unprivileged_protected_attributes=[np.array([0.])])\n",
    "        return binaryLabelDataset,df\n",
    "\n",
    "    def buildROCusingval(self):\n",
    "        dataset_val = self.buildbinarydata(self.X_val,self.y_val)[0]\n",
    "        dataset_val_pred = dataset_val.copy(deepcopy=True)\n",
    "        dataset_val_pred.scores = self.model.predict_proba(dataset_val.features[:,0:self.var_dim])[:,self.positive_index].reshape(-1,1)\n",
    "        privileged_groups = [{'S': 1}]\n",
    "        unprivileged_groups = [{'S': 0}]\n",
    "        # Metric used (should be one of allowed_metrics)\n",
    "        metric_name = \"Statistical parity difference\"\n",
    "        # Upper and lower bound on the fairness metric used\n",
    "        metric_ub = 0.05\n",
    "        metric_lb = -0.05\n",
    "        ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                        privileged_groups=privileged_groups, \n",
    "                                        low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                        num_class_thresh=50, num_ROC_margin=10,\n",
    "                                        metric_name=metric_name,\n",
    "                                        metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "        ROC = ROC.fit(dataset_val, dataset_val_pred)\n",
    "        print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "        print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)\n",
    "        return ROC\n",
    "\n",
    "    def postprocess(self,X_test,y_test,tv_origin): # the tv distance won't change\n",
    "        dataset_test_pred,df_test = self.buildbinarydata(X_test,y_test) #.copy(deepcopy=True)\n",
    "        dataset_test_pred.scores = self.model.predict_proba(X_test[:,0:self.var_dim])[:,self.positive_index].reshape(-1,1)\n",
    "        dataset_test_pred_transf = self.ROC.predict(dataset_test_pred)\n",
    "        y_pred = dataset_test_pred_transf.labels\n",
    "        # return dataset_test_pred_transf.convert_to_dataframe()[0]\n",
    "\n",
    "        di = DisparateImpact_postprocess(df_test,y_pred,favorable_label=self.favorable_label)\n",
    "        f1_macro = f1_score(df_test['Y'], y_pred, average='macro',sample_weight=df_test['W'])\n",
    "        f1_micro = f1_score(df_test['Y'], y_pred, average='micro',sample_weight=df_test['W'])\n",
    "        f1_weighted = f1_score(df_test['Y'], y_pred, average='weighted',sample_weight=df_test['W'])\n",
    "        new_row=pd.Series({'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,\n",
    "                           'TV distance':tv_origin,'method':'ROC'})\n",
    "        return new_row.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projpostprocess:\n",
    "    \n",
    "    def __init__(self,X_test,y_test,x_list,var_list,prediction_model,K,e,thresh,favorable_label=1):\n",
    "        self.model = prediction_model\n",
    "        self.K=K\n",
    "        self.e=e\n",
    "        self.x_list=x_list\n",
    "        self.var_list=var_list\n",
    "        self.var_dim=len(var_list)\n",
    "        self.favorable_label = favorable_label\n",
    "\n",
    "        df_test=pd.DataFrame(np.concatenate((X_test,y_test.reshape(-1,1)), axis=1),columns=var_list+['S','W','Y'])\n",
    "        df_test=df_test.groupby(by=var_list+['S','Y'],as_index=False).sum()\n",
    "        if len(x_list)>1:\n",
    "            df_test['X'] = list(zip(*[df_test[c] for c in x_list]))\n",
    "            self.x_range=sorted(set(df_test['X']))\n",
    "            weight=list(1/(df_test[x_list].max()-df_test[x_list].min())) # because 'education-num' range from 1 to 16 while others 1 to 4\n",
    "            self.C=c_generate_higher(self.x_range,weight)\n",
    "        else:\n",
    "            df_test['X']=df_test[x_list]\n",
    "            self.x_range=sorted(set(df_test['X']))\n",
    "            self.C=c_generate(self.x_range)\n",
    "        self.df_test = df_test\n",
    "        self.var_range=list(pd.pivot_table(df_test,index=var_list,values=['S','W','Y']).index)\n",
    "        self.distribution_generator()\n",
    "        \n",
    "        if thresh == 'auto':\n",
    "            self.thresh_generator()\n",
    "        else:\n",
    "            self.thresh=thresh\n",
    "\n",
    "    def distribution_generator(self):\n",
    "        bin=len(self.x_range)\n",
    "        dist=rdata_analysis(self.df_test,self.x_range,'X')\n",
    "        \n",
    "        dist['v']=[(dist['x_0'][i]-dist['x_1'][i])/dist['x'][i] for i in range(bin)]\n",
    "        \n",
    "        dist['t_x']=dist['x'] # #dist['x'] #dist['x_0']*0.5+dist['x_1']*0.5 \n",
    "        self.px=np.matrix(dist['x']).T\n",
    "        self.ptx=np.matrix(dist['t_x']).T\n",
    "        if np.any(dist['x_0']==0): \n",
    "            self.p0=np.matrix((dist['x_0']+1.0e-9)/sum(dist['x_0']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p0=np.matrix(dist['x_0']).T \n",
    "        if np.any(dist['x_1']==0):\n",
    "            self.p1=np.matrix((dist['x_1']+1.0e-9)/sum(dist['x_1']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p1=np.matrix(dist['x_1']).T \n",
    "        self.V=np.matrix(dist['v']).T\n",
    "        self.tv_origin=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "        # return px,ptx,V,p0,p1\n",
    "    \n",
    "    def _run_method(self, method, C, eps, px, ptx, K, V=None, theta=None):\n",
    "        group_blind = GroupBlindRepair(C, px, ptx, V=V, epsilon=eps, K=K)\n",
    "        if method == \"baseline\":\n",
    "            group_blind.fit_baseline()\n",
    "        elif method == \"partial_repair\":\n",
    "            group_blind.fit_partial(theta)\n",
    "        elif method == \"total_repair\":\n",
    "            group_blind.fit_total()\n",
    "        return group_blind.coupling_matrix()\n",
    "\n",
    "    def coupling_generator(self,method,para=None):\n",
    "        if method == 'unconstrained':\n",
    "            coupling=self._run_method(method=\"baseline\", C=self.C, eps=self.e, px=self.px, ptx=self.ptx, K=self.K)\n",
    "        elif method == 'barycentre':\n",
    "            coupling=self._run_method(method=\"baseline\", C=self.C, eps=self.e, px=self.p0, ptx=self.p1, K=self.K)\n",
    "        elif method == 'partial':\n",
    "            coupling=self._run_method(method=\"partial_repair\", C=self.C, eps=self.e, px=self.px, ptx=self.ptx, V=self.V, theta=para, K=self.K)\n",
    "        return coupling\n",
    "\n",
    "    def postprocess(self,method,para=None):\n",
    "        if method == 'origin':\n",
    "            y_pred=self.model.predict(np.array(self.df_test[self.var_list]))\n",
    "            tv = self.tv_origin\n",
    "        else:\n",
    "            coupling = self.coupling_generator(method,para)\n",
    "            if (method == 'unconstrained') or (method == 'partial'):\n",
    "                y_pred=postprocess(self.df_test,coupling,self.x_list,self.x_range,self.var_list,self.var_range,self.model,self.thresh)\n",
    "                tv=assess_tv(self.df_test,coupling,self.x_range,self.x_list,self.var_list)\n",
    "                if (para != None) and (method == 'partial'):\n",
    "                    method = method+'_'+str(para)\n",
    "            elif method == 'barycentre':\n",
    "                y_pred,tv=postprocess_bary(self.df_test,coupling,self.x_list,self.x_range,self.var_list,self.var_range,self.model,self.thresh)\n",
    "            else:\n",
    "                print('Unknown method')\n",
    "\n",
    "        di = DisparateImpact_postprocess(self.df_test,y_pred,favorable_label=self.favorable_label)\n",
    "        f1_macro = f1_score(self.df_test['Y'], y_pred, average='macro',sample_weight=self.df_test['W'])\n",
    "        f1_micro = f1_score(self.df_test['Y'], y_pred, average='micro',sample_weight=self.df_test['W'])\n",
    "        f1_weighted = f1_score(self.df_test['Y'], y_pred, average='weighted',sample_weight=self.df_test['W'])\n",
    "\n",
    "        new_row=pd.Series({'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,\n",
    "                           'TV distance':tv,'method':method})\n",
    "        return new_row.to_frame().T\n",
    "    \n",
    "    def thresh_generator(self):\n",
    "        num_thresh = 10\n",
    "        ba_arr = np.zeros(num_thresh)\n",
    "        ba_arr1 = np.zeros(num_thresh)\n",
    "        class_thresh_arr = np.linspace(0.01, 0.1, num_thresh)\n",
    "        coupling=self.coupling_generator('partial',para=1e-2)\n",
    "    \n",
    "        for idx, thresh in enumerate(class_thresh_arr):\n",
    "            y_pred=postprocess(self.df_test,coupling,self.x_list,self.x_range,self.var_list,self.var_range,self.model,thresh)\n",
    "            ba_arr[idx] = DisparateImpact_postprocess(self.df_test,y_pred,favorable_label=self.favorable_label)\n",
    "            ba_arr1[idx] = f1_score(self.df_test['Y'], y_pred, average='macro',sample_weight=self.df_test['W'])\n",
    "\n",
    "        best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "        best_thresh = class_thresh_arr[best_ind]\n",
    "        print(\"Optional threshold = \",class_thresh_arr)\n",
    "        print(\"Disparate Impact = \",ba_arr)\n",
    "        print(\"f1 scores = \",ba_arr1)\n",
    "        self.thresh = best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path,var_list,pa):\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education',\n",
    "                'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "                'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                'native-country', 'Y']\n",
    "    na_values=['?']\n",
    "    pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "    label_dict={'>50K.':1,'>50K':1,'<=50K.':0,'<=50K':0}\n",
    "    train_path = os.path.join(data_path, 'adult.data')\n",
    "    test_path = os.path.join(data_path, 'adult.test')\n",
    "    train = pd.read_csv(train_path, header=None,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    test = pd.read_csv(test_path, header=0,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    messydata = pd.concat([test, train], ignore_index=True)[var_list+[pa,'Y']]\n",
    "    messydata=messydata.rename(columns={pa:'S'})\n",
    "    messydata['S']=messydata['S'].replace(pa_dict)\n",
    "    messydata['Y']=messydata['Y'].replace(label_dict)\n",
    "    messydata=messydata[(messydata['S']==0)|(messydata['S']==1)]\n",
    "    for col in var_list+['S','Y']:\n",
    "        messydata[col]=messydata[col].astype('int64')\n",
    "    messydata['W']=1\n",
    "    bins_capitalgain=[100,3500,7500,10000]\n",
    "    bins_capitalloss=[100,1600,1900,2200]\n",
    "    bins_age=[26,36,46,56]\n",
    "    bins_hours=[21,36,46,61]\n",
    "\n",
    "    messydata=categerise(messydata,'age',bins_age)\n",
    "    messydata=categerise(messydata,'hours-per-week',bins_hours)\n",
    "    messydata=categerise(messydata,'capital-gain',bins_capitalgain)\n",
    "    messydata=categerise(messydata,'capital-loss',bins_capitalloss)\n",
    "    \n",
    "    return messydata\n",
    "\n",
    "def categerise(df,col,bins):\n",
    "    for i in range(len(bins)+1):\n",
    "        if i == 0:\n",
    "            df.loc[df[col] < bins[i], col] = i\n",
    "        elif i == len(bins):\n",
    "            df.loc[df[col] >= bins[i-1], col] = i\n",
    "        else:\n",
    "            df.loc[(df[col] >= bins[i-1])& (df[col] < bins[i]), col] = i        \n",
    "    return df\n",
    "\n",
    "def choose_x(var_list,messydata):\n",
    "    tv_dist=dict()\n",
    "    for x_name in var_list:\n",
    "        x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "        dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "        tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    x_list=[]\n",
    "    for key,val in tv_dist.items():\n",
    "        if val>0.1:\n",
    "            x_list+=[key]  \n",
    "    return x_list,tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: change this path\n",
    "data_path='C://personal//work//repair//.venv//Lib//site-packages//aif360//data//raw//adult'\n",
    "\n",
    "var_list=['hours-per-week','age','capital-gain','capital-loss','education-num'] #\n",
    "pa='race'\n",
    "favorable_label = 1\n",
    "var_dim=len(var_list)\n",
    "\n",
    "K=200\n",
    "e=0.01\n",
    "\n",
    "if pa == 'sex':\n",
    "    thresh=0.05\n",
    "elif pa == 'race':\n",
    "    thresh=0.05\n",
    "\n",
    "messydata = load_data(data_path,var_list,pa)\n",
    "x_list,tv_dist = choose_x(var_list,messydata)\n",
    "\n",
    "X=messydata[var_list+['S','W']].to_numpy() # [X,S,W]\n",
    "y=messydata['Y'].to_numpy() #[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hours-per-week': np.float64(0.12216173195089294),\n",
       " 'age': np.float64(0.04149230147335384),\n",
       " 'capital-gain': np.float64(0.026764553949230142),\n",
       " 'capital-loss': np.float64(0.014217783478743178),\n",
       " 'education-num': np.float64(0.11867963282506956)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraints) = 0.1900\n",
      "Optimal ROC margin = 0.0211\n",
      "Optimal classification threshold (with fairness constraints) = 0.2500\n",
      "Optimal ROC margin = 0.0278\n",
      "Optimal classification threshold (with fairness constraints) = 0.1900\n",
      "Optimal ROC margin = 0.0211\n",
      "Optimal classification threshold (with fairness constraints) = 0.2500\n",
      "Optimal ROC margin = 0.0278\n",
      "Optimal classification threshold (with fairness constraints) = 0.1900\n",
      "Optimal ROC margin = 0.0211\n",
      "Optimal classification threshold (with fairness constraints) = 0.1900\n",
      "Optimal ROC margin = 0.0211\n",
      "Optimal classification threshold (with fairness constraints) = 0.2300\n",
      "Optimal ROC margin = 0.0256\n",
      "Optimal classification threshold (with fairness constraints) = 0.2500\n",
      "Optimal ROC margin = 0.0278\n",
      "Optimal classification threshold (with fairness constraints) = 0.2500\n",
      "Optimal ROC margin = 0.0278\n",
      "Optimal classification threshold (with fairness constraints) = 0.2100\n",
      "Optimal ROC margin = 0.0233\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','unconstrained','barycentre','partial','ROC'] # Place ROC in the end\n",
    "report=pd.DataFrame(columns=['DI','f1 macro','f1 micro','f1 weighted','TV distance','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "    clf=RandomForestClassifier(max_depth=5).fit(X_train[:,0:var_dim],y_train)\n",
    "    projpost = Projpostprocess(X_test,y_test,x_list,var_list,clf,K,e,thresh,favorable_label)\n",
    "    for method in methods[:-1]:\n",
    "        # report = pd.concat([report,projpost.postprocess(method,para=1e-2)], ignore_index=True)\n",
    "        report = pd.concat([report,projpost.postprocess(method,para=1e-3)], ignore_index=True)\n",
    "\n",
    "    ROCpost = ROCpostprocess(X_val,y_val,var_list,clf,favorable_label) # use validation set to train a ROC model\n",
    "    report = pd.concat([report,ROCpost.postprocess(X_test,y_test,tv_origin=projpost.tv_origin)], ignore_index=True)\n",
    "\n",
    "report.to_csv(path+'/data/report_postprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>TV distance</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.44089</td>\n",
       "      <td>0.695622</td>\n",
       "      <td>0.822918</td>\n",
       "      <td>0.798317</td>\n",
       "      <td>0.201745</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.44089</td>\n",
       "      <td>0.695622</td>\n",
       "      <td>0.822918</td>\n",
       "      <td>0.798317</td>\n",
       "      <td>0.201586</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523586</td>\n",
       "      <td>0.690475</td>\n",
       "      <td>0.816244</td>\n",
       "      <td>0.793412</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.003543</td>\n",
       "      <td>0.629555</td>\n",
       "      <td>0.69557</td>\n",
       "      <td>0.711142</td>\n",
       "      <td>0.02522</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.063995</td>\n",
       "      <td>0.677043</td>\n",
       "      <td>0.711018</td>\n",
       "      <td>0.731693</td>\n",
       "      <td>0.201745</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.484483</td>\n",
       "      <td>0.689719</td>\n",
       "      <td>0.815221</td>\n",
       "      <td>0.790782</td>\n",
       "      <td>0.186703</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.484483</td>\n",
       "      <td>0.689719</td>\n",
       "      <td>0.815221</td>\n",
       "      <td>0.790782</td>\n",
       "      <td>0.18656</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.571713</td>\n",
       "      <td>0.689318</td>\n",
       "      <td>0.810054</td>\n",
       "      <td>0.788507</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.118056</td>\n",
       "      <td>0.610987</td>\n",
       "      <td>0.704559</td>\n",
       "      <td>0.708697</td>\n",
       "      <td>0.027387</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.926581</td>\n",
       "      <td>0.721237</td>\n",
       "      <td>0.77776</td>\n",
       "      <td>0.785523</td>\n",
       "      <td>0.186703</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.481969</td>\n",
       "      <td>0.680863</td>\n",
       "      <td>0.816944</td>\n",
       "      <td>0.789676</td>\n",
       "      <td>0.183082</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.481969</td>\n",
       "      <td>0.680863</td>\n",
       "      <td>0.816944</td>\n",
       "      <td>0.789676</td>\n",
       "      <td>0.182953</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.552126</td>\n",
       "      <td>0.677418</td>\n",
       "      <td>0.809624</td>\n",
       "      <td>0.785248</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.05397</td>\n",
       "      <td>0.612424</td>\n",
       "      <td>0.684321</td>\n",
       "      <td>0.699586</td>\n",
       "      <td>0.024069</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.087541</td>\n",
       "      <td>0.670584</td>\n",
       "      <td>0.70655</td>\n",
       "      <td>0.727419</td>\n",
       "      <td>0.183082</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.449155</td>\n",
       "      <td>0.693059</td>\n",
       "      <td>0.818559</td>\n",
       "      <td>0.795751</td>\n",
       "      <td>0.177351</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.449155</td>\n",
       "      <td>0.693059</td>\n",
       "      <td>0.818559</td>\n",
       "      <td>0.795751</td>\n",
       "      <td>0.177246</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.549506</td>\n",
       "      <td>0.682715</td>\n",
       "      <td>0.81027</td>\n",
       "      <td>0.787975</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.016256</td>\n",
       "      <td>0.611369</td>\n",
       "      <td>0.682975</td>\n",
       "      <td>0.698653</td>\n",
       "      <td>0.023047</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.968149</td>\n",
       "      <td>0.711148</td>\n",
       "      <td>0.77087</td>\n",
       "      <td>0.77987</td>\n",
       "      <td>0.177351</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.468625</td>\n",
       "      <td>0.675559</td>\n",
       "      <td>0.816836</td>\n",
       "      <td>0.786956</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.468625</td>\n",
       "      <td>0.675559</td>\n",
       "      <td>0.816836</td>\n",
       "      <td>0.786956</td>\n",
       "      <td>0.18633</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.546298</td>\n",
       "      <td>0.669314</td>\n",
       "      <td>0.809785</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.029938</td>\n",
       "      <td>0.638352</td>\n",
       "      <td>0.720652</td>\n",
       "      <td>0.728118</td>\n",
       "      <td>0.025681</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.155515</td>\n",
       "      <td>0.675589</td>\n",
       "      <td>0.709457</td>\n",
       "      <td>0.730129</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.401175</td>\n",
       "      <td>0.691235</td>\n",
       "      <td>0.82168</td>\n",
       "      <td>0.796933</td>\n",
       "      <td>0.191424</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.401175</td>\n",
       "      <td>0.691235</td>\n",
       "      <td>0.82168</td>\n",
       "      <td>0.796933</td>\n",
       "      <td>0.191319</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.44059</td>\n",
       "      <td>0.685249</td>\n",
       "      <td>0.813661</td>\n",
       "      <td>0.791131</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.962601</td>\n",
       "      <td>0.632639</td>\n",
       "      <td>0.705797</td>\n",
       "      <td>0.71898</td>\n",
       "      <td>0.025617</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.051373</td>\n",
       "      <td>0.673538</td>\n",
       "      <td>0.708811</td>\n",
       "      <td>0.730055</td>\n",
       "      <td>0.191424</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.44536</td>\n",
       "      <td>0.683228</td>\n",
       "      <td>0.819797</td>\n",
       "      <td>0.791764</td>\n",
       "      <td>0.182471</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.44536</td>\n",
       "      <td>0.683228</td>\n",
       "      <td>0.819797</td>\n",
       "      <td>0.791764</td>\n",
       "      <td>0.182357</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.46198</td>\n",
       "      <td>0.655306</td>\n",
       "      <td>0.808009</td>\n",
       "      <td>0.775026</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.945536</td>\n",
       "      <td>0.632626</td>\n",
       "      <td>0.714839</td>\n",
       "      <td>0.723314</td>\n",
       "      <td>0.025613</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.892195</td>\n",
       "      <td>0.704892</td>\n",
       "      <td>0.757522</td>\n",
       "      <td>0.769925</td>\n",
       "      <td>0.182471</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.418775</td>\n",
       "      <td>0.683637</td>\n",
       "      <td>0.815814</td>\n",
       "      <td>0.789948</td>\n",
       "      <td>0.189237</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.418775</td>\n",
       "      <td>0.683637</td>\n",
       "      <td>0.815814</td>\n",
       "      <td>0.789948</td>\n",
       "      <td>0.18911</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.498882</td>\n",
       "      <td>0.683008</td>\n",
       "      <td>0.808978</td>\n",
       "      <td>0.786897</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.040132</td>\n",
       "      <td>0.611959</td>\n",
       "      <td>0.679584</td>\n",
       "      <td>0.696177</td>\n",
       "      <td>0.024712</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.92547</td>\n",
       "      <td>0.711503</td>\n",
       "      <td>0.77087</td>\n",
       "      <td>0.779542</td>\n",
       "      <td>0.189237</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.482718</td>\n",
       "      <td>0.677905</td>\n",
       "      <td>0.814253</td>\n",
       "      <td>0.784779</td>\n",
       "      <td>0.185147</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.482718</td>\n",
       "      <td>0.677905</td>\n",
       "      <td>0.814253</td>\n",
       "      <td>0.784779</td>\n",
       "      <td>0.184965</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.536321</td>\n",
       "      <td>0.678516</td>\n",
       "      <td>0.808924</td>\n",
       "      <td>0.782937</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.018327</td>\n",
       "      <td>0.625095</td>\n",
       "      <td>0.691803</td>\n",
       "      <td>0.705745</td>\n",
       "      <td>0.024661</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.952548</td>\n",
       "      <td>0.718086</td>\n",
       "      <td>0.774907</td>\n",
       "      <td>0.782632</td>\n",
       "      <td>0.185147</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.438658</td>\n",
       "      <td>0.685906</td>\n",
       "      <td>0.816567</td>\n",
       "      <td>0.789613</td>\n",
       "      <td>0.207366</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.438658</td>\n",
       "      <td>0.685906</td>\n",
       "      <td>0.816567</td>\n",
       "      <td>0.789613</td>\n",
       "      <td>0.207217</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.483718</td>\n",
       "      <td>0.677772</td>\n",
       "      <td>0.808924</td>\n",
       "      <td>0.78301</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.023329</td>\n",
       "      <td>0.627658</td>\n",
       "      <td>0.703644</td>\n",
       "      <td>0.713766</td>\n",
       "      <td>0.026017</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.191077</td>\n",
       "      <td>0.698584</td>\n",
       "      <td>0.74595</td>\n",
       "      <td>0.759751</td>\n",
       "      <td>0.207366</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DI  f1 macro  f1 micro f1 weighted TV distance         method\n",
       "0    0.44089  0.695622  0.822918    0.798317    0.201745         origin\n",
       "1    0.44089  0.695622  0.822918    0.798317    0.201586  unconstrained\n",
       "2   0.523586  0.690475  0.816244    0.793412    0.000221     barycentre\n",
       "3   1.003543  0.629555   0.69557    0.711142     0.02522  partial_0.001\n",
       "4   1.063995  0.677043  0.711018    0.731693    0.201745            ROC\n",
       "5   0.484483  0.689719  0.815221    0.790782    0.186703         origin\n",
       "6   0.484483  0.689719  0.815221    0.790782     0.18656  unconstrained\n",
       "7   0.571713  0.689318  0.810054    0.788507    0.000022     barycentre\n",
       "8   1.118056  0.610987  0.704559    0.708697    0.027387  partial_0.001\n",
       "9   0.926581  0.721237   0.77776    0.785523    0.186703            ROC\n",
       "10  0.481969  0.680863  0.816944    0.789676    0.183082         origin\n",
       "11  0.481969  0.680863  0.816944    0.789676    0.182953  unconstrained\n",
       "12  0.552126  0.677418  0.809624    0.785248     0.00023     barycentre\n",
       "13   1.05397  0.612424  0.684321    0.699586    0.024069  partial_0.001\n",
       "14  1.087541  0.670584   0.70655    0.727419    0.183082            ROC\n",
       "15  0.449155  0.693059  0.818559    0.795751    0.177351         origin\n",
       "16  0.449155  0.693059  0.818559    0.795751    0.177246  unconstrained\n",
       "17  0.549506  0.682715   0.81027    0.787975    0.000001     barycentre\n",
       "18  1.016256  0.611369  0.682975    0.698653    0.023047  partial_0.001\n",
       "19  0.968149  0.711148   0.77087     0.77987    0.177351            ROC\n",
       "20  0.468625  0.675559  0.816836    0.786956    0.186441         origin\n",
       "21  0.468625  0.675559  0.816836    0.786956     0.18633  unconstrained\n",
       "22  0.546298  0.669314  0.809785    0.781457    0.000095     barycentre\n",
       "23  1.029938  0.638352  0.720652    0.728118    0.025681  partial_0.001\n",
       "24  1.155515  0.675589  0.709457    0.730129    0.186441            ROC\n",
       "25  0.401175  0.691235   0.82168    0.796933    0.191424         origin\n",
       "26  0.401175  0.691235   0.82168    0.796933    0.191319  unconstrained\n",
       "27   0.44059  0.685249  0.813661    0.791131    0.000217     barycentre\n",
       "28  0.962601  0.632639  0.705797     0.71898    0.025617  partial_0.001\n",
       "29  1.051373  0.673538  0.708811    0.730055    0.191424            ROC\n",
       "30   0.44536  0.683228  0.819797    0.791764    0.182471         origin\n",
       "31   0.44536  0.683228  0.819797    0.791764    0.182357  unconstrained\n",
       "32   0.46198  0.655306  0.808009    0.775026     0.00003     barycentre\n",
       "33  0.945536  0.632626  0.714839    0.723314    0.025613  partial_0.001\n",
       "34  0.892195  0.704892  0.757522    0.769925    0.182471            ROC\n",
       "35  0.418775  0.683637  0.815814    0.789948    0.189237         origin\n",
       "36  0.418775  0.683637  0.815814    0.789948     0.18911  unconstrained\n",
       "37  0.498882  0.683008  0.808978    0.786897    0.000004     barycentre\n",
       "38  1.040132  0.611959  0.679584    0.696177    0.024712  partial_0.001\n",
       "39   0.92547  0.711503   0.77087    0.779542    0.189237            ROC\n",
       "40  0.482718  0.677905  0.814253    0.784779    0.185147         origin\n",
       "41  0.482718  0.677905  0.814253    0.784779    0.184965  unconstrained\n",
       "42  0.536321  0.678516  0.808924    0.782937    0.000005     barycentre\n",
       "43  1.018327  0.625095  0.691803    0.705745    0.024661  partial_0.001\n",
       "44  0.952548  0.718086  0.774907    0.782632    0.185147            ROC\n",
       "45  0.438658  0.685906  0.816567    0.789613    0.207366         origin\n",
       "46  0.438658  0.685906  0.816567    0.789613    0.207217  unconstrained\n",
       "47  0.483718  0.677772  0.808924     0.78301    0.000189     barycentre\n",
       "48  1.023329  0.627658  0.703644    0.713766    0.026017  partial_0.001\n",
       "49  1.191077  0.698584   0.74595    0.759751    0.207366            ROC"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute average feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance=[]\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "    clf=RandomForestClassifier(max_depth=5).fit(X_train[:,0:var_dim],y_train)\n",
    "    importance.append(list(clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features ['hours-per-week', 'age', 'capital-gain', 'capital-loss', 'education-num']\n",
      "mean importances [0.09166975 0.20494856 0.34059725 0.04906175 0.31372269]\n"
     ]
    }
   ],
   "source": [
    "importance=np.array(importance)\n",
    "print(\"features\", var_list)\n",
    "print(\"mean importances\", importance.mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
