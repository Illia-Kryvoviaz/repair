{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness Post-Processing on the Adult Income Dataset\n",
    "\n",
    "In this notebook we compare several post-processing techniques on the well-known \"Adult\" dataset to  \n",
    "reduce demographic disparities in a binary income prediction task. \n",
    "\n",
    "We’ll walk through:  \n",
    "\n",
    "1. Imports & configuration\n",
    "\n",
    "2. Utility functions (data loading, feature selection)\n",
    "\n",
    "3. Training / post‑processing loop\n",
    "\n",
    "4. Result summary & feature importance\n",
    "\n",
    "5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1  Imports & basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "from aif360.datasets import BinaryLabelDataset, AdultDataset\n",
    "\n",
    "# TODO: change the import method\n",
    "repo_root = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, repo_root)\n",
    "repair_folder = os.path.join(repo_root, \"humancompatible\", \"repair\")\n",
    "sys.path.insert(0, repair_folder)\n",
    "from humancompatible.repair.methods.cost import *\n",
    "from humancompatible.repair.methods.coupling_utils import *\n",
    "from humancompatible.repair.methods.data_analysis import *\n",
    "from humancompatible.repair.group_blind_repair import *\n",
    "from humancompatible.repair.methods.metrics import *\n",
    "\n",
    "from humancompatible.repair.postprocess.roc_postprocess import ROCpostprocess\n",
    "from humancompatible.repair.postprocess.proj_postprocess import Projpostprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve turned off FutureWarning noise so we can focus on the core outputs. Next up, we’ll write a couple of utility functions to:\n",
    "\n",
    "1. **Load & clean** the Adult dataset (apply binning, encode labels).\n",
    "\n",
    "2. **Compute TV distances** to pick out the most imbalanced features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  Utility helpers\n",
    "\n",
    "Below are three helper functions:\n",
    "\n",
    "- **`load_data`**: merges train/test, binning continuous features, encodes sensitive (`S`) & target (`Y`).\n",
    "\n",
    "- **`categorise`**: assigns numeric bins for age, hours-per-week, capital gain/loss.\n",
    "\n",
    "- **`choose_x`**: measures total-variation distance for each feature to detect imbalance and returns a shortlist for repair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path,var_list,pa):\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education',\n",
    "                'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "                'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                'native-country', 'Y']\n",
    "    na_values=['?']\n",
    "    pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "    label_dict={'>50K.':1,'>50K':1,'<=50K.':0,'<=50K':0}\n",
    "    train_path = os.path.join(data_path, 'adult.data')\n",
    "    test_path = os.path.join(data_path, 'adult.test')\n",
    "    train = pd.read_csv(train_path, header=None,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    test = pd.read_csv(test_path, header=0,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    messydata = pd.concat([test, train], ignore_index=True)[var_list+[pa,'Y']]\n",
    "    messydata=messydata.rename(columns={pa:'S'})\n",
    "    messydata['S']=messydata['S'].replace(pa_dict)\n",
    "    messydata['Y']=messydata['Y'].replace(label_dict)\n",
    "    messydata=messydata[(messydata['S']==0)|(messydata['S']==1)]\n",
    "    for col in var_list+['S','Y']:\n",
    "        messydata[col]=messydata[col].astype('int64')\n",
    "    messydata['W']=1\n",
    "    bins_capitalgain=[100,3500,7500,10000]\n",
    "    bins_capitalloss=[100,1600,1900,2200]\n",
    "    bins_age=[26,36,46,56]\n",
    "    bins_hours=[21,36,46,61]\n",
    "\n",
    "    messydata=categerise(messydata,'age',bins_age)\n",
    "    messydata=categerise(messydata,'hours-per-week',bins_hours)\n",
    "    messydata=categerise(messydata,'capital-gain',bins_capitalgain)\n",
    "    messydata=categerise(messydata,'capital-loss',bins_capitalloss)\n",
    "    \n",
    "    return messydata\n",
    "\n",
    "def categerise(df,col,bins):\n",
    "    for i in range(len(bins)+1):\n",
    "        if i == 0:\n",
    "            df.loc[df[col] < bins[i], col] = i\n",
    "        elif i == len(bins):\n",
    "            df.loc[df[col] >= bins[i-1], col] = i\n",
    "        else:\n",
    "            df.loc[(df[col] >= bins[i-1])& (df[col] < bins[i]), col] = i        \n",
    "    return df\n",
    "\n",
    "def choose_x(var_list,messydata):\n",
    "    tv_dist=dict()\n",
    "    for x_name in var_list:\n",
    "        x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "        dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "        tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    x_list=[]\n",
    "    for key,val in tv_dist.items():\n",
    "        if val>0.1:\n",
    "            x_list+=[key]  \n",
    "    return x_list,tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='..//data//adult'\n",
    "var_list=['hours-per-week','age','capital-gain','capital-loss','education-num'] #\n",
    "pa='race'\n",
    "favorable_label = 1\n",
    "var_dim=len(var_list)\n",
    "\n",
    "K=200\n",
    "e=0.01\n",
    "\n",
    "if pa == 'sex':\n",
    "    thresh=0.05\n",
    "elif pa == 'race':\n",
    "    thresh=0.05\n",
    "\n",
    "messydata = load_data(data_path,var_list,pa)\n",
    "x_list,tv_dist = choose_x(var_list,messydata)\n",
    "\n",
    "X=messydata[var_list+['S','W']].to_numpy() # [X,S,W]\n",
    "y=messydata['Y'].to_numpy() #[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hours-per-week': np.float64(0.12216173195089294),\n",
       " 'age': np.float64(0.04149230147335384),\n",
       " 'capital-gain': np.float64(0.026764553949230142),\n",
       " 'capital-loss': np.float64(0.014217783478743178),\n",
       " 'education-num': np.float64(0.11867963282506956)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see which features differ most across the sensitive groups:\n",
    "\n",
    "- **hours-per-week** and **education-num** stand out  \n",
    "\n",
    "- These will be the coordinates along which we apply our post-processing repairs\n",
    "\n",
    "With `X, y` ready, we now move on to the main experiment loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  Training & post‑processing experiment\n",
    "\n",
    "Here we’ll:\n",
    "\n",
    "1. Split data (train/val/test).  \n",
    "\n",
    "2. Fit a Random Forest baseline.  \n",
    "\n",
    "3. Apply four post-processing strategies:\n",
    "   - **origin** (no fairness correction)  \n",
    "   - **unconstrained** (repair without thresholding)  \n",
    "   - **barycentre** (optimal transport-based repair)  \n",
    "   - **partial** (partial coupling)  \n",
    "   - **ROC** (learn an ROC-based thresholding on the validation set)\n",
    "\n",
    "We repeat this 10× to smooth out randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraints) = 0.2500\n",
      "Optimal ROC margin = 0.0278\n",
      "Optimal classification threshold (with fairness constraints) = 0.2500\n",
      "Optimal ROC margin = 0.0278\n",
      "Optimal classification threshold (with fairness constraints) = 0.2100\n",
      "Optimal ROC margin = 0.0233\n",
      "Optimal classification threshold (with fairness constraints) = 0.2100\n",
      "Optimal ROC margin = 0.0233\n",
      "Optimal classification threshold (with fairness constraints) = 0.1900\n",
      "Optimal ROC margin = 0.0211\n",
      "Optimal classification threshold (with fairness constraints) = 0.2500\n",
      "Optimal ROC margin = 0.0278\n",
      "Optimal classification threshold (with fairness constraints) = 0.2500\n",
      "Optimal ROC margin = 0.0278\n",
      "Optimal classification threshold (with fairness constraints) = 0.2100\n",
      "Optimal ROC margin = 0.0233\n",
      "Optimal classification threshold (with fairness constraints) = 0.2500\n",
      "Optimal ROC margin = 0.0278\n",
      "Optimal classification threshold (with fairness constraints) = 0.1900\n",
      "Optimal ROC margin = 0.0211\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','unconstrained','barycentre','partial','ROC'] # Place ROC in the end\n",
    "report=pd.DataFrame(columns=['DI','f1 macro','f1 micro','f1 weighted','TV distance','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "    clf=RandomForestClassifier(max_depth=5).fit(X_train[:,0:var_dim],y_train)\n",
    "    projpost = Projpostprocess(X_test,y_test,x_list,var_list,clf,K,e,thresh,favorable_label,linspace_range=(0.01,0.1),theta=1e-2)\n",
    "    for method in methods[:-1]:\n",
    "        # report = pd.concat([report,projpost.postprocess(method,para=1e-2)], ignore_index=True)\n",
    "        report = pd.concat([report,projpost.postprocess(method,para=1e-3)], ignore_index=True)\n",
    "\n",
    "    ROCpost = ROCpostprocess(X_val,y_val,var_list,clf,favorable_label) # use validation set to train a ROC model\n",
    "    report = pd.concat([report,ROCpost.postprocess(X_test,y_test,tv_origin=projpost.tv_origin)], ignore_index=True)\n",
    "\n",
    "report.to_csv('../data/report_postprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logs above show, for each fold, the selected decision threshold and ROC margin needed to satisfy our fairness constraint. \n",
    "\n",
    "Lower margins indicate less aggressive adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s aggregate results across our folds.  In the table below:\n",
    "\n",
    "- **DI** (Disparate Impact): ratio of favourable outcomes  \n",
    "\n",
    "- **F1** (macro/micro/weighted): classification quality  \n",
    "\n",
    "- **TV distance**: remaining distribution gap on the repaired features  \n",
    "\n",
    "- **method**: which post-processor was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>TV distance</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.475461</td>\n",
       "      <td>0.68644</td>\n",
       "      <td>0.817751</td>\n",
       "      <td>0.792063</td>\n",
       "      <td>0.183889</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.475461</td>\n",
       "      <td>0.68644</td>\n",
       "      <td>0.817751</td>\n",
       "      <td>0.792063</td>\n",
       "      <td>0.183804</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523036</td>\n",
       "      <td>0.686234</td>\n",
       "      <td>0.811561</td>\n",
       "      <td>0.789457</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.033796</td>\n",
       "      <td>0.620186</td>\n",
       "      <td>0.690995</td>\n",
       "      <td>0.705551</td>\n",
       "      <td>0.025841</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.037732</td>\n",
       "      <td>0.718886</td>\n",
       "      <td>0.776899</td>\n",
       "      <td>0.78536</td>\n",
       "      <td>0.183889</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.476313</td>\n",
       "      <td>0.693666</td>\n",
       "      <td>0.822165</td>\n",
       "      <td>0.797155</td>\n",
       "      <td>0.188048</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.476313</td>\n",
       "      <td>0.693666</td>\n",
       "      <td>0.822165</td>\n",
       "      <td>0.797155</td>\n",
       "      <td>0.187894</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.505581</td>\n",
       "      <td>0.692132</td>\n",
       "      <td>0.81689</td>\n",
       "      <td>0.794358</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.034528</td>\n",
       "      <td>0.614992</td>\n",
       "      <td>0.69148</td>\n",
       "      <td>0.704503</td>\n",
       "      <td>0.025483</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.99929</td>\n",
       "      <td>0.720119</td>\n",
       "      <td>0.780074</td>\n",
       "      <td>0.787688</td>\n",
       "      <td>0.188048</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.572486</td>\n",
       "      <td>0.694913</td>\n",
       "      <td>0.820012</td>\n",
       "      <td>0.797867</td>\n",
       "      <td>0.177917</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.572486</td>\n",
       "      <td>0.694913</td>\n",
       "      <td>0.820012</td>\n",
       "      <td>0.797867</td>\n",
       "      <td>0.177824</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.656437</td>\n",
       "      <td>0.690917</td>\n",
       "      <td>0.81253</td>\n",
       "      <td>0.793089</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.070007</td>\n",
       "      <td>0.619943</td>\n",
       "      <td>0.689865</td>\n",
       "      <td>0.705851</td>\n",
       "      <td>0.024637</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.091692</td>\n",
       "      <td>0.680888</td>\n",
       "      <td>0.719791</td>\n",
       "      <td>0.739606</td>\n",
       "      <td>0.177917</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.500643</td>\n",
       "      <td>0.693356</td>\n",
       "      <td>0.816298</td>\n",
       "      <td>0.795135</td>\n",
       "      <td>0.190228</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.500643</td>\n",
       "      <td>0.693356</td>\n",
       "      <td>0.816298</td>\n",
       "      <td>0.795135</td>\n",
       "      <td>0.190099</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.622277</td>\n",
       "      <td>0.689476</td>\n",
       "      <td>0.804672</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.021832</td>\n",
       "      <td>0.610178</td>\n",
       "      <td>0.686151</td>\n",
       "      <td>0.700388</td>\n",
       "      <td>0.025909</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.991517</td>\n",
       "      <td>0.684316</td>\n",
       "      <td>0.723505</td>\n",
       "      <td>0.74262</td>\n",
       "      <td>0.190228</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.496236</td>\n",
       "      <td>0.690994</td>\n",
       "      <td>0.819581</td>\n",
       "      <td>0.793574</td>\n",
       "      <td>0.192912</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.496236</td>\n",
       "      <td>0.690994</td>\n",
       "      <td>0.819581</td>\n",
       "      <td>0.793574</td>\n",
       "      <td>0.19274</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.535787</td>\n",
       "      <td>0.690479</td>\n",
       "      <td>0.812369</td>\n",
       "      <td>0.790435</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.975459</td>\n",
       "      <td>0.640915</td>\n",
       "      <td>0.708865</td>\n",
       "      <td>0.7213</td>\n",
       "      <td>0.023983</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.060931</td>\n",
       "      <td>0.67504</td>\n",
       "      <td>0.707788</td>\n",
       "      <td>0.728127</td>\n",
       "      <td>0.192912</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.478522</td>\n",
       "      <td>0.688905</td>\n",
       "      <td>0.818989</td>\n",
       "      <td>0.793555</td>\n",
       "      <td>0.189756</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.478522</td>\n",
       "      <td>0.688905</td>\n",
       "      <td>0.818989</td>\n",
       "      <td>0.793555</td>\n",
       "      <td>0.189615</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.490854</td>\n",
       "      <td>0.686918</td>\n",
       "      <td>0.813661</td>\n",
       "      <td>0.790544</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.026593</td>\n",
       "      <td>0.617814</td>\n",
       "      <td>0.697077</td>\n",
       "      <td>0.708357</td>\n",
       "      <td>0.027295</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.044884</td>\n",
       "      <td>0.717992</td>\n",
       "      <td>0.783304</td>\n",
       "      <td>0.788592</td>\n",
       "      <td>0.189756</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.418058</td>\n",
       "      <td>0.677327</td>\n",
       "      <td>0.815006</td>\n",
       "      <td>0.785884</td>\n",
       "      <td>0.194698</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.418058</td>\n",
       "      <td>0.677327</td>\n",
       "      <td>0.815006</td>\n",
       "      <td>0.785884</td>\n",
       "      <td>0.194523</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.428613</td>\n",
       "      <td>0.677591</td>\n",
       "      <td>0.810862</td>\n",
       "      <td>0.784353</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.026958</td>\n",
       "      <td>0.630578</td>\n",
       "      <td>0.707412</td>\n",
       "      <td>0.71735</td>\n",
       "      <td>0.026703</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.869701</td>\n",
       "      <td>0.710554</td>\n",
       "      <td>0.763766</td>\n",
       "      <td>0.774473</td>\n",
       "      <td>0.194698</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.471464</td>\n",
       "      <td>0.681046</td>\n",
       "      <td>0.815975</td>\n",
       "      <td>0.788295</td>\n",
       "      <td>0.194704</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.471464</td>\n",
       "      <td>0.681046</td>\n",
       "      <td>0.815975</td>\n",
       "      <td>0.788295</td>\n",
       "      <td>0.194569</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.575988</td>\n",
       "      <td>0.677846</td>\n",
       "      <td>0.810054</td>\n",
       "      <td>0.784539</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.05615</td>\n",
       "      <td>0.604148</td>\n",
       "      <td>0.684106</td>\n",
       "      <td>0.696123</td>\n",
       "      <td>0.02493</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.06757</td>\n",
       "      <td>0.680701</td>\n",
       "      <td>0.718661</td>\n",
       "      <td>0.737617</td>\n",
       "      <td>0.194704</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.416788</td>\n",
       "      <td>0.698531</td>\n",
       "      <td>0.81985</td>\n",
       "      <td>0.798471</td>\n",
       "      <td>0.196962</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.416788</td>\n",
       "      <td>0.698531</td>\n",
       "      <td>0.81985</td>\n",
       "      <td>0.798471</td>\n",
       "      <td>0.196808</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.470537</td>\n",
       "      <td>0.698199</td>\n",
       "      <td>0.814091</td>\n",
       "      <td>0.795932</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.00474</td>\n",
       "      <td>0.617107</td>\n",
       "      <td>0.671834</td>\n",
       "      <td>0.692754</td>\n",
       "      <td>0.027937</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.960401</td>\n",
       "      <td>0.716359</td>\n",
       "      <td>0.774907</td>\n",
       "      <td>0.783702</td>\n",
       "      <td>0.196962</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.430797</td>\n",
       "      <td>0.685291</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.792381</td>\n",
       "      <td>0.192816</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.430797</td>\n",
       "      <td>0.685291</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.792381</td>\n",
       "      <td>0.192703</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.463068</td>\n",
       "      <td>0.679971</td>\n",
       "      <td>0.811131</td>\n",
       "      <td>0.787257</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.946959</td>\n",
       "      <td>0.630409</td>\n",
       "      <td>0.705743</td>\n",
       "      <td>0.717787</td>\n",
       "      <td>0.027599</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.000098</td>\n",
       "      <td>0.677223</td>\n",
       "      <td>0.712902</td>\n",
       "      <td>0.733418</td>\n",
       "      <td>0.192816</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DI  f1 macro  f1 micro f1 weighted TV distance         method\n",
       "0   0.475461   0.68644  0.817751    0.792063    0.183889         origin\n",
       "1   0.475461   0.68644  0.817751    0.792063    0.183804  unconstrained\n",
       "2   0.523036  0.686234  0.811561    0.789457    0.000068     barycentre\n",
       "3   1.033796  0.620186  0.690995    0.705551    0.025841  partial_0.001\n",
       "4   1.037732  0.718886  0.776899     0.78536    0.183889            ROC\n",
       "5   0.476313  0.693666  0.822165    0.797155    0.188048         origin\n",
       "6   0.476313  0.693666  0.822165    0.797155    0.187894  unconstrained\n",
       "7   0.505581  0.692132   0.81689    0.794358    0.000037     barycentre\n",
       "8   1.034528  0.614992   0.69148    0.704503    0.025483  partial_0.001\n",
       "9    0.99929  0.720119  0.780074    0.787688    0.188048            ROC\n",
       "10  0.572486  0.694913  0.820012    0.797867    0.177917         origin\n",
       "11  0.572486  0.694913  0.820012    0.797867    0.177824  unconstrained\n",
       "12  0.656437  0.690917   0.81253    0.793089    0.000459     barycentre\n",
       "13  1.070007  0.619943  0.689865    0.705851    0.024637  partial_0.001\n",
       "14  1.091692  0.680888  0.719791    0.739606    0.177917            ROC\n",
       "15  0.500643  0.693356  0.816298    0.795135    0.190228         origin\n",
       "16  0.500643  0.693356  0.816298    0.795135    0.190099  unconstrained\n",
       "17  0.622277  0.689476  0.804672    0.788618    0.000126     barycentre\n",
       "18  1.021832  0.610178  0.686151    0.700388    0.025909  partial_0.001\n",
       "19  0.991517  0.684316  0.723505     0.74262    0.190228            ROC\n",
       "20  0.496236  0.690994  0.819581    0.793574    0.192912         origin\n",
       "21  0.496236  0.690994  0.819581    0.793574     0.19274  unconstrained\n",
       "22  0.535787  0.690479  0.812369    0.790435    0.000015     barycentre\n",
       "23  0.975459  0.640915  0.708865      0.7213    0.023983  partial_0.001\n",
       "24  1.060931   0.67504  0.707788    0.728127    0.192912            ROC\n",
       "25  0.478522  0.688905  0.818989    0.793555    0.189756         origin\n",
       "26  0.478522  0.688905  0.818989    0.793555    0.189615  unconstrained\n",
       "27  0.490854  0.686918  0.813661    0.790544    0.000597     barycentre\n",
       "28  1.026593  0.617814  0.697077    0.708357    0.027295  partial_0.001\n",
       "29  1.044884  0.717992  0.783304    0.788592    0.189756            ROC\n",
       "30  0.418058  0.677327  0.815006    0.785884    0.194698         origin\n",
       "31  0.418058  0.677327  0.815006    0.785884    0.194523  unconstrained\n",
       "32  0.428613  0.677591  0.810862    0.784353    0.000122     barycentre\n",
       "33  1.026958  0.630578  0.707412     0.71735    0.026703  partial_0.001\n",
       "34  0.869701  0.710554  0.763766    0.774473    0.194698            ROC\n",
       "35  0.471464  0.681046  0.815975    0.788295    0.194704         origin\n",
       "36  0.471464  0.681046  0.815975    0.788295    0.194569  unconstrained\n",
       "37  0.575988  0.677846  0.810054    0.784539    0.000003     barycentre\n",
       "38   1.05615  0.604148  0.684106    0.696123     0.02493  partial_0.001\n",
       "39   1.06757  0.680701  0.718661    0.737617    0.194704            ROC\n",
       "40  0.416788  0.698531   0.81985    0.798471    0.196962         origin\n",
       "41  0.416788  0.698531   0.81985    0.798471    0.196808  unconstrained\n",
       "42  0.470537  0.698199  0.814091    0.795932    0.000012     barycentre\n",
       "43   1.00474  0.617107  0.671834    0.692754    0.027937  partial_0.001\n",
       "44  0.960401  0.716359  0.774907    0.783702    0.196962            ROC\n",
       "45  0.430797  0.685291  0.818182    0.792381    0.192816         origin\n",
       "46  0.430797  0.685291  0.818182    0.792381    0.192703  unconstrained\n",
       "47  0.463068  0.679971  0.811131    0.787257    0.000019     barycentre\n",
       "48  0.946959  0.630409  0.705743    0.717787    0.027599  partial_0.001\n",
       "49  1.000098  0.677223  0.712902    0.733418    0.192816            ROC"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4  Compute average feature importance\n",
    "\n",
    "Finally, we will revisit our random-forest baseline to see which features drive the income prediction the most.\n",
    "\n",
    "This helps contextualize which attributes the model relies on - and which we may want to protect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance=[]\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "    clf=RandomForestClassifier(max_depth=5).fit(X_train[:,0:var_dim],y_train)\n",
    "    importance.append(list(clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features ['hours-per-week', 'age', 'capital-gain', 'capital-loss', 'education-num']\n",
      "mean importances [0.09313296 0.2046915  0.33826656 0.04915601 0.31475297]\n"
     ]
    }
   ],
   "source": [
    "importance=np.array(importance)\n",
    "print(\"features\", var_list)\n",
    "print(\"mean importances\", importance.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Conclusions\n",
    "\n",
    "Our **baseline** (origin/unconstrained) shows the best accuracy but also the biggest gap between protected groups. \n",
    "\n",
    "The **barycentre** method virtually erases that gap - but does so by flipping a lot of predictions, which could feel jarring in practice. \n",
    "\n",
    "With **partial repair**, you get a handy dial: small tweaks nudge toward parity with minimal impact, while larger tweaks tighten fairness at a greater cost. \n",
    "\n",
    "And **ROC post-processing** strikes a nice compromise, cutting disparity quite a bit while keeping f-scores close to where we started.\n",
    "\n",
    "Looking at feature importance reminds us what the model \"cares about\" most: **capital gain** and **education level** top the list, with **age** not far behind. If you’re worried about proxying sensitive traits, these are the variables to think hard about - either by guarding them or by designing even earlier interventions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
