{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "from aif360.datasets import BinaryLabelDataset, AdultDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "repo_root = os.path.dirname(os.getcwd())\n",
    "repair_folder = os.path.join(repo_root, \"humancompatible\", \"repair\")\n",
    "sys.path.insert(0, repair_folder)\n",
    "\n",
    "from cost import *\n",
    "from coupling_utils import *\n",
    "from data_analysis import *\n",
    "from group_blind_repair import *\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path=os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROCpostprocess:\n",
    "    def __init__(self,X_val,y_val,var_list,prediction_model,favorable_label):\n",
    "        self.X_val =X_val\n",
    "        self.y_val =y_val\n",
    "        self.model = prediction_model\n",
    "        self.positive_index = 1 # positive label\n",
    "        self.var_list = var_list\n",
    "        self.var_dim=len(self.var_list)\n",
    "        self.ROC = self.buildROCusingval()\n",
    "        self.favorable_label = favorable_label\n",
    "\n",
    "    def buildbinarydata(self,X,y):\n",
    "        df=pd.DataFrame(np.concatenate((X,y.reshape(-1,1)), axis=1),columns=self.var_list+['S','W','Y'])\n",
    "        binaryLabelDataset = BinaryLabelDataset(\n",
    "                            # favorable_label=self.favorable_label,\n",
    "                            # unfavorable_label=0,\n",
    "                            df=df[self.var_list+['S','W','Y']], #df_test.drop('X',axis=1), #[x_list+['S','W','Y']],\n",
    "                            label_names=['Y'],\n",
    "                            instance_weights_name=['W'],\n",
    "                            protected_attribute_names=['S'],\n",
    "                            privileged_protected_attributes=[np.array([1.0])],\n",
    "                            unprivileged_protected_attributes=[np.array([0.])])\n",
    "        return binaryLabelDataset,df\n",
    "\n",
    "    def buildROCusingval(self):\n",
    "        dataset_val = self.buildbinarydata(self.X_val,self.y_val)[0]\n",
    "        dataset_val_pred = dataset_val.copy(deepcopy=True)\n",
    "        dataset_val_pred.scores = self.model.predict_proba(dataset_val.features[:,0:self.var_dim])[:,self.positive_index].reshape(-1,1)\n",
    "        privileged_groups = [{'S': 1}]\n",
    "        unprivileged_groups = [{'S': 0}]\n",
    "        # Metric used (should be one of allowed_metrics)\n",
    "        metric_name = \"Statistical parity difference\"\n",
    "        # Upper and lower bound on the fairness metric used\n",
    "        metric_ub = 0.05\n",
    "        metric_lb = -0.05\n",
    "        ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                        privileged_groups=privileged_groups, \n",
    "                                        low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                        num_class_thresh=50, num_ROC_margin=10,\n",
    "                                        metric_name=metric_name,\n",
    "                                        metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "        ROC = ROC.fit(dataset_val, dataset_val_pred)\n",
    "        print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "        print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)\n",
    "        return ROC\n",
    "\n",
    "    def postprocess(self,X_test,y_test,tv_origin): # the tv distance won't change\n",
    "        dataset_test_pred,df_test = self.buildbinarydata(X_test,y_test) #.copy(deepcopy=True)\n",
    "        dataset_test_pred.scores = self.model.predict_proba(X_test[:,0:self.var_dim])[:,self.positive_index].reshape(-1,1)\n",
    "        dataset_test_pred_transf = self.ROC.predict(dataset_test_pred)\n",
    "        y_pred = dataset_test_pred_transf.labels\n",
    "        # return dataset_test_pred_transf.convert_to_dataframe()[0]\n",
    "\n",
    "        di = DisparateImpact_postprocess(df_test,y_pred,favorable_label=self.favorable_label)\n",
    "        f1_macro = f1_score(df_test['Y'], y_pred, average='macro',sample_weight=df_test['W'])\n",
    "        f1_micro = f1_score(df_test['Y'], y_pred, average='micro',sample_weight=df_test['W'])\n",
    "        f1_weighted = f1_score(df_test['Y'], y_pred, average='weighted',sample_weight=df_test['W'])\n",
    "        new_row=pd.Series({'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,\n",
    "                           'TV distance':tv_origin,'method':'ROC'})\n",
    "        return new_row.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projpostprocess:\n",
    "    \n",
    "    def __init__(self,X_test,y_test,x_list,var_list,prediction_model,K,e,thresh,favorable_label=1):\n",
    "        self.model = prediction_model\n",
    "        self.K=K\n",
    "        self.e=e\n",
    "        self.x_list=x_list\n",
    "        self.var_list=var_list\n",
    "        self.var_dim=len(var_list)\n",
    "        self.favorable_label = favorable_label\n",
    "\n",
    "        df_test=pd.DataFrame(np.concatenate((X_test,y_test.reshape(-1,1)), axis=1),columns=var_list+['S','W','Y'])\n",
    "        df_test=df_test.groupby(by=var_list+['S','Y'],as_index=False).sum()\n",
    "        if len(x_list)>1:\n",
    "            df_test['X'] = list(zip(*[df_test[c] for c in x_list]))\n",
    "            self.x_range=sorted(set(df_test['X']))\n",
    "            weight=list(1/(df_test[x_list].max()-df_test[x_list].min())) # because 'education-num' range from 1 to 16 while others 1 to 4\n",
    "            self.C=c_generate_higher(self.x_range,weight)\n",
    "        else:\n",
    "            df_test['X']=df_test[x_list]\n",
    "            self.x_range=sorted(set(df_test['X']))\n",
    "            self.C=c_generate(self.x_range)\n",
    "        self.df_test = df_test\n",
    "        self.var_range=list(pd.pivot_table(df_test,index=var_list,values=['S','W','Y']).index)\n",
    "        self.distribution_generator()\n",
    "        \n",
    "        if thresh == 'auto':\n",
    "            self.thresh_generator()\n",
    "        else:\n",
    "            self.thresh=thresh\n",
    "\n",
    "    def distribution_generator(self):\n",
    "        bin=len(self.x_range)\n",
    "        dist=rdata_analysis(self.df_test,self.x_range,'X')\n",
    "        \n",
    "        dist['v']=[(dist['x_0'][i]-dist['x_1'][i])/dist['x'][i] for i in range(bin)]\n",
    "        \n",
    "        dist['t_x']=dist['x'] # #dist['x'] #dist['x_0']*0.5+dist['x_1']*0.5 \n",
    "        self.px=np.matrix(dist['x']).T\n",
    "        self.ptx=np.matrix(dist['t_x']).T\n",
    "        if np.any(dist['x_0']==0): \n",
    "            self.p0=np.matrix((dist['x_0']+1.0e-9)/sum(dist['x_0']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p0=np.matrix(dist['x_0']).T \n",
    "        if np.any(dist['x_1']==0):\n",
    "            self.p1=np.matrix((dist['x_1']+1.0e-9)/sum(dist['x_1']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p1=np.matrix(dist['x_1']).T \n",
    "        self.V=np.matrix(dist['v']).T\n",
    "        self.tv_origin=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "        # return px,ptx,V,p0,p1\n",
    "    \n",
    "    def coupling_generator(self,method,para=None):\n",
    "        if method == 'unconstrained':\n",
    "            coupling=baseline(self.C,self.e,self.px,self.ptx,self.K)\n",
    "        elif method == 'barycentre':\n",
    "            coupling=baseline(self.C,self.e,self.p0,self.p1,self.K)\n",
    "        elif method == 'partial':\n",
    "            coupling=partial_repair(self.C,self.e,self.px,self.ptx,self.V,para,self.K)\n",
    "        return coupling\n",
    "\n",
    "    def postprocess(self,method,para=None):\n",
    "        if method == 'origin':\n",
    "            y_pred=self.model.predict(np.array(self.df_test[self.var_list]))\n",
    "            tv = self.tv_origin\n",
    "        else:\n",
    "            coupling = self.coupling_generator(method,para)\n",
    "            if (method == 'unconstrained') or (method == 'partial'):\n",
    "                y_pred=postprocess(self.df_test,coupling,self.x_list,self.x_range,self.var_list,self.var_range,self.model,self.thresh)\n",
    "                tv=assess_tv(self.df_test,coupling,self.x_range,self.x_list,self.var_list)\n",
    "                if (para != None) and (method == 'partial'):\n",
    "                    method = method+'_'+str(para)\n",
    "            elif method == 'barycentre':\n",
    "                y_pred,tv=postprocess_bary(self.df_test,coupling,self.x_list,self.x_range,self.var_list,self.var_range,self.model,self.thresh)\n",
    "            else:\n",
    "                print('Unknown method')\n",
    "\n",
    "        di = DisparateImpact_postprocess(self.df_test,y_pred,favorable_label=self.favorable_label)\n",
    "        f1_macro = f1_score(self.df_test['Y'], y_pred, average='macro',sample_weight=self.df_test['W'])\n",
    "        f1_micro = f1_score(self.df_test['Y'], y_pred, average='micro',sample_weight=self.df_test['W'])\n",
    "        f1_weighted = f1_score(self.df_test['Y'], y_pred, average='weighted',sample_weight=self.df_test['W'])\n",
    "\n",
    "        new_row=pd.Series({'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,\n",
    "                           'TV distance':tv,'method':method})\n",
    "        return new_row.to_frame().T\n",
    "    \n",
    "    def thresh_generator(self):\n",
    "        num_thresh = 10\n",
    "        ba_arr = np.zeros(num_thresh)\n",
    "        ba_arr1 = np.zeros(num_thresh)\n",
    "        class_thresh_arr = np.linspace(0.01, 0.1, num_thresh)\n",
    "        coupling=self.coupling_generator('partial',para=1e-2)\n",
    "    \n",
    "        for idx, thresh in enumerate(class_thresh_arr):\n",
    "            y_pred=postprocess(self.df_test,coupling,self.x_list,self.x_range,self.var_list,self.var_range,self.model,thresh)\n",
    "            ba_arr[idx] = DisparateImpact_postprocess(self.df_test,y_pred,favorable_label=self.favorable_label)\n",
    "            ba_arr1[idx] = f1_score(self.df_test['Y'], y_pred, average='macro',sample_weight=self.df_test['W'])\n",
    "\n",
    "        best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "        best_thresh = class_thresh_arr[best_ind]\n",
    "        print(\"Optional threshold = \",class_thresh_arr)\n",
    "        print(\"Disparate Impact = \",ba_arr)\n",
    "        print(\"f1 scores = \",ba_arr1)\n",
    "        self.thresh = best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path,var_list,pa):\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education',\n",
    "                'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "                'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                'native-country', 'Y']\n",
    "    na_values=['?']\n",
    "    pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "    label_dict={'>50K.':1,'>50K':1,'<=50K.':0,'<=50K':0}\n",
    "    train_path = os.path.join(data_path, 'adult.data')\n",
    "    test_path = os.path.join(data_path, 'adult.test')\n",
    "    train = pd.read_csv(train_path, header=None,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    test = pd.read_csv(test_path, header=0,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    messydata = pd.concat([test, train], ignore_index=True)[var_list+[pa,'Y']]\n",
    "    messydata=messydata.rename(columns={pa:'S'})\n",
    "    messydata['S']=messydata['S'].replace(pa_dict)\n",
    "    messydata['Y']=messydata['Y'].replace(label_dict)\n",
    "    messydata=messydata[(messydata['S']==0)|(messydata['S']==1)]\n",
    "    for col in var_list+['S','Y']:\n",
    "        messydata[col]=messydata[col].astype('int64')\n",
    "    messydata['W']=1\n",
    "    bins_capitalgain=[100,3500,7500,10000]\n",
    "    bins_capitalloss=[100,1600,1900,2200]\n",
    "    bins_age=[26,36,46,56]\n",
    "    bins_hours=[21,36,46,61]\n",
    "\n",
    "    messydata=categerise(messydata,'age',bins_age)\n",
    "    messydata=categerise(messydata,'hours-per-week',bins_hours)\n",
    "    messydata=categerise(messydata,'capital-gain',bins_capitalgain)\n",
    "    messydata=categerise(messydata,'capital-loss',bins_capitalloss)\n",
    "    \n",
    "    return messydata\n",
    "\n",
    "def categerise(df,col,bins):\n",
    "    for i in range(len(bins)+1):\n",
    "        if i == 0:\n",
    "            df.loc[df[col] < bins[i], col] = i\n",
    "        elif i == len(bins):\n",
    "            df.loc[df[col] >= bins[i-1], col] = i\n",
    "        else:\n",
    "            df.loc[(df[col] >= bins[i-1])& (df[col] < bins[i]), col] = i        \n",
    "    return df\n",
    "\n",
    "def choose_x(var_list,messydata):\n",
    "    tv_dist=dict()\n",
    "    for x_name in var_list:\n",
    "        x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "        dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "        tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    x_list=[]\n",
    "    for key,val in tv_dist.items():\n",
    "        if val>0.1:\n",
    "            x_list+=[key]  \n",
    "    return x_list,tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='C://personal//work//repair//.venv//Lib//site-packages//aif360//data//raw//adult'\n",
    "\n",
    "var_list=['hours-per-week','age','capital-gain','capital-loss','education-num'] #\n",
    "pa='race'\n",
    "favorable_label = 1\n",
    "var_dim=len(var_list)\n",
    "\n",
    "K=200\n",
    "e=0.01\n",
    "\n",
    "if pa == 'sex':\n",
    "    thresh=0.05\n",
    "elif pa == 'race':\n",
    "    thresh=0.05\n",
    "\n",
    "messydata = load_data(data_path,var_list,pa)\n",
    "x_list,tv_dist = choose_x(var_list,messydata)\n",
    "\n",
    "X=messydata[var_list+['S','W']].to_numpy() # [X,S,W]\n",
    "y=messydata['Y'].to_numpy() #[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hours-per-week': np.float64(0.12216173195089294),\n",
       " 'age': np.float64(0.04149230147335384),\n",
       " 'capital-gain': np.float64(0.026764553949230142),\n",
       " 'capital-loss': np.float64(0.014217783478743178),\n",
       " 'education-num': np.float64(0.11867963282506956)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m projpost = Projpostprocess(X_test,y_test,x_list,var_list,clf,K,e,thresh,favorable_label)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m methods[:-\u001b[32m1\u001b[39m]:\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# report = pd.concat([report,projpost.postprocess(method,para=1e-2)], ignore_index=True)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     report = pd.concat([report,\u001b[43mprojpost\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     14\u001b[39m ROCpost = ROCpostprocess(X_val,y_val,var_list,clf,favorable_label) \u001b[38;5;66;03m# use validation set to train a ROC model\u001b[39;00m\n\u001b[32m     15\u001b[39m report = pd.concat([report,ROCpost.postprocess(X_test,y_test,tv_origin=projpost.tv_origin)], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mProjpostprocess.postprocess\u001b[39m\u001b[34m(self, method, para)\u001b[39m\n\u001b[32m     65\u001b[39m     tv = \u001b[38;5;28mself\u001b[39m.tv_origin\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     coupling = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcoupling_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (method == \u001b[33m'\u001b[39m\u001b[33munconstrained\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (method == \u001b[33m'\u001b[39m\u001b[33mpartial\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     69\u001b[39m         y_pred=postprocess(\u001b[38;5;28mself\u001b[39m.df_test,coupling,\u001b[38;5;28mself\u001b[39m.x_list,\u001b[38;5;28mself\u001b[39m.x_range,\u001b[38;5;28mself\u001b[39m.var_list,\u001b[38;5;28mself\u001b[39m.var_range,\u001b[38;5;28mself\u001b[39m.model,\u001b[38;5;28mself\u001b[39m.thresh)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mProjpostprocess.coupling_generator\u001b[39m\u001b[34m(self, method, para)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcoupling_generator\u001b[39m(\u001b[38;5;28mself\u001b[39m,method,para=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33munconstrained\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m         coupling=\u001b[43mbaseline\u001b[49m(\u001b[38;5;28mself\u001b[39m.C,\u001b[38;5;28mself\u001b[39m.e,\u001b[38;5;28mself\u001b[39m.px,\u001b[38;5;28mself\u001b[39m.ptx,\u001b[38;5;28mself\u001b[39m.K)\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33mbarycentre\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     57\u001b[39m         coupling=baseline(\u001b[38;5;28mself\u001b[39m.C,\u001b[38;5;28mself\u001b[39m.e,\u001b[38;5;28mself\u001b[39m.p0,\u001b[38;5;28mself\u001b[39m.p1,\u001b[38;5;28mself\u001b[39m.K)\n",
      "\u001b[31mNameError\u001b[39m: name 'baseline' is not defined"
     ]
    }
   ],
   "source": [
    "methods=['origin','unconstrained','barycentre','partial','ROC'] # Place ROC in the end\n",
    "report=pd.DataFrame(columns=['DI','f1 macro','f1 micro','f1 weighted','TV distance','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "    clf=RandomForestClassifier(max_depth=5).fit(X_train[:,0:var_dim],y_train)\n",
    "    projpost = Projpostprocess(X_test,y_test,x_list,var_list,clf,K,e,thresh,favorable_label)\n",
    "    for method in methods[:-1]:\n",
    "        # report = pd.concat([report,projpost.postprocess(method,para=1e-2)], ignore_index=True)\n",
    "        report = pd.concat([report,projpost.postprocess(method,para=1e-3)], ignore_index=True)\n",
    "\n",
    "    ROCpost = ROCpostprocess(X_val,y_val,var_list,clf,favorable_label) # use validation set to train a ROC model\n",
    "    report = pd.concat([report,ROCpost.postprocess(X_test,y_test,tv_origin=projpost.tv_origin)], ignore_index=True)\n",
    "\n",
    "report.to_csv(path+'/data/report_postprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>TV distance</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.45499</td>\n",
       "      <td>0.672327</td>\n",
       "      <td>0.81436</td>\n",
       "      <td>0.785157</td>\n",
       "      <td>0.19857</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.45499</td>\n",
       "      <td>0.672327</td>\n",
       "      <td>0.81436</td>\n",
       "      <td>0.785157</td>\n",
       "      <td>0.198444</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.579056</td>\n",
       "      <td>0.671156</td>\n",
       "      <td>0.809947</td>\n",
       "      <td>0.78289</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.936146</td>\n",
       "      <td>0.636093</td>\n",
       "      <td>0.710641</td>\n",
       "      <td>0.722237</td>\n",
       "      <td>0.025519</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.992225</td>\n",
       "      <td>0.629455</td>\n",
       "      <td>0.648636</td>\n",
       "      <td>0.673547</td>\n",
       "      <td>0.19857</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.442332</td>\n",
       "      <td>0.679638</td>\n",
       "      <td>0.817913</td>\n",
       "      <td>0.789218</td>\n",
       "      <td>0.17519</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.442332</td>\n",
       "      <td>0.679638</td>\n",
       "      <td>0.817913</td>\n",
       "      <td>0.789218</td>\n",
       "      <td>0.175089</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.446741</td>\n",
       "      <td>0.67798</td>\n",
       "      <td>0.813553</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.908634</td>\n",
       "      <td>0.637094</td>\n",
       "      <td>0.711933</td>\n",
       "      <td>0.722896</td>\n",
       "      <td>0.025059</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.886741</td>\n",
       "      <td>0.704938</td>\n",
       "      <td>0.756015</td>\n",
       "      <td>0.768854</td>\n",
       "      <td>0.17519</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.485849</td>\n",
       "      <td>0.700419</td>\n",
       "      <td>0.819043</td>\n",
       "      <td>0.796802</td>\n",
       "      <td>0.208107</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.485849</td>\n",
       "      <td>0.700419</td>\n",
       "      <td>0.819043</td>\n",
       "      <td>0.796802</td>\n",
       "      <td>0.208001</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.534043</td>\n",
       "      <td>0.697245</td>\n",
       "      <td>0.811292</td>\n",
       "      <td>0.792249</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.063127</td>\n",
       "      <td>0.619568</td>\n",
       "      <td>0.685236</td>\n",
       "      <td>0.700379</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.992617</td>\n",
       "      <td>0.722927</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.787746</td>\n",
       "      <td>0.208107</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.391761</td>\n",
       "      <td>0.682322</td>\n",
       "      <td>0.818989</td>\n",
       "      <td>0.791164</td>\n",
       "      <td>0.195031</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.391761</td>\n",
       "      <td>0.682322</td>\n",
       "      <td>0.818989</td>\n",
       "      <td>0.791164</td>\n",
       "      <td>0.194886</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.436101</td>\n",
       "      <td>0.680668</td>\n",
       "      <td>0.812799</td>\n",
       "      <td>0.787967</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.031515</td>\n",
       "      <td>0.620322</td>\n",
       "      <td>0.698638</td>\n",
       "      <td>0.710398</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.787188</td>\n",
       "      <td>0.726558</td>\n",
       "      <td>0.796867</td>\n",
       "      <td>0.798987</td>\n",
       "      <td>0.195031</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.510502</td>\n",
       "      <td>0.69581</td>\n",
       "      <td>0.818828</td>\n",
       "      <td>0.795297</td>\n",
       "      <td>0.186881</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.510502</td>\n",
       "      <td>0.69581</td>\n",
       "      <td>0.818828</td>\n",
       "      <td>0.795297</td>\n",
       "      <td>0.186711</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.579339</td>\n",
       "      <td>0.692618</td>\n",
       "      <td>0.811454</td>\n",
       "      <td>0.790911</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.07643</td>\n",
       "      <td>0.627937</td>\n",
       "      <td>0.696216</td>\n",
       "      <td>0.709908</td>\n",
       "      <td>0.026251</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.024714</td>\n",
       "      <td>0.676036</td>\n",
       "      <td>0.71048</td>\n",
       "      <td>0.730362</td>\n",
       "      <td>0.186881</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.540068</td>\n",
       "      <td>0.677477</td>\n",
       "      <td>0.81689</td>\n",
       "      <td>0.788266</td>\n",
       "      <td>0.185251</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.540068</td>\n",
       "      <td>0.677477</td>\n",
       "      <td>0.81689</td>\n",
       "      <td>0.788266</td>\n",
       "      <td>0.185138</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.525316</td>\n",
       "      <td>0.676043</td>\n",
       "      <td>0.812476</td>\n",
       "      <td>0.785885</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.997878</td>\n",
       "      <td>0.629657</td>\n",
       "      <td>0.731148</td>\n",
       "      <td>0.73095</td>\n",
       "      <td>0.027169</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.930811</td>\n",
       "      <td>0.647434</td>\n",
       "      <td>0.672856</td>\n",
       "      <td>0.696898</td>\n",
       "      <td>0.185251</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.476957</td>\n",
       "      <td>0.681043</td>\n",
       "      <td>0.818666</td>\n",
       "      <td>0.791004</td>\n",
       "      <td>0.206801</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.476957</td>\n",
       "      <td>0.681043</td>\n",
       "      <td>0.818666</td>\n",
       "      <td>0.791004</td>\n",
       "      <td>0.206571</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.49389</td>\n",
       "      <td>0.681092</td>\n",
       "      <td>0.813822</td>\n",
       "      <td>0.789072</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.069447</td>\n",
       "      <td>0.624121</td>\n",
       "      <td>0.696593</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.025844</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.907942</td>\n",
       "      <td>0.715803</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>0.783762</td>\n",
       "      <td>0.206801</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.480408</td>\n",
       "      <td>0.695913</td>\n",
       "      <td>0.822918</td>\n",
       "      <td>0.798823</td>\n",
       "      <td>0.199606</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.480408</td>\n",
       "      <td>0.695913</td>\n",
       "      <td>0.822918</td>\n",
       "      <td>0.798823</td>\n",
       "      <td>0.199439</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.516306</td>\n",
       "      <td>0.691873</td>\n",
       "      <td>0.816083</td>\n",
       "      <td>0.794318</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.990432</td>\n",
       "      <td>0.6393</td>\n",
       "      <td>0.709941</td>\n",
       "      <td>0.722889</td>\n",
       "      <td>0.026036</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.007093</td>\n",
       "      <td>0.624587</td>\n",
       "      <td>0.643845</td>\n",
       "      <td>0.669112</td>\n",
       "      <td>0.199606</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.47055</td>\n",
       "      <td>0.680659</td>\n",
       "      <td>0.815975</td>\n",
       "      <td>0.788238</td>\n",
       "      <td>0.191661</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.47055</td>\n",
       "      <td>0.680659</td>\n",
       "      <td>0.815975</td>\n",
       "      <td>0.788238</td>\n",
       "      <td>0.19148</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.454722</td>\n",
       "      <td>0.678523</td>\n",
       "      <td>0.810431</td>\n",
       "      <td>0.785094</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.022877</td>\n",
       "      <td>0.627403</td>\n",
       "      <td>0.697562</td>\n",
       "      <td>0.711077</td>\n",
       "      <td>0.026003</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.05082</td>\n",
       "      <td>0.686927</td>\n",
       "      <td>0.724205</td>\n",
       "      <td>0.742835</td>\n",
       "      <td>0.191661</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.483415</td>\n",
       "      <td>0.681953</td>\n",
       "      <td>0.816944</td>\n",
       "      <td>0.789564</td>\n",
       "      <td>0.185007</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.483415</td>\n",
       "      <td>0.681953</td>\n",
       "      <td>0.816944</td>\n",
       "      <td>0.789564</td>\n",
       "      <td>0.184871</td>\n",
       "      <td>unconstrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.513153</td>\n",
       "      <td>0.680369</td>\n",
       "      <td>0.811454</td>\n",
       "      <td>0.786676</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.047013</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.698423</td>\n",
       "      <td>0.710424</td>\n",
       "      <td>0.025435</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.891762</td>\n",
       "      <td>0.723387</td>\n",
       "      <td>0.800743</td>\n",
       "      <td>0.799357</td>\n",
       "      <td>0.185007</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DI  f1 macro  f1 micro f1 weighted TV distance         method\n",
       "0    0.45499  0.672327   0.81436    0.785157     0.19857         origin\n",
       "1    0.45499  0.672327   0.81436    0.785157    0.198444  unconstrained\n",
       "2   0.579056  0.671156  0.809947     0.78289    0.000055     barycentre\n",
       "3   0.936146  0.636093  0.710641    0.722237    0.025519  partial_0.001\n",
       "4   0.992225  0.629455  0.648636    0.673547     0.19857            ROC\n",
       "5   0.442332  0.679638  0.817913    0.789218     0.17519         origin\n",
       "6   0.442332  0.679638  0.817913    0.789218    0.175089  unconstrained\n",
       "7   0.446741   0.67798  0.813553    0.786765    0.000046     barycentre\n",
       "8   0.908634  0.637094  0.711933    0.722896    0.025059  partial_0.001\n",
       "9   0.886741  0.704938  0.756015    0.768854     0.17519            ROC\n",
       "10  0.485849  0.700419  0.819043    0.796802    0.208107         origin\n",
       "11  0.485849  0.700419  0.819043    0.796802    0.208001  unconstrained\n",
       "12  0.534043  0.697245  0.811292    0.792249    0.000001     barycentre\n",
       "13  1.063127  0.619568  0.685236    0.700379    0.027778  partial_0.001\n",
       "14  0.992617  0.722927  0.780935    0.787746    0.208107            ROC\n",
       "15  0.391761  0.682322  0.818989    0.791164    0.195031         origin\n",
       "16  0.391761  0.682322  0.818989    0.791164    0.194886  unconstrained\n",
       "17  0.436101  0.680668  0.812799    0.787967    0.000016     barycentre\n",
       "18  1.031515  0.620322  0.698638    0.710398    0.028413  partial_0.001\n",
       "19  0.787188  0.726558  0.796867    0.798987    0.195031            ROC\n",
       "20  0.510502   0.69581  0.818828    0.795297    0.186881         origin\n",
       "21  0.510502   0.69581  0.818828    0.795297    0.186711  unconstrained\n",
       "22  0.579339  0.692618  0.811454    0.790911    0.000274     barycentre\n",
       "23   1.07643  0.627937  0.696216    0.709908    0.026251  partial_0.001\n",
       "24  1.024714  0.676036   0.71048    0.730362    0.186881            ROC\n",
       "25  0.540068  0.677477   0.81689    0.788266    0.185251         origin\n",
       "26  0.540068  0.677477   0.81689    0.788266    0.185138  unconstrained\n",
       "27  0.525316  0.676043  0.812476    0.785885    0.000008     barycentre\n",
       "28  0.997878  0.629657  0.731148     0.73095    0.027169  partial_0.001\n",
       "29  0.930811  0.647434  0.672856    0.696898    0.185251            ROC\n",
       "30  0.476957  0.681043  0.818666    0.791004    0.206801         origin\n",
       "31  0.476957  0.681043  0.818666    0.791004    0.206571  unconstrained\n",
       "32   0.49389  0.681092  0.813822    0.789072    0.000005     barycentre\n",
       "33  1.069447  0.624121  0.696593    0.710744    0.025844  partial_0.001\n",
       "34  0.907942  0.715803    0.7748    0.783762    0.206801            ROC\n",
       "35  0.480408  0.695913  0.822918    0.798823    0.199606         origin\n",
       "36  0.480408  0.695913  0.822918    0.798823    0.199439  unconstrained\n",
       "37  0.516306  0.691873  0.816083    0.794318    0.000034     barycentre\n",
       "38  0.990432    0.6393  0.709941    0.722889    0.026036  partial_0.001\n",
       "39  1.007093  0.624587  0.643845    0.669112    0.199606            ROC\n",
       "40   0.47055  0.680659  0.815975    0.788238    0.191661         origin\n",
       "41   0.47055  0.680659  0.815975    0.788238     0.19148  unconstrained\n",
       "42  0.454722  0.678523  0.810431    0.785094    0.000068     barycentre\n",
       "43  1.022877  0.627403  0.697562    0.711077    0.026003  partial_0.001\n",
       "44   1.05082  0.686927  0.724205    0.742835    0.191661            ROC\n",
       "45  0.483415  0.681953  0.816944    0.789564    0.185007         origin\n",
       "46  0.483415  0.681953  0.816944    0.789564    0.184871  unconstrained\n",
       "47  0.513153  0.680369  0.811454    0.786676    0.000008     barycentre\n",
       "48  1.047013    0.6225  0.698423    0.710424    0.025435  partial_0.001\n",
       "49  0.891762  0.723387  0.800743    0.799357    0.185007            ROC"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute average feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance=[]\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "    clf=RandomForestClassifier(max_depth=5).fit(X_train[:,0:var_dim],y_train)\n",
    "    importance.append(list(clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features ['hours-per-week', 'age', 'capital-gain', 'capital-loss', 'education-num']\n",
      "mean importances [0.09746381 0.20263391 0.3359696  0.04851905 0.31541363]\n"
     ]
    }
   ],
   "source": [
    "importance=np.array(importance)\n",
    "print(\"features\", var_list)\n",
    "print(\"mean importances\", importance.mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
