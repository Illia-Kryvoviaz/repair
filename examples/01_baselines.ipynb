{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover,Reweighing,LFR\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from aif360.datasets import CompasDataset, AdultDataset\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# TODO: change the import method\n",
    "import sys\n",
    "import os\n",
    "repo_root = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, repo_root)\n",
    "repair_folder = os.path.join(repo_root, \"humancompatible\", \"repair\")\n",
    "sys.path.insert(0, repair_folder)\n",
    "from humancompatible.repair.cost import *\n",
    "from humancompatible.repair.coupling_utils import *\n",
    "from humancompatible.repair.data_analysis import *\n",
    "from humancompatible.repair.group_blind_repair import *\n",
    "from humancompatible.repair.metrics import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "path=os.path.dirname(os.getcwd())\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# if you need \"OptimPreproc\"\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projpreprocess:\n",
    "    \n",
    "    def __init__(self,traindata,x_list,var_list,K,e):\n",
    "\n",
    "        self.K=K\n",
    "        self.e=e\n",
    "        self.x_list=x_list\n",
    "        self.var_list=var_list\n",
    "      \n",
    "        self.var_dim=len(var_list)\n",
    "        self.arg_list=[elem for elem in var_list if elem not in x_list]\n",
    "        self.train = traindata.copy()\n",
    "        self.df = self.train.convert_to_dataframe()[0]\n",
    "        self.pa = self.train.protected_attribute_names[0]\n",
    "        self.pa_index = self.train.feature_names.index(pa)\n",
    "        self.label_name = self.train.label_names[0]\n",
    "        self.df=self.df.rename(columns={self.pa:'S',self.label_name:'Y'})\n",
    "\n",
    "        self.df['W'] = self.train.instance_weights\n",
    "        for col in self.var_list+['S','Y']:\n",
    "            self.df[col]=self.df[col].astype('int64')\n",
    "        self.df=self.df[var_list+['S','W','Y']]\n",
    "        if len(x_list)>1:\n",
    "            self.df['X'] = list(zip(*[self.df[c] for c in x_list]))\n",
    "            self.x_range=sorted(set(self.df['X']))\n",
    "            weight=list(1/(self.df[x_list].max()-self.df[x_list].min())) # because ranges of attributes differ\n",
    "            self.C=c_generate_higher(self.x_range,weight)\n",
    "        else:\n",
    "            self.df['X']=self.df[x_list]\n",
    "            self.x_range=sorted(set(self.df['X']))\n",
    "            self.C=c_generate(self.x_range)\n",
    "        self.df = self.df[self.arg_list+['X','S','Y','W']].groupby(by=self.arg_list+['X','S','Y'],as_index=False).sum()\n",
    "        self.distribution_generator()\n",
    "        \n",
    "    def distribution_generator(self):\n",
    "        bin=len(self.x_range)\n",
    "        dist=rdata_analysis(self.df,self.x_range,'X')\n",
    "        dist['v']=[(dist['x_0'][i]-dist['x_1'][i])/dist['x'][i] for i in range(bin)]\n",
    "        dist['t_x']=dist['x'] # #dist['x'] #dist['x_0']*0.5+dist['x_1']*0.5 \n",
    "        self.px=np.matrix(dist['x']).T\n",
    "        self.ptx=np.matrix(dist['t_x']).T\n",
    "        if np.any(dist['x_0']==0): \n",
    "            self.p0=np.matrix((dist['x_0']+1.0e-9)/sum(dist['x_0']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p0=np.matrix(dist['x_0']).T \n",
    "        if np.any(dist['x_1']==0):\n",
    "            self.p1=np.matrix((dist['x_1']+1.0e-9)/sum(dist['x_1']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p1=np.matrix(dist['x_1']).T \n",
    "        self.V=np.matrix(dist['v']).T\n",
    "        # self.tv_origin=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "        # return px,ptx,V,p0,p1\n",
    "    \n",
    "    def coupling_generator(self,method,Theta=1e-2):\n",
    "        print(Theta)\n",
    "        if method == 'unconstrained':\n",
    "            coupling=baseline(self.C,self.e,self.px,self.ptx,self.K)\n",
    "        elif method == 'barycentre':\n",
    "            coupling=baseline(self.C,self.e,self.p0,self.p1,self.K)\n",
    "        elif method == 'partial':\n",
    "            coupling=partial_repair(self.C,self.e,self.px,self.ptx,self.V,Theta,self.K)\n",
    "        return coupling\n",
    "\n",
    "    def preprocess(self,method,Theta=1e-2):\n",
    "        coupling = self.coupling_generator(method,Theta)\n",
    "        if len(self.x_list)>1:\n",
    "            df_proj=projection_higher(self.df,coupling,self.x_range,self.x_list,self.var_list)\n",
    "        else:\n",
    "            df_proj=projection(self.df,coupling,self.x_range,self.x_list[0],self.var_list)\n",
    "        df_proj = df_proj.groupby(by=self.arg_list+['X','S','Y'],as_index=False).sum()\n",
    "        X=list(zip(*df_proj['X']))\n",
    "        df_proj = df_proj.assign(**{self.x_list[i]:X[i] for i in range(len(self.x_list))})\n",
    "        df_proj=df_proj.drop('X',axis=1)\n",
    "        df_proj=df_proj.rename(columns={'S':self.pa,'Y':self.label_name})\n",
    "        binaryLabelDataset = BinaryLabelDataset(\n",
    "            favorable_label=0,\n",
    "            unfavorable_label=1,\n",
    "            df=df_proj.drop('W',axis=1), \n",
    "            label_names=self.train.label_names,\n",
    "            protected_attribute_names=self.train.protected_attribute_names,\n",
    "            privileged_protected_attributes=[np.array([1.0])],unprivileged_protected_attributes=[np.array([0.])])\n",
    "        binaryLabelDataset.instance_weights = df_proj['W'].tolist()\n",
    "        # return binaryLabelDataset.align_datasets(self.train)\n",
    "        return self.train.align_datasets(binaryLabelDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baselinepreprocess:\n",
    "\n",
    "    def __init__(self,train,test):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.pa = train.protected_attribute_names[0]\n",
    "        self.pa_index = train.feature_names.index(pa)\n",
    "        self.prigroups = [{self.pa: 1}]\n",
    "        self.unprigroups = [{self.pa: 0}]\n",
    "\n",
    "    def preprocessing(self,method):\n",
    "        test_tranf = self.test.copy()\n",
    "        if method == 'RW':\n",
    "            RW = Reweighing(privileged_groups = self.prigroups,unprivileged_groups = self.unprigroups) #DisparateImpactRemover(repair_level = 1)\n",
    "            RW.fit(self.train)\n",
    "            train_tranf = RW.transform(self.train)\n",
    "        elif method == 'DIremover':\n",
    "            di = DisparateImpactRemover(repair_level = 1,sensitive_attribute=pa)\n",
    "            train_tranf = di.fit_transform(self.train)\n",
    "            test_tranf = di.fit_transform(self.test)\n",
    "        elif method == 'LFR':\n",
    "            TR = LFR(privileged_groups = self.prigroups,unprivileged_groups = self.unprigroups,\n",
    "                     Az = 1, Ax = 0.01, Ay = 1,verbose=0)\n",
    "            TR = TR.fit(self.train)\n",
    "            train_tranf = TR.transform(self.train)\n",
    "            test_tranf = TR.transform(self.test)\n",
    "        elif method == 'OP':\n",
    "            optim_options = {\n",
    "                \"distortion_fun\": get_distortion_adult,\n",
    "                \"epsilon\": 0.05,\n",
    "                \"clist\": [0.99, 1.99, 2.99],\n",
    "                \"dlist\": [.1, 0.05, 0]\n",
    "            }\n",
    "            OP = OptimPreproc(OptTools, optim_options)\n",
    "            OP = OP.fit(self.train)\n",
    "            train_tranf = OP.transform(self.train, transform_Y=True)\n",
    "        return train_tranf, test_tranf\n",
    "\n",
    "    def prediction(self,method,para=None):\n",
    "        test_tranf = self.test.copy()\n",
    "        if method == 'origin':\n",
    "            train_tranf = self.train\n",
    "        elif method in ['RW','DIremover','LFR','OP']:\n",
    "            train_tranf,test_tranf = self.preprocessing(method)\n",
    "        else:\n",
    "            K=200\n",
    "            e=0.01\n",
    "            var_list=self.train.feature_names.copy()\n",
    "            var_list.remove(self.pa)\n",
    "            projpre=Projpreprocess(self.train,para['x_list'],var_list,K,e)\n",
    "            train_tranf=projpre.preprocess(method,para['Theta'])\n",
    "\n",
    "        di=self.DisparateImpact(train_tranf)\n",
    "        print('Disparate Impact of train',di)\n",
    "\n",
    "        if method != 'LFR':\n",
    "            X_train = np.delete(train_tranf.features, self.pa_index, axis=1)\n",
    "            y_train = train_tranf.labels.ravel()\n",
    "            weight_train = train_tranf.instance_weights\n",
    "            model=RandomForestClassifier(max_depth=5).fit(X_train,y_train, sample_weight=weight_train)\n",
    "\n",
    "            X_test = np.delete(test_tranf.features, self.pa_index, axis=1)\n",
    "            y_pred = model.predict(X_test)\n",
    "        else:\n",
    "            y_pred = test_tranf.labels\n",
    "        return y_pred,di\n",
    "    \n",
    "    def DisparateImpact(self,data):\n",
    "        di = pd.DataFrame({'S':data.protected_attributes.ravel().tolist(),\n",
    "            'Y':data.labels.ravel().tolist(),\n",
    "            'W':list(data.instance_weights)},columns=['S','Y','W'])\n",
    "        privileged = self.train.privileged_protected_attributes[0][0]\n",
    "        unprivileged = self.train.unprivileged_protected_attributes[0][0]\n",
    "        numerator=sum(di[(di['S']==unprivileged)&(di['Y']==data.favorable_label)]['W'])/sum(di[di['S']==unprivileged]['W'])\n",
    "        denominator=sum(di[(di['S']==privileged)&(di['Y']==data.favorable_label)]['W'])/sum(di[di['S']==privileged]['W'])\n",
    "        if numerator==denominator:\n",
    "            return 1\n",
    "        return numerator/denominator\n",
    "\n",
    "    def assess(self,method,para=None):\n",
    "        if para != None:\n",
    "            y_pred,di_train = self.prediction(method,para)\n",
    "        else:\n",
    "            y_pred,di_train = self.prediction(method)\n",
    "        y_test_pred = self.test.copy()\n",
    "        y_test_pred.labels = y_pred\n",
    "\n",
    "        di=self.DisparateImpact(y_test_pred)\n",
    "        f1_macro = f1_score(self.test.labels, y_pred, average='macro',sample_weight=self.test.instance_weights)\n",
    "        f1_micro = f1_score(self.test.labels, y_pred, average='micro',sample_weight=self.test.instance_weights)\n",
    "        f1_weighted = f1_score(self.test.labels, y_pred, average='weighted',sample_weight=self.test.instance_weights)\n",
    "        print('Disparate Impact of '+str(method),di)\n",
    "        print('f1 macro of '+str(method),f1_macro)\n",
    "\n",
    "        new_row=pd.Series({'DI of train':di_train,'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,'method':method})\n",
    "        return new_row.to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juv_fel_count 0.03210337325453563\n",
      "juv_misd_count 0.04323143324022939\n",
      "juv_other_count 0.021763780679615215\n",
      "priors_count 0.12622233191661625\n",
      "age_cat=25 - 45 0.054431947619680315\n",
      "age_cat=Greater than 45 0.13519019921101838\n",
      "age_cat=Less than 25 0.08075825159133806\n",
      "c_charge_degree=F 0.07840757396162046\n",
      "c_charge_degree=M 0.07840757396162046\n"
     ]
    }
   ],
   "source": [
    "pa = 'race'\n",
    "label_map = {1.0: 'Did recid.', 0.0: 'No recid.'}\n",
    "protected_attribute_maps = {1.0: 'Caucasian', 0.0: 'Not Caucasian'}\n",
    "privileged_groups = [{pa: 1}]\n",
    "unprivileged_groups = [{pa: 0}]\n",
    "cd = CompasDataset(protected_attribute_names=[pa],privileged_classes=[['Caucasian'],[1]], \n",
    "                    metadata={'label_map': label_map,'protected_attribute_maps': protected_attribute_maps},\n",
    "                    features_to_drop=['age', 'sex', 'c_charge_desc'])\n",
    "train,test = cd.split([0.6], shuffle=True) #len(test.instance_names) = 2057\n",
    "var_list = cd.feature_names.copy()\n",
    "var_list.remove(pa)\n",
    "var_dim=len(var_list)\n",
    "\n",
    "# df_train = df.loc[train.instance_names,:].reset_index(drop=True)\n",
    "# df_test = df.loc[test.instance_names,:].reset_index(drop=True)\n",
    "df=cd.convert_to_dataframe()[0]\n",
    "df=df.rename(columns={pa:'S',cd.label_names[0]:'Y'})\n",
    "df['W'] = cd.instance_weights\n",
    "for col in var_list+['S','Y']:\n",
    "    df[col]=df[col].astype('int64')\n",
    "df=df[var_list+['S','W','Y']]\n",
    "\n",
    "tv_dist=dict()\n",
    "for x_name in var_list:\n",
    "    x_range_single=list(pd.pivot_table(df,index=x_name,values=['W'],observed=False)[('W')].index) \n",
    "    dist=rdata_analysis(df,x_range_single,x_name)\n",
    "    tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    print(x_name, tv_dist[x_name])\n",
    "x_list=[]\n",
    "for key,val in tv_dist.items():\n",
    "    if val>0.1:\n",
    "        x_list+=[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.8508063904090156\n",
      "Disparate Impact of origin 0.790151357857663\n",
      "f1 macro of origin 0.6606396161144692\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7912403973955378\n",
      "f1 macro of RW 0.6595996061700033\n",
      "Disparate Impact of train 0.8508063904090156\n",
      "Disparate Impact of DIremover 0.87822695035461\n",
      "f1 macro of DIremover 0.6509420624812522\n",
      "Disparate Impact of train 0.9184663961285563\n",
      "Disparate Impact of LFR 0.9273086507129059\n",
      "f1 macro of LFR 0.6512482451580937\n",
      "Disparate Impact of train 0.8380490196078431\n",
      "Disparate Impact of origin 0.7570159008877184\n",
      "f1 macro of origin 0.6582753992914918\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7527235579207451\n",
      "f1 macro of RW 0.6633554405301845\n",
      "Disparate Impact of train 0.8380490196078431\n",
      "Disparate Impact of DIremover 0.8918455074337427\n",
      "f1 macro of DIremover 0.6609850417128611\n",
      "Disparate Impact of train 0.9137245175848118\n",
      "Disparate Impact of LFR 0.9644233899093234\n",
      "f1 macro of LFR 0.6559355161020726\n",
      "Disparate Impact of train 0.8628984381298602\n",
      "Disparate Impact of origin 0.7633311789709066\n",
      "f1 macro of origin 0.6671230111477789\n",
      "Disparate Impact of train 0.9999999999999998\n",
      "Disparate Impact of RW 0.7681258122970713\n",
      "f1 macro of RW 0.664288226554683\n",
      "Disparate Impact of train 0.8628984381298602\n",
      "Disparate Impact of DIremover 0.8539350566231348\n",
      "f1 macro of DIremover 0.6668650136250837\n",
      "Disparate Impact of train 0.9434105182896242\n",
      "Disparate Impact of LFR 0.9758252780779634\n",
      "f1 macro of LFR 0.6615109533458843\n",
      "Disparate Impact of train 0.8527979743527716\n",
      "Disparate Impact of origin 0.7851050370580183\n",
      "f1 macro of origin 0.6809370525664791\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.8092679774762301\n",
      "f1 macro of RW 0.6755542047199874\n",
      "Disparate Impact of train 0.8527979743527716\n",
      "Disparate Impact of DIremover 0.9518030690537086\n",
      "f1 macro of DIremover 0.6686069478331591\n",
      "Disparate Impact of train 0.9352986392797951\n",
      "Disparate Impact of LFR 0.9485390638014326\n",
      "f1 macro of LFR 0.6653584163538973\n",
      "Disparate Impact of train 0.8169858937416425\n",
      "Disparate Impact of origin 0.7975021768001478\n",
      "f1 macro of origin 0.6587632654480085\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.796300787772496\n",
      "f1 macro of RW 0.6584248606274807\n",
      "Disparate Impact of train 0.8169858937416425\n",
      "Disparate Impact of DIremover 0.89008682462565\n",
      "f1 macro of DIremover 0.644605168083999\n",
      "Disparate Impact of train 0.8948711119003225\n",
      "Disparate Impact of LFR 0.8690978824568117\n",
      "f1 macro of LFR 0.671037195689608\n",
      "Disparate Impact of train 0.8790738255033558\n",
      "Disparate Impact of origin 0.8298464914337156\n",
      "f1 macro of origin 0.6636719672022202\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.831163708086785\n",
      "f1 macro of RW 0.6633191820613686\n",
      "Disparate Impact of train 0.8790738255033558\n",
      "Disparate Impact of DIremover 0.8010030693288612\n",
      "f1 macro of DIremover 0.6691908695053217\n",
      "Disparate Impact of train 0.9414728109538862\n",
      "Disparate Impact of LFR 0.9813073907301298\n",
      "f1 macro of LFR 0.6591820540471807\n",
      "Disparate Impact of train 0.8144711964195964\n",
      "Disparate Impact of origin 0.7825639411197924\n",
      "f1 macro of origin 0.6550588121084154\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7800190177340369\n",
      "f1 macro of RW 0.6565564477110454\n",
      "Disparate Impact of train 0.8144711964195964\n",
      "Disparate Impact of DIremover 0.884040047114252\n",
      "f1 macro of DIremover 0.6494259145413561\n",
      "Disparate Impact of train 0.9078874793160507\n",
      "Disparate Impact of LFR 0.9674924490713964\n",
      "f1 macro of LFR 0.6472875364710953\n",
      "Disparate Impact of train 0.8264727954971857\n",
      "Disparate Impact of origin 0.8094606214082545\n",
      "f1 macro of origin 0.6604628146631784\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7731236435310271\n",
      "f1 macro of RW 0.6641625708838601\n",
      "Disparate Impact of train 0.8264727954971857\n",
      "Disparate Impact of DIremover 0.8421586753352297\n",
      "f1 macro of DIremover 0.6635604497970591\n",
      "Disparate Impact of train 0.9090259117082533\n",
      "Disparate Impact of LFR 0.8681673174955885\n",
      "f1 macro of LFR 0.6632178157725594\n",
      "Disparate Impact of train 0.8303328001257781\n",
      "Disparate Impact of origin 0.7618970453195053\n",
      "f1 macro of origin 0.6643606849981145\n",
      "Disparate Impact of train 0.9999999999999998\n",
      "Disparate Impact of RW 0.766206813042609\n",
      "f1 macro of RW 0.6587199329955343\n",
      "Disparate Impact of train 0.8303328001257781\n",
      "Disparate Impact of DIremover 0.9502972297789116\n",
      "f1 macro of DIremover 0.6396973933628964\n",
      "Disparate Impact of train 0.9234696850056962\n",
      "Disparate Impact of LFR 0.8775627172295574\n",
      "f1 macro of LFR 0.6618836781988314\n",
      "Disparate Impact of train 0.8128941593459464\n",
      "Disparate Impact of origin 0.7513016561945377\n",
      "f1 macro of origin 0.6577744133691754\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.7660245202827655\n",
      "f1 macro of RW 0.6545804822836816\n",
      "Disparate Impact of train 0.8128941593459464\n",
      "Disparate Impact of DIremover 0.8075531871237037\n",
      "f1 macro of DIremover 0.6519122562325514\n",
      "Disparate Impact of train 0.9544320528707145\n",
      "Disparate Impact of LFR 0.8996150303236835\n",
      "f1 macro of LFR 0.6568597870598614\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv(path+'/data/report_preprocess_compas_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path,var_list,pa):\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education',\n",
    "                'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "                'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                'native-country', 'Y']\n",
    "    na_values=['?']\n",
    "    pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "    label_dict={'>50K.':1,'>50K':1,'<=50K.':0,'<=50K':0}\n",
    "    train_path = os.path.join(data_path, 'adult.data')\n",
    "    test_path = os.path.join(data_path, 'adult.test')\n",
    "    train = pd.read_csv(train_path, header=None,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    test = pd.read_csv(test_path, header=0,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    messydata = pd.concat([test, train], ignore_index=True)[var_list+[pa,'Y']]\n",
    "    messydata=messydata.rename(columns={pa:'S'})\n",
    "    messydata['S']=messydata['S'].replace(pa_dict)\n",
    "    messydata['Y']=messydata['Y'].replace(label_dict)\n",
    "    messydata=messydata[(messydata['S']==0)|(messydata['S']==1)]\n",
    "    for col in var_list+['S','Y']:\n",
    "        messydata[col]=messydata[col].astype('int64')\n",
    "    messydata['W']=1\n",
    "    bins_capitalgain=[100,3500,7500,10000]\n",
    "    bins_capitalloss=[100,1600,1900,2200]\n",
    "    bins_age=[26,36,46,56]\n",
    "    bins_hours=[21,36,46,61]\n",
    "\n",
    "    messydata=categerise(messydata,'age',bins_age)\n",
    "    messydata=categerise(messydata,'hours-per-week',bins_hours)\n",
    "    messydata=categerise(messydata,'capital-gain',bins_capitalgain)\n",
    "    messydata=categerise(messydata,'capital-loss',bins_capitalloss)\n",
    "    \n",
    "    return messydata\n",
    "\n",
    "def categerise(df,col,bins):\n",
    "    for i in range(len(bins)+1):\n",
    "        if i == 0:\n",
    "            df.loc[df[col] < bins[i], col] = i\n",
    "        elif i == len(bins):\n",
    "            df.loc[df[col] >= bins[i-1], col] = i\n",
    "        else:\n",
    "            df.loc[(df[col] >= bins[i-1])& (df[col] < bins[i]), col] = i        \n",
    "    return df\n",
    "\n",
    "def choose_x(var_list,messydata):\n",
    "    tv_dist=dict()\n",
    "    for x_name in var_list:\n",
    "        x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "        dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "        tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    x_list=[]\n",
    "    for key,val in tv_dist.items():\n",
    "        if val>0.1:\n",
    "            x_list+=[key]  \n",
    "    return x_list,tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change the obtaining method for the adult data\n",
    "data_path='C://personal//work//repair//.venv//Lib//site-packages//aif360//data//raw//adult'\n",
    "\n",
    "var_list=['hours-per-week','age','capital-gain','capital-loss','education-num'] #,'education-num'\n",
    "pa='race'\n",
    "favorable_label = 1\n",
    "var_dim=len(var_list)\n",
    "\n",
    "messydata = load_data(data_path,var_list,pa)\n",
    "x_list,tv_dist = choose_x(var_list,messydata)\n",
    "messydata=messydata.rename(columns={'S':pa})\n",
    "cd=BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=messydata,label_names='Y',protected_attribute_names=[pa])\n",
    "train,test = cd.split([0.4], shuffle=True) \n",
    "valid,test = test.split([0.3], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.47223910848631023\n",
      "Disparate Impact of origin 0.43825807084041307\n",
      "f1 macro of origin 0.694201107170793\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.4341662543295398\n",
      "f1 macro of RW 0.6863462888817584\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m     prepro = Baselinepreprocess(train,test)\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m methods:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m         report = pd.concat([report,\u001b[43mprepro\u001b[49m\u001b[43m.\u001b[49m\u001b[43massess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     13\u001b[39m report.to_csv(path+\u001b[33m'\u001b[39m\u001b[33m/data/report_preprocess_adult_\u001b[39m\u001b[33m'\u001b[39m+\u001b[38;5;28mstr\u001b[39m(pa)+\u001b[33m'\u001b[39m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m,index=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mBaselinepreprocess.assess\u001b[39m\u001b[34m(self, method, para)\u001b[39m\n\u001b[32m     82\u001b[39m     y_pred,di_train = \u001b[38;5;28mself\u001b[39m.prediction(method,para)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     y_pred,di_train = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m y_test_pred = \u001b[38;5;28mself\u001b[39m.test.copy()\n\u001b[32m     86\u001b[39m y_test_pred.labels = y_pred\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mBaselinepreprocess.prediction\u001b[39m\u001b[34m(self, method, para)\u001b[39m\n\u001b[32m     42\u001b[39m     train_tranf = \u001b[38;5;28mself\u001b[39m.train\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mRW\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mDIremover\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mLFR\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mOP\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     train_tranf,test_tranf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     46\u001b[39m     K=\u001b[32m200\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mBaselinepreprocess.preprocessing\u001b[39m\u001b[34m(self, method)\u001b[39m\n\u001b[32m     18\u001b[39m     di = DisparateImpactRemover(repair_level = \u001b[32m1\u001b[39m,sensitive_attribute=pa)\n\u001b[32m     19\u001b[39m     train_tranf = di.fit_transform(\u001b[38;5;28mself\u001b[39m.train)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     test_tranf = \u001b[43mdi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33mLFR\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     22\u001b[39m     TR = LFR(privileged_groups = \u001b[38;5;28mself\u001b[39m.prigroups,unprivileged_groups = \u001b[38;5;28mself\u001b[39m.unprigroups,\n\u001b[32m     23\u001b[39m              Az = \u001b[32m1\u001b[39m, Ax = \u001b[32m0.01\u001b[39m, Ay = \u001b[32m1\u001b[39m,verbose=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\work\\repair\\.venv\\Lib\\site-packages\\aif360\\algorithms\\transformer.py:27\u001b[39m, in \u001b[36maddmetadata.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     new_dataset = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_dataset, Dataset):\n\u001b[32m     29\u001b[39m         new_dataset.metadata = new_dataset.metadata.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\work\\repair\\.venv\\Lib\\site-packages\\aif360\\algorithms\\preprocessing\\disparate_impact_remover.py:60\u001b[39m, in \u001b[36mDisparateImpactRemover.fit_transform\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m     57\u001b[39m repairer = \u001b[38;5;28mself\u001b[39m.Repairer(features, index, \u001b[38;5;28mself\u001b[39m.repair_level, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     59\u001b[39m repaired = dataset.copy()\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m repaired_features = \u001b[43mrepairer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrepair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m repaired.features = np.array(repaired_features, dtype=np.float64)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# protected attribute shouldn't change\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\work\\repair\\.venv\\Lib\\site-packages\\BlackBoxAuditing\\repairers\\GeneralRepairer.py:20\u001b[39m, in \u001b[36mRepairer.repair\u001b[39m\u001b[34m(self, data_to_repair)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrepair\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_to_repair):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrepairer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrepair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_to_repair\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\work\\repair\\.venv\\Lib\\site-packages\\BlackBoxAuditing\\repairers\\NumericRepairer.py:28\u001b[39m, in \u001b[36mRepairer.repair\u001b[39m\u001b[34m(self, data_to_repair)\u001b[39m\n\u001b[32m     25\u001b[39m   category_vals = [data_to_repair[j][\u001b[38;5;28mself\u001b[39m.feature_to_repair] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m index_bin]\n\u001b[32m     26\u001b[39m   category_medians[bin_name] = get_median(category_vals, \u001b[38;5;28mself\u001b[39m.kdd)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m repaired_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcategoric_repairer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrepair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinned_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Replace the \"feature_to_repair\" column with the median numeric value.\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(repaired_data)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\work\\repair\\.venv\\Lib\\site-packages\\BlackBoxAuditing\\repairers\\CategoricRepairer.py:156\u001b[39m, in \u001b[36mRepairer.repair\u001b[39m\u001b[34m(self, data_to_repair)\u001b[39m\n\u001b[32m    154\u001b[39m current_val_pos = index_lookup[col_id][original_value]\n\u001b[32m    155\u001b[39m distance = median_val_pos - current_val_pos \u001b[38;5;66;03m# distance between indices\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m distance_to_repair = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrepair_level\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m index_of_repair_value = current_val_pos + distance_to_repair\n\u001b[32m    158\u001b[39m repaired_value = unique_col_vals[col_id][index_of_repair_value]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "para={'x_list':x_list,'Theta':1e-2}\n",
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv(path+'/data/report_preprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI of train</th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.467542</td>\n",
       "      <td>0.489939</td>\n",
       "      <td>0.683935</td>\n",
       "      <td>0.819314</td>\n",
       "      <td>0.79216</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.511456</td>\n",
       "      <td>0.690812</td>\n",
       "      <td>0.819007</td>\n",
       "      <td>0.794974</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.467542</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.688262</td>\n",
       "      <td>0.819622</td>\n",
       "      <td>0.794136</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.790206</td>\n",
       "      <td>0.932976</td>\n",
       "      <td>0.685474</td>\n",
       "      <td>0.809626</td>\n",
       "      <td>0.788862</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.457948</td>\n",
       "      <td>0.441882</td>\n",
       "      <td>0.678863</td>\n",
       "      <td>0.815726</td>\n",
       "      <td>0.787174</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.438133</td>\n",
       "      <td>0.676989</td>\n",
       "      <td>0.815213</td>\n",
       "      <td>0.786154</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.457948</td>\n",
       "      <td>0.439819</td>\n",
       "      <td>0.687472</td>\n",
       "      <td>0.816495</td>\n",
       "      <td>0.791215</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.757844</td>\n",
       "      <td>0.864616</td>\n",
       "      <td>0.700593</td>\n",
       "      <td>0.808704</td>\n",
       "      <td>0.793542</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.492511</td>\n",
       "      <td>0.465343</td>\n",
       "      <td>0.690802</td>\n",
       "      <td>0.822287</td>\n",
       "      <td>0.796149</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.460183</td>\n",
       "      <td>0.69525</td>\n",
       "      <td>0.823159</td>\n",
       "      <td>0.798405</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.492511</td>\n",
       "      <td>0.468147</td>\n",
       "      <td>0.703401</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>0.801723</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.872252</td>\n",
       "      <td>0.844944</td>\n",
       "      <td>0.698594</td>\n",
       "      <td>0.814137</td>\n",
       "      <td>0.796096</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.494126</td>\n",
       "      <td>0.425631</td>\n",
       "      <td>0.691328</td>\n",
       "      <td>0.820801</td>\n",
       "      <td>0.795593</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.40555</td>\n",
       "      <td>0.682197</td>\n",
       "      <td>0.820032</td>\n",
       "      <td>0.791356</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.494126</td>\n",
       "      <td>0.417864</td>\n",
       "      <td>0.688979</td>\n",
       "      <td>0.821364</td>\n",
       "      <td>0.79481</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.815176</td>\n",
       "      <td>0.718679</td>\n",
       "      <td>0.699547</td>\n",
       "      <td>0.812958</td>\n",
       "      <td>0.795823</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.493582</td>\n",
       "      <td>0.387433</td>\n",
       "      <td>0.675837</td>\n",
       "      <td>0.816956</td>\n",
       "      <td>0.786577</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391573</td>\n",
       "      <td>0.683428</td>\n",
       "      <td>0.819109</td>\n",
       "      <td>0.790734</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.493582</td>\n",
       "      <td>0.384134</td>\n",
       "      <td>0.683287</td>\n",
       "      <td>0.819263</td>\n",
       "      <td>0.790734</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.817671</td>\n",
       "      <td>0.666286</td>\n",
       "      <td>0.691215</td>\n",
       "      <td>0.813419</td>\n",
       "      <td>0.791792</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.478487</td>\n",
       "      <td>0.475398</td>\n",
       "      <td>0.682115</td>\n",
       "      <td>0.819878</td>\n",
       "      <td>0.791924</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.473628</td>\n",
       "      <td>0.683664</td>\n",
       "      <td>0.819775</td>\n",
       "      <td>0.792547</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.478487</td>\n",
       "      <td>0.470653</td>\n",
       "      <td>0.691371</td>\n",
       "      <td>0.822697</td>\n",
       "      <td>0.797012</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.828515</td>\n",
       "      <td>0.77835</td>\n",
       "      <td>0.703823</td>\n",
       "      <td>0.813061</td>\n",
       "      <td>0.798207</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.484752</td>\n",
       "      <td>0.395999</td>\n",
       "      <td>0.674021</td>\n",
       "      <td>0.818033</td>\n",
       "      <td>0.787558</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.667499</td>\n",
       "      <td>0.815982</td>\n",
       "      <td>0.783933</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.484752</td>\n",
       "      <td>0.391519</td>\n",
       "      <td>0.668261</td>\n",
       "      <td>0.816495</td>\n",
       "      <td>0.784463</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.882646</td>\n",
       "      <td>0.777564</td>\n",
       "      <td>0.696054</td>\n",
       "      <td>0.814547</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.479622</td>\n",
       "      <td>0.431169</td>\n",
       "      <td>0.687489</td>\n",
       "      <td>0.821262</td>\n",
       "      <td>0.796182</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.419771</td>\n",
       "      <td>0.681035</td>\n",
       "      <td>0.820237</td>\n",
       "      <td>0.793051</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.479622</td>\n",
       "      <td>0.425423</td>\n",
       "      <td>0.683517</td>\n",
       "      <td>0.820288</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.845565</td>\n",
       "      <td>0.802582</td>\n",
       "      <td>0.705586</td>\n",
       "      <td>0.814393</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.459117</td>\n",
       "      <td>0.457237</td>\n",
       "      <td>0.676066</td>\n",
       "      <td>0.814598</td>\n",
       "      <td>0.785161</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0.459872</td>\n",
       "      <td>0.676275</td>\n",
       "      <td>0.814957</td>\n",
       "      <td>0.785394</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.459117</td>\n",
       "      <td>0.44574</td>\n",
       "      <td>0.687279</td>\n",
       "      <td>0.817828</td>\n",
       "      <td>0.791335</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.763368</td>\n",
       "      <td>0.752575</td>\n",
       "      <td>0.700804</td>\n",
       "      <td>0.811472</td>\n",
       "      <td>0.794515</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.47403</td>\n",
       "      <td>0.489144</td>\n",
       "      <td>0.684831</td>\n",
       "      <td>0.81875</td>\n",
       "      <td>0.792592</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.487089</td>\n",
       "      <td>0.68337</td>\n",
       "      <td>0.818545</td>\n",
       "      <td>0.791886</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.47403</td>\n",
       "      <td>0.47186</td>\n",
       "      <td>0.689036</td>\n",
       "      <td>0.820442</td>\n",
       "      <td>0.795066</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.814628</td>\n",
       "      <td>0.943558</td>\n",
       "      <td>0.699911</td>\n",
       "      <td>0.812599</td>\n",
       "      <td>0.796368</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DI of train        DI  f1 macro  f1 micro f1 weighted     method\n",
       "0     0.467542  0.489939  0.683935  0.819314     0.79216     origin\n",
       "1            1  0.511456  0.690812  0.819007    0.794974         RW\n",
       "2     0.467542    0.4965  0.688262  0.819622    0.794136  DIremover\n",
       "3     0.790206  0.932976  0.685474  0.809626    0.788862        LFR\n",
       "4     0.457948  0.441882  0.678863  0.815726    0.787174     origin\n",
       "5            1  0.438133  0.676989  0.815213    0.786154         RW\n",
       "6     0.457948  0.439819  0.687472  0.816495    0.791215  DIremover\n",
       "7     0.757844  0.864616  0.700593  0.808704    0.793542        LFR\n",
       "8     0.492511  0.465343  0.690802  0.822287    0.796149     origin\n",
       "9          1.0  0.460183   0.69525  0.823159    0.798405         RW\n",
       "10    0.492511  0.468147  0.703401    0.8228    0.801723  DIremover\n",
       "11    0.872252  0.844944  0.698594  0.814137    0.796096        LFR\n",
       "12    0.494126  0.425631  0.691328  0.820801    0.795593     origin\n",
       "13           1   0.40555  0.682197  0.820032    0.791356         RW\n",
       "14    0.494126  0.417864  0.688979  0.821364     0.79481  DIremover\n",
       "15    0.815176  0.718679  0.699547  0.812958    0.795823        LFR\n",
       "16    0.493582  0.387433  0.675837  0.816956    0.786577     origin\n",
       "17         1.0  0.391573  0.683428  0.819109    0.790734         RW\n",
       "18    0.493582  0.384134  0.683287  0.819263    0.790734  DIremover\n",
       "19    0.817671  0.666286  0.691215  0.813419    0.791792        LFR\n",
       "20    0.478487  0.475398  0.682115  0.819878    0.791924     origin\n",
       "21           1  0.473628  0.683664  0.819775    0.792547         RW\n",
       "22    0.478487  0.470653  0.691371  0.822697    0.797012  DIremover\n",
       "23    0.828515   0.77835  0.703823  0.813061    0.798207        LFR\n",
       "24    0.484752  0.395999  0.674021  0.818033    0.787558     origin\n",
       "25         1.0  0.390625  0.667499  0.815982    0.783933         RW\n",
       "26    0.484752  0.391519  0.668261  0.816495    0.784463  DIremover\n",
       "27    0.882646  0.777564  0.696054  0.814547      0.7955        LFR\n",
       "28    0.479622  0.431169  0.687489  0.821262    0.796182     origin\n",
       "29         1.0  0.419771  0.681035  0.820237    0.793051         RW\n",
       "30    0.479622  0.425423  0.683517  0.820288    0.794118  DIremover\n",
       "31    0.845565  0.802582  0.705586  0.814393    0.800733        LFR\n",
       "32    0.459117  0.457237  0.676066  0.814598    0.785161     origin\n",
       "33           1  0.459872  0.676275  0.814957    0.785394         RW\n",
       "34    0.459117   0.44574  0.687279  0.817828    0.791335  DIremover\n",
       "35    0.763368  0.752575  0.700804  0.811472    0.794515        LFR\n",
       "36     0.47403  0.489144  0.684831   0.81875    0.792592     origin\n",
       "37         1.0  0.487089   0.68337  0.818545    0.791886         RW\n",
       "38     0.47403   0.47186  0.689036  0.820442    0.795066  DIremover\n",
       "39    0.814628  0.943558  0.699911  0.812599    0.796368        LFR"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'para' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m report.to_csv(path+\u001b[33m'\u001b[39m\u001b[33m/data/report_preprocess_compas_\u001b[39m\u001b[33m'\u001b[39m+\u001b[38;5;28mstr\u001b[39m(pa)+\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m+\u001b[38;5;28mstr\u001b[39m(\u001b[43mpara\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mTheta\u001b[39m\u001b[33m'\u001b[39m])+\u001b[33m'\u001b[39m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m,index=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'para' is not defined"
     ]
    }
   ],
   "source": [
    "report.to_csv(path+'/data/report_preprocess_compas_'+str(pa)+'_'+str(para['Theta'])+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baselinepreprocess(train,test).assess('partial',para=para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baselinepreprocess(train,test).assess('LFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baselinepreprocess(train,test).assess('RW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baselinepreprocess(train,test).assess('DIremover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baselinepreprocess(train,test).assess('origin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
