{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover,Reweighing,LFR\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from aif360.datasets import CompasDataset, AdultDataset\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from humancompatible.repair.methods.cost import c_generate, c_generate_higher\n",
    "from humancompatible.repair.methods.data_analysis import rdata_analysis\n",
    "from humancompatible.repair.methods.coupling_utils import projection, projection_higher\n",
    "from humancompatible.repair.group_blind_repair import GroupBlindRepair\n",
    "\n",
    "# if you need \"OptimPreproc\"\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projpreprocess:\n",
    "    \n",
    "    def __init__(self,traindata,x_list,var_list,K,e):\n",
    "\n",
    "        self.K=K\n",
    "        self.e=e\n",
    "        self.x_list=x_list\n",
    "        self.var_list=var_list\n",
    "            \n",
    "        print(\"var_list ====== \")\n",
    "        print(self.var_list)\n",
    "        if 'W' in self.var_list:\n",
    "            self.var_list.remove('W')\n",
    "      \n",
    "        self.var_dim=len(self.var_list)\n",
    "        self.arg_list=[elem for elem in self.var_list if elem not in x_list]\n",
    "        self.train = traindata.copy()\n",
    "        self.df = self.train.convert_to_dataframe()[0]\n",
    "        self.pa = self.train.protected_attribute_names[0]\n",
    "        self.pa_index = self.train.feature_names.index(self.pa)\n",
    "        self.label_name = self.train.label_names[0]\n",
    "        self.df=self.df.rename(columns={self.pa:'S',self.label_name:'Y'})\n",
    "\n",
    "        self.df['W'] = self.train.instance_weights\n",
    "        for col in self.var_list+['S','Y']:\n",
    "            self.df[col]=self.df[col].astype('int64')\n",
    "        self.df=self.df[self.var_list+['S','W','Y']]\n",
    "        if len(x_list)>1:\n",
    "            self.df['X'] = list(zip(*[self.df[c] for c in x_list]))\n",
    "            self.x_range=sorted(set(self.df['X']))\n",
    "            weight=list(1/(self.df[x_list].max()-self.df[x_list].min())) # because ranges of attributes differ\n",
    "            self.C=c_generate_higher(self.x_range,weight)\n",
    "        else:\n",
    "            self.df['X']=self.df[x_list]\n",
    "            self.x_range=sorted(set(self.df['X']))\n",
    "            self.C=c_generate(self.x_range)\n",
    "        \n",
    "        # DEBUGGING\n",
    "        # print(type(self.df))\n",
    "        # print(self.arg_list)\n",
    "        # print(self.df.columns)\n",
    "        # print(self.df)\n",
    "        # print(self.df['W'])\n",
    "        # print(check_duplicate_columns_equal(self.df))\n",
    "        # self.df = remove_duplicate_columns(self.df)\n",
    "        # print(type(self.df))\n",
    "        # print(self.arg_list)\n",
    "        # print(self.df.columns)\n",
    "        # print(self.df)\n",
    "        # print(self.df['W'])\n",
    "        # print(check_duplicate_columns_equal(self.df))\n",
    "\n",
    "\n",
    "        self.df = self.df[list(set(self.arg_list+['X','S','Y','W']))].groupby(by=list(set(self.arg_list+['X','S','Y'])),as_index=False).sum()\n",
    "        self.distribution_generator()\n",
    "        \n",
    "    def distribution_generator(self):\n",
    "        bin=len(self.x_range)\n",
    "        dist=rdata_analysis(self.df,self.x_range,'X')\n",
    "        dist['v']=[(dist['x_0'][i]-dist['x_1'][i])/dist['x'][i] for i in range(bin)]\n",
    "        dist['t_x']=dist['x'] # #dist['x'] #dist['x_0']*0.5+dist['x_1']*0.5 \n",
    "        self.px=np.matrix(dist['x']).T\n",
    "        self.ptx=np.matrix(dist['t_x']).T\n",
    "        if np.any(dist['x_0']==0): \n",
    "            self.p0=np.matrix((dist['x_0']+1.0e-9)/sum(dist['x_0']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p0=np.matrix(dist['x_0']).T \n",
    "        if np.any(dist['x_1']==0):\n",
    "            self.p1=np.matrix((dist['x_1']+1.0e-9)/sum(dist['x_1']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p1=np.matrix(dist['x_1']).T \n",
    "        self.V=np.matrix(dist['v']).T\n",
    "        # self.tv_origin=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "        # return px,ptx,V,p0,p1\n",
    "    \n",
    "    def _run_method(self, method, C, eps, px, ptx, K, V=None, theta=None):\n",
    "        group_blind = GroupBlindRepair(C, px, ptx, V=V, epsilon=eps, K=K)\n",
    "        if method == \"baseline\":\n",
    "            group_blind.fit_baseline()\n",
    "        elif method == \"partial_repair\":\n",
    "            group_blind.fit_partial(theta)\n",
    "        elif method == \"total_repair\":\n",
    "            group_blind.fit_total()\n",
    "        return group_blind.coupling_matrix()\n",
    "\n",
    "    def coupling_generator(self,method,Theta=1e-2):\n",
    "        if method == 'unconstrained':\n",
    "            coupling=self._run_method(method=\"baseline\", C=self.C, eps=self.e, px=self.px, ptx=self.ptx, K=self.K)\n",
    "        elif method == 'barycentre':\n",
    "            coupling=self._run_method(method=\"baseline\", C=self.C, eps=self.e, px=self.p0, ptx=self.p1, K=self.K)\n",
    "        elif method == 'partial':\n",
    "            coupling=self._run_method(method=\"partial_repair\", C=self.C, eps=self.e, px=self.px, ptx=self.ptx, V=self.V, theta=Theta, K=self.K)\n",
    "        return coupling\n",
    "\n",
    "    def preprocess(self,method,Theta=1e-2):\n",
    "        coupling = self.coupling_generator(method,Theta)\n",
    "        if len(self.x_list)>1:\n",
    "            df_proj=projection_higher(self.df,coupling,self.x_range,self.x_list,self.var_list)\n",
    "        else:\n",
    "            df_proj=projection(self.df,coupling,self.x_range,self.x_list[0],self.var_list)\n",
    "        df_proj = df_proj.groupby(by=self.arg_list+['X','S','Y'],as_index=False).sum()\n",
    "        X=list(zip(*df_proj['X']))\n",
    "        df_proj = df_proj.assign(**{self.x_list[i]:X[i] for i in range(len(self.x_list))})\n",
    "        df_proj=df_proj.drop('X',axis=1)\n",
    "        df_proj=df_proj.rename(columns={'S':self.pa,'Y':self.label_name})\n",
    "        binaryLabelDataset = BinaryLabelDataset(\n",
    "            favorable_label=0,\n",
    "            unfavorable_label=1,\n",
    "            df=df_proj.drop('W',axis=1), \n",
    "            label_names=self.train.label_names,\n",
    "            protected_attribute_names=self.train.protected_attribute_names,\n",
    "            privileged_protected_attributes=[np.array([1.0])],unprivileged_protected_attributes=[np.array([0.])])\n",
    "        binaryLabelDataset.instance_weights = df_proj['W'].tolist()\n",
    "        # return binaryLabelDataset.align_datasets(self.train)\n",
    "\n",
    "        # print(\"preprocess function ===================\")\n",
    "        # print(df_proj)\n",
    "        # print(df_proj['W'])\n",
    "        # print(\"binaryLabelDataset ===================\")\n",
    "        # print(type(binaryLabelDataset))\n",
    "        # print(binaryLabelDataset)\n",
    "        # print(\"self.train ===================\")\")\n",
    "        # print(type(self.train))\n",
    "        # print(self.train)\n",
    "\n",
    "        return self.train.align_datasets(binaryLabelDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baselinepreprocess:\n",
    "\n",
    "    def __init__(self,train,test):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.pa = train.protected_attribute_names[0]\n",
    "        self.pa_index = train.feature_names.index(self.pa)\n",
    "        self.prigroups = [{self.pa: 1}]\n",
    "        self.unprigroups = [{self.pa: 0}]\n",
    "\n",
    "    def preprocessing(self,method):\n",
    "        test_tranf = self.test.copy()\n",
    "        if method == 'RW':\n",
    "            RW = Reweighing(privileged_groups = self.prigroups,unprivileged_groups = self.unprigroups) #DisparateImpactRemover(repair_level = 1)\n",
    "            RW.fit(self.train)\n",
    "            train_tranf = RW.transform(self.train)\n",
    "        elif method == 'DIremover':\n",
    "            di = DisparateImpactRemover(repair_level = 1,sensitive_attribute=self.pa)\n",
    "            train_tranf = di.fit_transform(self.train)\n",
    "            test_tranf = di.fit_transform(self.test)\n",
    "        elif method == 'LFR':\n",
    "            TR = LFR(privileged_groups = self.prigroups,unprivileged_groups = self.unprigroups,\n",
    "                     Az = 1, Ax = 0.01, Ay = 1,verbose=0)\n",
    "            TR = TR.fit(self.train)\n",
    "            train_tranf = TR.transform(self.train)\n",
    "            test_tranf = TR.transform(self.test)\n",
    "        elif method == 'OP':\n",
    "            optim_options = {\n",
    "                \"distortion_fun\": get_distortion_adult,\n",
    "                \"epsilon\": 0.05,\n",
    "                \"clist\": [0.99, 1.99, 2.99],\n",
    "                \"dlist\": [.1, 0.05, 0]\n",
    "            }\n",
    "            OP = OptimPreproc(OptTools, optim_options)\n",
    "            OP = OP.fit(self.train)\n",
    "            train_tranf = OP.transform(self.train, transform_Y=True)\n",
    "        return train_tranf, test_tranf\n",
    "\n",
    "    def prediction(self,method,para=None):\n",
    "        test_tranf = self.test.copy()\n",
    "        if method == 'origin':\n",
    "            train_tranf = self.train\n",
    "        elif method in ['RW','DIremover','LFR','OP']:\n",
    "            train_tranf,test_tranf = self.preprocessing(method)\n",
    "        else:\n",
    "            K=200\n",
    "            e=0.01\n",
    "            var_list=self.train.feature_names.copy()\n",
    "            var_list.remove(self.pa)\n",
    "            projpre=Projpreprocess(self.train,para['x_list'],var_list,K,e)\n",
    "            train_tranf=projpre.preprocess(method,para['Theta'])\n",
    "\n",
    "        di=self.DisparateImpact(train_tranf)\n",
    "        print('Disparate Impact of train',di)\n",
    "\n",
    "        if method != 'LFR':\n",
    "            X_train = np.delete(train_tranf.features, self.pa_index, axis=1)\n",
    "            y_train = train_tranf.labels.ravel()\n",
    "            weight_train = train_tranf.instance_weights\n",
    "            model=RandomForestClassifier(max_depth=5).fit(X_train,y_train, sample_weight=weight_train)\n",
    "\n",
    "            X_test = np.delete(test_tranf.features, self.pa_index, axis=1)\n",
    "            y_pred = model.predict(X_test)\n",
    "        else:\n",
    "            y_pred = test_tranf.labels\n",
    "        return y_pred,di\n",
    "    \n",
    "    def DisparateImpact(self,data):\n",
    "        di = pd.DataFrame({'S':data.protected_attributes.ravel().tolist(),\n",
    "            'Y':data.labels.ravel().tolist(),\n",
    "            'W':list(data.instance_weights)},columns=['S','Y','W'])\n",
    "        privileged = self.train.privileged_protected_attributes[0][0]\n",
    "        unprivileged = self.train.unprivileged_protected_attributes[0][0]\n",
    "        numerator=sum(di[(di['S']==unprivileged)&(di['Y']==data.favorable_label)]['W'])/sum(di[di['S']==unprivileged]['W'])\n",
    "        denominator=sum(di[(di['S']==privileged)&(di['Y']==data.favorable_label)]['W'])/sum(di[di['S']==privileged]['W'])\n",
    "        if numerator==denominator:\n",
    "            return 1\n",
    "        return numerator/denominator\n",
    "\n",
    "    def assess(self,method,para=None):\n",
    "        if para != None:\n",
    "            y_pred,di_train = self.prediction(method,para)\n",
    "        else:\n",
    "            y_pred,di_train = self.prediction(method)\n",
    "        y_test_pred = self.test.copy()\n",
    "        y_test_pred.labels = y_pred\n",
    "\n",
    "        di=self.DisparateImpact(y_test_pred)\n",
    "        f1_macro = f1_score(self.test.labels, y_pred, average='macro',sample_weight=self.test.instance_weights)\n",
    "        f1_micro = f1_score(self.test.labels, y_pred, average='micro',sample_weight=self.test.instance_weights)\n",
    "        f1_weighted = f1_score(self.test.labels, y_pred, average='weighted',sample_weight=self.test.instance_weights)\n",
    "        print('Disparate Impact of '+str(method),di)\n",
    "        print('f1 macro of '+str(method),f1_macro)\n",
    "\n",
    "        new_row=pd.Series({'DI of train':di_train,'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,'method':method})\n",
    "        return new_row.to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juv_fel_count 0.03210337325453563\n",
      "juv_misd_count 0.04323143324022939\n",
      "juv_other_count 0.021763780679615215\n",
      "priors_count 0.12622233191661625\n",
      "age_cat=25 - 45 0.054431947619680315\n",
      "age_cat=Greater than 45 0.13519019921101838\n",
      "age_cat=Less than 25 0.08075825159133806\n",
      "c_charge_degree=F 0.07840757396162046\n",
      "c_charge_degree=M 0.07840757396162046\n"
     ]
    }
   ],
   "source": [
    "pa = 'race'\n",
    "label_map = {1.0: 'Did recid.', 0.0: 'No recid.'}\n",
    "protected_attribute_maps = {1.0: 'Caucasian', 0.0: 'Not Caucasian'}\n",
    "privileged_groups = [{pa: 1}]\n",
    "unprivileged_groups = [{pa: 0}]\n",
    "cd = CompasDataset(protected_attribute_names=[pa],privileged_classes=[['Caucasian'],[1]], \n",
    "                    metadata={'label_map': label_map,'protected_attribute_maps': protected_attribute_maps},\n",
    "                    features_to_drop=['age', 'sex', 'c_charge_desc'])\n",
    "train,test = cd.split([0.6], shuffle=True) #len(test.instance_names) = 2057\n",
    "var_list = cd.feature_names.copy()\n",
    "var_list.remove(pa)\n",
    "var_dim=len(var_list)\n",
    "\n",
    "# df_train = df.loc[train.instance_names,:].reset_index(drop=True)\n",
    "# df_test = df.loc[test.instance_names,:].reset_index(drop=True)\n",
    "df=cd.convert_to_dataframe()[0]\n",
    "df=df.rename(columns={pa:'S',cd.label_names[0]:'Y'})\n",
    "df['W'] = cd.instance_weights\n",
    "for col in var_list+['S','Y']:\n",
    "    df[col]=df[col].astype('int64')\n",
    "df=df[var_list+['S','W','Y']]\n",
    "\n",
    "tv_dist=dict()\n",
    "for x_name in var_list:\n",
    "    x_range_single=list(pd.pivot_table(df,index=x_name,values=['W'],observed=False)[('W')].index) \n",
    "    dist=rdata_analysis(df,x_range_single,x_name)\n",
    "    tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    print(x_name, tv_dist[x_name])\n",
    "x_list=[]\n",
    "for key,val in tv_dist.items():\n",
    "    if val>0.1:\n",
    "        x_list+=[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.8402770892329867\n",
      "Disparate Impact of origin 0.7920019090772499\n",
      "f1 macro of origin 0.6661448830604686\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.7977096816672113\n",
      "f1 macro of RW 0.6619634977938227\n",
      "Disparate Impact of train 0.8402770892329867\n",
      "Disparate Impact of DIremover 0.8765711943309157\n",
      "f1 macro of DIremover 0.6694498322659348\n",
      "Disparate Impact of train 0.9182176686120846\n",
      "Disparate Impact of LFR 0.9658723272211144\n",
      "f1 macro of LFR 0.6704781999734366\n",
      "Disparate Impact of train 0.8414590862964464\n",
      "Disparate Impact of origin 0.783236210503632\n",
      "f1 macro of origin 0.661457485134364\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.784047014034174\n",
      "f1 macro of RW 0.6610096760777926\n",
      "Disparate Impact of train 0.8414590862964464\n",
      "Disparate Impact of DIremover 0.7808610487655581\n",
      "f1 macro of DIremover 0.6627885764081127\n",
      "Disparate Impact of train 0.936318521857122\n",
      "Disparate Impact of LFR 0.8947374197990362\n",
      "f1 macro of LFR 0.6612939836228457\n",
      "Disparate Impact of train 0.8641001477133211\n",
      "Disparate Impact of origin 0.800862210866827\n",
      "f1 macro of origin 0.6569680532079314\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.8123485969086972\n",
      "f1 macro of RW 0.6517258630547504\n",
      "Disparate Impact of train 0.8641001477133211\n",
      "Disparate Impact of DIremover 0.7808019018063181\n",
      "f1 macro of DIremover 0.6634226622765517\n",
      "Disparate Impact of train 0.9812222634706421\n",
      "Disparate Impact of LFR 1.0305086071987481\n",
      "f1 macro of LFR 0.658561138855683\n",
      "Disparate Impact of train 0.8365618756900072\n",
      "Disparate Impact of origin 0.7589693294139703\n",
      "f1 macro of origin 0.6671233478161723\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7589693294139703\n",
      "f1 macro of RW 0.6663354740831928\n",
      "Disparate Impact of train 0.8365618756900072\n",
      "Disparate Impact of DIremover 0.8238646302711006\n",
      "f1 macro of DIremover 0.6551161366564257\n",
      "Disparate Impact of train 0.9084322839018972\n",
      "Disparate Impact of LFR 0.9262466662614462\n",
      "f1 macro of LFR 0.6580063728690161\n",
      "Disparate Impact of train 0.8255144609991236\n",
      "Disparate Impact of origin 0.7930256039191292\n",
      "f1 macro of origin 0.6683866750868426\n",
      "Disparate Impact of train 0.9999999999999998\n",
      "Disparate Impact of RW 0.8315974253949677\n",
      "f1 macro of RW 0.6534984415023299\n",
      "Disparate Impact of train 0.8255144609991236\n",
      "Disparate Impact of DIremover 0.9005893170609379\n",
      "f1 macro of DIremover 0.6714028635547034\n",
      "Disparate Impact of train 0.9335163061026801\n",
      "Disparate Impact of LFR 1.0266410320711081\n",
      "f1 macro of LFR 0.6569119073370696\n",
      "Disparate Impact of train 0.8691187252553888\n",
      "Disparate Impact of origin 0.7869882333902251\n",
      "f1 macro of origin 0.6639314479363302\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7890306342208856\n",
      "f1 macro of RW 0.6627762476946953\n",
      "Disparate Impact of train 0.8691187252553888\n",
      "Disparate Impact of DIremover 0.9049719082483576\n",
      "f1 macro of DIremover 0.6440421395250607\n",
      "Disparate Impact of train 0.9667044809982983\n",
      "Disparate Impact of LFR 0.9263535491967042\n",
      "f1 macro of LFR 0.6634128611853891\n",
      "Disparate Impact of train 0.8380368243724197\n",
      "Disparate Impact of origin 0.8042013238467133\n",
      "f1 macro of origin 0.6661476454683652\n",
      "Disparate Impact of train 0.9999999999999998\n",
      "Disparate Impact of RW 0.7961162198385994\n",
      "f1 macro of RW 0.6678239763311508\n",
      "Disparate Impact of train 0.8380368243724197\n",
      "Disparate Impact of DIremover 0.7951115506362548\n",
      "f1 macro of DIremover 0.6705726966228842\n",
      "Disparate Impact of train 0.8771494175053506\n",
      "Disparate Impact of LFR 0.946201531055306\n",
      "f1 macro of LFR 0.6699417732026428\n",
      "Disparate Impact of train 0.8905971175332638\n",
      "Disparate Impact of origin 0.8158590035070306\n",
      "f1 macro of origin 0.663901490602722\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.8136197567743683\n",
      "f1 macro of RW 0.6651060411588392\n",
      "Disparate Impact of train 0.8905971175332638\n",
      "Disparate Impact of DIremover 0.8580095794623632\n",
      "f1 macro of DIremover 0.660363520619208\n",
      "Disparate Impact of train 1.0239268843705072\n",
      "Disparate Impact of LFR 1.0257853299110293\n",
      "f1 macro of LFR 0.6623500304669037\n",
      "Disparate Impact of train 0.8389732734536648\n",
      "Disparate Impact of origin 0.7605480894775188\n",
      "f1 macro of origin 0.6586885375122364\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7591900825261164\n",
      "f1 macro of RW 0.665470062427221\n",
      "Disparate Impact of train 0.8389732734536648\n",
      "Disparate Impact of DIremover 0.8666331234175161\n",
      "f1 macro of DIremover 0.6589915542624128\n",
      "Disparate Impact of train 0.9279127473355658\n",
      "Disparate Impact of LFR 0.8757219127015848\n",
      "f1 macro of LFR 0.6691165887118526\n",
      "Disparate Impact of train 0.8277472073306096\n",
      "Disparate Impact of origin 0.7615822643364769\n",
      "f1 macro of origin 0.6587554854086632\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7592437312832432\n",
      "f1 macro of RW 0.659297599312335\n",
      "Disparate Impact of train 0.8277472073306096\n",
      "Disparate Impact of DIremover 0.8456056914340402\n",
      "f1 macro of DIremover 0.6593582312620906\n",
      "Disparate Impact of train 0.9438819875776397\n",
      "Disparate Impact of LFR 0.9464973463599662\n",
      "f1 macro of LFR 0.6592446104863776\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv('../data/report_preprocess_compas_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path,var_list,pa):\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education',\n",
    "                'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "                'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                'native-country', 'Y']\n",
    "    na_values=['?']\n",
    "    pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "    label_dict={'>50K.':1,'>50K':1,'<=50K.':0,'<=50K':0}\n",
    "    train_path = os.path.join(data_path, 'adult.data')\n",
    "    test_path = os.path.join(data_path, 'adult.test')\n",
    "    train = pd.read_csv(train_path, header=None,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    test = pd.read_csv(test_path, header=0,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    messydata = pd.concat([test, train], ignore_index=True)[var_list+[pa,'Y']]\n",
    "    messydata=messydata.rename(columns={pa:'S'})\n",
    "    messydata['S']=messydata['S'].replace(pa_dict)\n",
    "    messydata['Y']=messydata['Y'].replace(label_dict)\n",
    "    messydata=messydata[(messydata['S']==0)|(messydata['S']==1)]\n",
    "    for col in var_list+['S','Y']:\n",
    "        messydata[col]=messydata[col].astype('int64')\n",
    "    messydata['W']=1\n",
    "    bins_capitalgain=[100,3500,7500,10000]\n",
    "    bins_capitalloss=[100,1600,1900,2200]\n",
    "    bins_age=[26,36,46,56]\n",
    "    bins_hours=[21,36,46,61]\n",
    "\n",
    "    messydata=categerise(messydata,'age',bins_age)\n",
    "    messydata=categerise(messydata,'hours-per-week',bins_hours)\n",
    "    messydata=categerise(messydata,'capital-gain',bins_capitalgain)\n",
    "    messydata=categerise(messydata,'capital-loss',bins_capitalloss)\n",
    "    \n",
    "    return messydata\n",
    "\n",
    "def categerise(df,col,bins):\n",
    "    for i in range(len(bins)+1):\n",
    "        if i == 0:\n",
    "            df.loc[df[col] < bins[i], col] = i\n",
    "        elif i == len(bins):\n",
    "            df.loc[df[col] >= bins[i-1], col] = i\n",
    "        else:\n",
    "            df.loc[(df[col] >= bins[i-1])& (df[col] < bins[i]), col] = i        \n",
    "    return df\n",
    "\n",
    "def choose_x(var_list,messydata):\n",
    "    tv_dist=dict()\n",
    "    for x_name in var_list:\n",
    "        x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "        dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "        tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    x_list=[]\n",
    "    for key,val in tv_dist.items():\n",
    "        if val>0.1:\n",
    "            x_list+=[key]  \n",
    "    return x_list,tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='..//data//adult'\n",
    "var_list=['hours-per-week','age','capital-gain','capital-loss','education-num'] #,'education-num'\n",
    "pa='race'\n",
    "favorable_label = 1\n",
    "var_dim=len(var_list)\n",
    "\n",
    "messydata = load_data(data_path,var_list,pa)\n",
    "x_list,tv_dist = choose_x(var_list,messydata)\n",
    "messydata=messydata.rename(columns={'S':pa})\n",
    "cd=BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=messydata,label_names='Y',protected_attribute_names=[pa])\n",
    "train,test = cd.split([0.4], shuffle=True) \n",
    "valid,test = test.split([0.3], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.4172208918780259\n",
      "Disparate Impact of origin 0.42191947586702916\n",
      "f1 macro of origin 0.6824367895587713\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.427539518219476\n",
      "f1 macro of RW 0.6806524556317192\n",
      "Disparate Impact of train 0.4172208918780259\n",
      "Disparate Impact of DIremover 0.45325924090779085\n",
      "f1 macro of DIremover 0.6770051707768875\n",
      "Disparate Impact of train 0.7957295462799464\n",
      "Disparate Impact of LFR 0.9057899639263494\n",
      "f1 macro of LFR 0.6926326573082515\n",
      "Disparate Impact of train 0.4821497649060907\n",
      "Disparate Impact of origin 0.43924953095684804\n",
      "f1 macro of origin 0.6817760750473485\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.47618272790139526\n",
      "f1 macro of RW 0.6775300833076211\n",
      "Disparate Impact of train 0.4821497649060907\n",
      "Disparate Impact of DIremover 0.4709819543480859\n",
      "f1 macro of DIremover 0.6810161760758444\n",
      "Disparate Impact of train 0.8128851988115321\n",
      "Disparate Impact of LFR 0.891769203267237\n",
      "f1 macro of LFR 0.7069633280183247\n",
      "Disparate Impact of train 0.4901679421631508\n",
      "Disparate Impact of origin 0.4661482323813911\n",
      "f1 macro of origin 0.6864512806168456\n",
      "Disparate Impact of train 0.9999999999999999\n",
      "Disparate Impact of RW 0.48008676227311914\n",
      "f1 macro of RW 0.684429020200299\n",
      "Disparate Impact of train 0.4901679421631508\n",
      "Disparate Impact of DIremover 0.46325290174548184\n",
      "f1 macro of DIremover 0.6866503077109729\n",
      "Disparate Impact of train 0.9054325133920524\n",
      "Disparate Impact of LFR 0.8923378058305447\n",
      "f1 macro of LFR 0.7036126725231289\n",
      "Disparate Impact of train 0.4286754531509251\n",
      "Disparate Impact of origin 0.5465008559160345\n",
      "f1 macro of origin 0.6855733533221295\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.5232877842236947\n",
      "f1 macro of RW 0.6845378162496174\n",
      "Disparate Impact of train 0.4286754531509251\n",
      "Disparate Impact of DIremover 0.515060329397221\n",
      "f1 macro of DIremover 0.6838553907964382\n",
      "Disparate Impact of train 0.7844472535355982\n",
      "Disparate Impact of LFR 0.8685453779979004\n",
      "f1 macro of LFR 0.7106943112427666\n",
      "Disparate Impact of train 0.43113835169416787\n",
      "Disparate Impact of origin 0.4497593223712033\n",
      "f1 macro of origin 0.6823954244428023\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.45666409416975945\n",
      "f1 macro of RW 0.6862543213937669\n",
      "Disparate Impact of train 0.43113835169416787\n",
      "Disparate Impact of DIremover 0.449390969117828\n",
      "f1 macro of DIremover 0.6706230879415809\n",
      "Disparate Impact of train 0.7889978611132457\n",
      "Disparate Impact of LFR 0.9116616794066342\n",
      "f1 macro of LFR 0.6855009535975707\n",
      "Disparate Impact of train 0.47329393766534034\n",
      "Disparate Impact of origin 0.4752018105172565\n",
      "f1 macro of origin 0.6827331349804228\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.4807459767752002\n",
      "f1 macro of RW 0.6838248507878502\n",
      "Disparate Impact of train 0.47329393766534034\n",
      "Disparate Impact of DIremover 0.503606624621853\n",
      "f1 macro of DIremover 0.6873828174715189\n",
      "Disparate Impact of train 0.8431633918396105\n",
      "Disparate Impact of LFR 0.9262427887306688\n",
      "f1 macro of LFR 0.6932259666445554\n",
      "Disparate Impact of train 0.4730467970746653\n",
      "Disparate Impact of origin 0.4597315386932532\n",
      "f1 macro of origin 0.6848407573938835\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.4724191251769679\n",
      "f1 macro of RW 0.6717601132859565\n",
      "Disparate Impact of train 0.4730467970746653\n",
      "Disparate Impact of DIremover 0.4556120729048836\n",
      "f1 macro of DIremover 0.6826754781690134\n",
      "Disparate Impact of train 0.8138463039476028\n",
      "Disparate Impact of LFR 0.7935453741750349\n",
      "f1 macro of LFR 0.6973635696687646\n",
      "Disparate Impact of train 0.5155021954892048\n",
      "Disparate Impact of origin 0.4463808403720731\n",
      "f1 macro of origin 0.6809455057061519\n",
      "Disparate Impact of train 0.9999999999999999\n",
      "Disparate Impact of RW 0.453357765787777\n",
      "f1 macro of RW 0.6719124106222254\n",
      "Disparate Impact of train 0.5155021954892048\n",
      "Disparate Impact of DIremover 0.4519895715958552\n",
      "f1 macro of DIremover 0.6759683426948714\n",
      "Disparate Impact of train 0.8332903947183923\n",
      "Disparate Impact of LFR 0.7707024309918967\n",
      "f1 macro of LFR 0.6925318611881627\n",
      "Disparate Impact of train 0.46792146290086195\n",
      "Disparate Impact of origin 0.46322208523338054\n",
      "f1 macro of origin 0.6798152902505727\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.47575901963995887\n",
      "f1 macro of RW 0.6767858388353112\n",
      "Disparate Impact of train 0.46792146290086195\n",
      "Disparate Impact of DIremover 0.4686781573705355\n",
      "f1 macro of DIremover 0.6814300226715777\n",
      "Disparate Impact of train 0.7705653018037572\n",
      "Disparate Impact of LFR 0.8176115458219324\n",
      "f1 macro of LFR 0.6970686157112281\n",
      "Disparate Impact of train 0.4380118279965271\n",
      "Disparate Impact of origin 0.4818075543725935\n",
      "f1 macro of origin 0.645877316443819\n",
      "Disparate Impact of train 0.9999999999999999\n",
      "Disparate Impact of RW 0.4727823408180636\n",
      "f1 macro of RW 0.6492369833334652\n",
      "Disparate Impact of train 0.4380118279965271\n",
      "Disparate Impact of DIremover 0.4699732361935743\n",
      "f1 macro of DIremover 0.6578569458337964\n",
      "Disparate Impact of train 0.8853235139400315\n",
      "Disparate Impact of LFR 0.9009212671151335\n",
      "f1 macro of LFR 0.6927152086664886\n"
     ]
    }
   ],
   "source": [
    "para={'x_list':x_list,'Theta':1e-2}\n",
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv('../data/report_preprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI of train</th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.417221</td>\n",
       "      <td>0.421919</td>\n",
       "      <td>0.682437</td>\n",
       "      <td>0.815829</td>\n",
       "      <td>0.788811</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.42754</td>\n",
       "      <td>0.680652</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.787852</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.417221</td>\n",
       "      <td>0.453259</td>\n",
       "      <td>0.677005</td>\n",
       "      <td>0.814855</td>\n",
       "      <td>0.786063</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.79573</td>\n",
       "      <td>0.90579</td>\n",
       "      <td>0.692633</td>\n",
       "      <td>0.810344</td>\n",
       "      <td>0.790942</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.48215</td>\n",
       "      <td>0.43925</td>\n",
       "      <td>0.681776</td>\n",
       "      <td>0.820288</td>\n",
       "      <td>0.792351</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>0.67753</td>\n",
       "      <td>0.818545</td>\n",
       "      <td>0.789842</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.48215</td>\n",
       "      <td>0.470982</td>\n",
       "      <td>0.681016</td>\n",
       "      <td>0.819622</td>\n",
       "      <td>0.79176</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.812885</td>\n",
       "      <td>0.891769</td>\n",
       "      <td>0.706963</td>\n",
       "      <td>0.814496</td>\n",
       "      <td>0.800456</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.490168</td>\n",
       "      <td>0.466148</td>\n",
       "      <td>0.686451</td>\n",
       "      <td>0.817366</td>\n",
       "      <td>0.791185</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.480087</td>\n",
       "      <td>0.684429</td>\n",
       "      <td>0.816649</td>\n",
       "      <td>0.790023</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.490168</td>\n",
       "      <td>0.463253</td>\n",
       "      <td>0.68665</td>\n",
       "      <td>0.817213</td>\n",
       "      <td>0.79121</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.905433</td>\n",
       "      <td>0.892338</td>\n",
       "      <td>0.703613</td>\n",
       "      <td>0.809831</td>\n",
       "      <td>0.795334</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.428675</td>\n",
       "      <td>0.546501</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>0.818904</td>\n",
       "      <td>0.791858</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523288</td>\n",
       "      <td>0.684538</td>\n",
       "      <td>0.819109</td>\n",
       "      <td>0.791491</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.428675</td>\n",
       "      <td>0.51506</td>\n",
       "      <td>0.683855</td>\n",
       "      <td>0.818443</td>\n",
       "      <td>0.790931</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.784447</td>\n",
       "      <td>0.868545</td>\n",
       "      <td>0.710694</td>\n",
       "      <td>0.815265</td>\n",
       "      <td>0.800982</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.431138</td>\n",
       "      <td>0.449759</td>\n",
       "      <td>0.682395</td>\n",
       "      <td>0.818392</td>\n",
       "      <td>0.790257</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.456664</td>\n",
       "      <td>0.686254</td>\n",
       "      <td>0.818648</td>\n",
       "      <td>0.792029</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.431138</td>\n",
       "      <td>0.449391</td>\n",
       "      <td>0.670623</td>\n",
       "      <td>0.815777</td>\n",
       "      <td>0.784104</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.788998</td>\n",
       "      <td>0.911662</td>\n",
       "      <td>0.685501</td>\n",
       "      <td>0.813727</td>\n",
       "      <td>0.789723</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.473294</td>\n",
       "      <td>0.475202</td>\n",
       "      <td>0.682733</td>\n",
       "      <td>0.820186</td>\n",
       "      <td>0.791905</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.480746</td>\n",
       "      <td>0.683825</td>\n",
       "      <td>0.820442</td>\n",
       "      <td>0.792477</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.473294</td>\n",
       "      <td>0.503607</td>\n",
       "      <td>0.687383</td>\n",
       "      <td>0.821159</td>\n",
       "      <td>0.794293</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.843163</td>\n",
       "      <td>0.926243</td>\n",
       "      <td>0.693226</td>\n",
       "      <td>0.813214</td>\n",
       "      <td>0.793526</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.473047</td>\n",
       "      <td>0.459732</td>\n",
       "      <td>0.684841</td>\n",
       "      <td>0.816136</td>\n",
       "      <td>0.789579</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.472419</td>\n",
       "      <td>0.67176</td>\n",
       "      <td>0.813214</td>\n",
       "      <td>0.782708</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.473047</td>\n",
       "      <td>0.455612</td>\n",
       "      <td>0.682675</td>\n",
       "      <td>0.815777</td>\n",
       "      <td>0.788493</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.813846</td>\n",
       "      <td>0.793545</td>\n",
       "      <td>0.697364</td>\n",
       "      <td>0.810857</td>\n",
       "      <td>0.792788</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.515502</td>\n",
       "      <td>0.446381</td>\n",
       "      <td>0.680946</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.788283</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.453358</td>\n",
       "      <td>0.671912</td>\n",
       "      <td>0.813522</td>\n",
       "      <td>0.783271</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.515502</td>\n",
       "      <td>0.45199</td>\n",
       "      <td>0.675968</td>\n",
       "      <td>0.814803</td>\n",
       "      <td>0.785547</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.83329</td>\n",
       "      <td>0.770702</td>\n",
       "      <td>0.692532</td>\n",
       "      <td>0.811318</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.467921</td>\n",
       "      <td>0.463222</td>\n",
       "      <td>0.679815</td>\n",
       "      <td>0.814393</td>\n",
       "      <td>0.785782</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0.475759</td>\n",
       "      <td>0.676786</td>\n",
       "      <td>0.814188</td>\n",
       "      <td>0.784364</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.467921</td>\n",
       "      <td>0.468678</td>\n",
       "      <td>0.68143</td>\n",
       "      <td>0.814547</td>\n",
       "      <td>0.786554</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.770565</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.697069</td>\n",
       "      <td>0.80978</td>\n",
       "      <td>0.791396</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.438012</td>\n",
       "      <td>0.481808</td>\n",
       "      <td>0.645877</td>\n",
       "      <td>0.813419</td>\n",
       "      <td>0.773266</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.472782</td>\n",
       "      <td>0.649237</td>\n",
       "      <td>0.814547</td>\n",
       "      <td>0.775173</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.438012</td>\n",
       "      <td>0.469973</td>\n",
       "      <td>0.657857</td>\n",
       "      <td>0.816085</td>\n",
       "      <td>0.779542</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.885324</td>\n",
       "      <td>0.900921</td>\n",
       "      <td>0.692715</td>\n",
       "      <td>0.815419</td>\n",
       "      <td>0.794268</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DI of train        DI  f1 macro  f1 micro f1 weighted     method\n",
       "0     0.417221  0.421919  0.682437  0.815829    0.788811     origin\n",
       "1            1   0.42754  0.680652  0.815367    0.787852         RW\n",
       "2     0.417221  0.453259  0.677005  0.814855    0.786063  DIremover\n",
       "3      0.79573   0.90579  0.692633  0.810344    0.790942        LFR\n",
       "4      0.48215   0.43925  0.681776  0.820288    0.792351     origin\n",
       "5            1  0.476183   0.67753  0.818545    0.789842         RW\n",
       "6      0.48215  0.470982  0.681016  0.819622     0.79176  DIremover\n",
       "7     0.812885  0.891769  0.706963  0.814496    0.800456        LFR\n",
       "8     0.490168  0.466148  0.686451  0.817366    0.791185     origin\n",
       "9          1.0  0.480087  0.684429  0.816649    0.790023         RW\n",
       "10    0.490168  0.463253   0.68665  0.817213     0.79121  DIremover\n",
       "11    0.905433  0.892338  0.703613  0.809831    0.795334        LFR\n",
       "12    0.428675  0.546501  0.685573  0.818904    0.791858     origin\n",
       "13           1  0.523288  0.684538  0.819109    0.791491         RW\n",
       "14    0.428675   0.51506  0.683855  0.818443    0.790931  DIremover\n",
       "15    0.784447  0.868545  0.710694  0.815265    0.800982        LFR\n",
       "16    0.431138  0.449759  0.682395  0.818392    0.790257     origin\n",
       "17         1.0  0.456664  0.686254  0.818648    0.792029         RW\n",
       "18    0.431138  0.449391  0.670623  0.815777    0.784104  DIremover\n",
       "19    0.788998  0.911662  0.685501  0.813727    0.789723        LFR\n",
       "20    0.473294  0.475202  0.682733  0.820186    0.791905     origin\n",
       "21         1.0  0.480746  0.683825  0.820442    0.792477         RW\n",
       "22    0.473294  0.503607  0.687383  0.821159    0.794293  DIremover\n",
       "23    0.843163  0.926243  0.693226  0.813214    0.793526        LFR\n",
       "24    0.473047  0.459732  0.684841  0.816136    0.789579     origin\n",
       "25           1  0.472419   0.67176  0.813214    0.782708         RW\n",
       "26    0.473047  0.455612  0.682675  0.815777    0.788493  DIremover\n",
       "27    0.813846  0.793545  0.697364  0.810857    0.792788        LFR\n",
       "28    0.515502  0.446381  0.680946  0.816239    0.788283     origin\n",
       "29         1.0  0.453358  0.671912  0.813522    0.783271         RW\n",
       "30    0.515502   0.45199  0.675968  0.814803    0.785547  DIremover\n",
       "31     0.83329  0.770702  0.692532  0.811318    0.791265        LFR\n",
       "32    0.467921  0.463222  0.679815  0.814393    0.785782     origin\n",
       "33           1  0.475759  0.676786  0.814188    0.784364         RW\n",
       "34    0.467921  0.468678   0.68143  0.814547    0.786554  DIremover\n",
       "35    0.770565  0.817612  0.697069   0.80978    0.791396        LFR\n",
       "36    0.438012  0.481808  0.645877  0.813419    0.773266     origin\n",
       "37         1.0  0.472782  0.649237  0.814547    0.775173         RW\n",
       "38    0.438012  0.469973  0.657857  0.816085    0.779542  DIremover\n",
       "39    0.885324  0.900921  0.692715  0.815419    0.794268        LFR"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.to_csv('../data/report_preprocess_compas_'+str(pa)+'_'+str(para['Theta'])+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grouper for 'W' not 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mBaselinepreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43massess\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpartial\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 82\u001b[39m, in \u001b[36mBaselinepreprocess.assess\u001b[39m\u001b[34m(self, method, para)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34massess\u001b[39m(\u001b[38;5;28mself\u001b[39m,method,para=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m para != \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         y_pred,di_train = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m         y_pred,di_train = \u001b[38;5;28mself\u001b[39m.prediction(method)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mBaselinepreprocess.prediction\u001b[39m\u001b[34m(self, method, para)\u001b[39m\n\u001b[32m     48\u001b[39m     var_list=\u001b[38;5;28mself\u001b[39m.train.feature_names.copy()\n\u001b[32m     49\u001b[39m     var_list.remove(\u001b[38;5;28mself\u001b[39m.pa)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     projpre=\u001b[43mProjpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mx_list\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     train_tranf=projpre.preprocess(method,para[\u001b[33m'\u001b[39m\u001b[33mTheta\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     53\u001b[39m di=\u001b[38;5;28mself\u001b[39m.DisparateImpact(train_tranf)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mProjpreprocess.__init__\u001b[39m\u001b[34m(self, traindata, x_list, var_list, K, e)\u001b[39m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mself\u001b[39m.C=c_generate(\u001b[38;5;28mself\u001b[39m.x_range)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# DEBUGGING\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# print(type(self.df))\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# print(self.arg_list)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# print(self.df['W'])\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# print(check_duplicate_columns_equal(self.df))\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28mself\u001b[39m.df = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marg_list\u001b[49m\u001b[43m+\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mY\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mW\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marg_list\u001b[49m\u001b[43m+\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mY\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m.sum()\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m.distribution_generator()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\work\\repair\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9186\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9189\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\work\\repair\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\work\\repair\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1038\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1034\u001b[39m     in_axis, name, gpr = \u001b[38;5;28;01mTrue\u001b[39;00m, gpr, obj[gpr]\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gpr.ndim != \u001b[32m1\u001b[39m:\n\u001b[32m   1036\u001b[39m         \u001b[38;5;66;03m# non-unique columns; raise here to get the name in the\u001b[39;00m\n\u001b[32m   1037\u001b[39m         \u001b[38;5;66;03m# exception message\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGrouper for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not 1-dimensional\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1039\u001b[39m     exclusions.add(name)\n\u001b[32m   1040\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m obj._is_level_reference(gpr, axis=axis):\n",
      "\u001b[31mValueError\u001b[39m: Grouper for 'W' not 1-dimensional"
     ]
    }
   ],
   "source": [
    "Baselinepreprocess(train,test).assess('partial',para=para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_list ====== \n",
      "['hours-per-week', 'age', 'capital-gain', 'capital-loss', 'education-num', 'W']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names, label_names, and protected_attribute_names should match between this and other dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mBaselinepreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43massess\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpartial\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 82\u001b[39m, in \u001b[36mBaselinepreprocess.assess\u001b[39m\u001b[34m(self, method, para)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34massess\u001b[39m(\u001b[38;5;28mself\u001b[39m,method,para=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m para != \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         y_pred,di_train = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m         y_pred,di_train = \u001b[38;5;28mself\u001b[39m.prediction(method)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mBaselinepreprocess.prediction\u001b[39m\u001b[34m(self, method, para)\u001b[39m\n\u001b[32m     49\u001b[39m     var_list.remove(\u001b[38;5;28mself\u001b[39m.pa)\n\u001b[32m     50\u001b[39m     projpre=Projpreprocess(\u001b[38;5;28mself\u001b[39m.train,para[\u001b[33m'\u001b[39m\u001b[33mx_list\u001b[39m\u001b[33m'\u001b[39m],var_list,K,e)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     train_tranf=\u001b[43mprojpre\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTheta\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m di=\u001b[38;5;28mself\u001b[39m.DisparateImpact(train_tranf)\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mDisparate Impact of train\u001b[39m\u001b[33m'\u001b[39m,di)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 126\u001b[39m, in \u001b[36mProjpreprocess.preprocess\u001b[39m\u001b[34m(self, method, Theta)\u001b[39m\n\u001b[32m    113\u001b[39m binaryLabelDataset.instance_weights = df_proj[\u001b[33m'\u001b[39m\u001b[33mW\u001b[39m\u001b[33m'\u001b[39m].tolist()\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# return binaryLabelDataset.align_datasets(self.train)\u001b[39;00m\n\u001b[32m    115\u001b[39m \n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# print(\"preprocess function ===================\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# print(type(self.train))\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# print(self.train)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43malign_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinaryLabelDataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\work\\repair\\.venv\\Lib\\site-packages\\aif360\\datasets\\structured_dataset.py:327\u001b[39m, in \u001b[36mStructuredDataset.align_datasets\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Align the other dataset features, labels and protected_attributes to\u001b[39;00m\n\u001b[32m    314\u001b[39m \u001b[33;03mthis dataset.\u001b[39;00m\n\u001b[32m    315\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    StructuredDataset: New aligned dataset\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m.feature_names) != \u001b[38;5;28mset\u001b[39m(other.feature_names) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m.label_names) != \u001b[38;5;28mset\u001b[39m(other.label_names) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m.protected_attribute_names)\n\u001b[32m    326\u001b[39m         != \u001b[38;5;28mset\u001b[39m(other.protected_attribute_names)):\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfeature_names, label_names, and protected_attribute_names \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mshould match between this and other dataset.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# New dataset\u001b[39;00m\n\u001b[32m    332\u001b[39m new = other.copy()\n",
      "\u001b[31mValueError\u001b[39m: feature_names, label_names, and protected_attribute_names should match between this and other dataset."
     ]
    }
   ],
   "source": [
    "Baselinepreprocess(train,test).assess('partial',para=para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.8456240675896421\n",
      "Disparate Impact of LFR 0.93713336144422\n",
      "f1 macro of LFR 0.6988885331213838\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI of train</th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.845624</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.698889</td>\n",
       "      <td>0.812548</td>\n",
       "      <td>0.795925</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DI of train        DI  f1 macro  f1 micro f1 weighted method\n",
       "0    0.845624  0.937133  0.698889  0.812548    0.795925    LFR"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Baselinepreprocess(train,test).assess('LFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.9999999999999999\n",
      "Disparate Impact of RW 0.48223483793688754\n",
      "f1 macro of RW 0.6893390802908452\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI of train</th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.482235</td>\n",
       "      <td>0.689339</td>\n",
       "      <td>0.818802</td>\n",
       "      <td>0.794531</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DI of train        DI  f1 macro  f1 micro f1 weighted method\n",
       "0         1.0  0.482235  0.689339  0.818802    0.794531     RW"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Baselinepreprocess(train,test).assess('RW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baselinepreprocess(train,test).assess('DIremover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baselinepreprocess(train,test).assess('origin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
