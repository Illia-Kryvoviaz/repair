{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset, CompasDataset\n",
    "\n",
    "from humancompatible.repair.methods.data_analysis import rdata_analysis\n",
    "from humancompatible.repair.preprocess.baseline_preprocess import Baselinepreprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compas dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = 'race'\n",
    "label_map = {1.0: 'Did recid.', 0.0: 'No recid.'}\n",
    "protected_attribute_maps = {1.0: 'Caucasian', 0.0: 'Not Caucasian'}\n",
    "privileged_groups = [{pa: 1}]\n",
    "unprivileged_groups = [{pa: 0}]\n",
    "cd = CompasDataset(protected_attribute_names=[pa],privileged_classes=[['Caucasian'],[1]], \n",
    "                    metadata={'label_map': label_map,'protected_attribute_maps': protected_attribute_maps},\n",
    "                    features_to_drop=['age', 'sex', 'c_charge_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.88268198865032\n",
      "Disparate Impact of origin 0.7990410000946503\n",
      "f1 macro of origin 0.6606574329136953\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7826524620417751\n",
      "f1 macro of RW 0.6545518585569539\n",
      "Disparate Impact of train 0.88268198865032\n",
      "Disparate Impact of DIremover 0.9068771372318745\n",
      "f1 macro of DIremover 0.6380307369175431\n",
      "Disparate Impact of train 0.9224133615871055\n",
      "Disparate Impact of LFR 0.8785597034899163\n",
      "f1 macro of LFR 0.6639718528842544\n",
      "Disparate Impact of train 0.8036080534443975\n",
      "Disparate Impact of origin 0.7933092665979047\n",
      "f1 macro of origin 0.6609621777941983\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7671817527586758\n",
      "f1 macro of RW 0.6686182076847955\n",
      "Disparate Impact of train 0.8036080534443975\n",
      "Disparate Impact of DIremover 0.8868412177698747\n",
      "f1 macro of DIremover 0.6691445795313495\n",
      "Disparate Impact of train 0.9683940526910703\n",
      "Disparate Impact of LFR 1.0373354850277927\n",
      "f1 macro of LFR 0.663497173954508\n",
      "Disparate Impact of train 0.8171128002432351\n",
      "Disparate Impact of origin 0.7717961488334106\n",
      "f1 macro of origin 0.6611755339192162\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.779382747045313\n",
      "f1 macro of RW 0.6555705573667954\n",
      "Disparate Impact of train 0.8171128002432351\n",
      "Disparate Impact of DIremover 0.8581793240398282\n",
      "f1 macro of DIremover 0.6576411610898631\n",
      "Disparate Impact of train 0.9803767791460098\n",
      "Disparate Impact of LFR 1.0034758836164812\n",
      "f1 macro of LFR 0.6540799247963297\n",
      "Disparate Impact of train 0.8486794824662311\n",
      "Disparate Impact of origin 0.8134403935185184\n",
      "f1 macro of origin 0.661519357780223\n",
      "Disparate Impact of train 0.9999999999999998\n",
      "Disparate Impact of RW 0.8159212351117638\n",
      "f1 macro of RW 0.6562421123498604\n",
      "Disparate Impact of train 0.8486794824662311\n",
      "Disparate Impact of DIremover 0.8439032422636452\n",
      "f1 macro of DIremover 0.682468692588647\n",
      "Disparate Impact of train 0.9800861877660147\n",
      "Disparate Impact of LFR 0.9337917433479028\n",
      "f1 macro of LFR 0.6881343457734217\n",
      "Disparate Impact of train 0.8025331564218297\n",
      "Disparate Impact of origin 0.7644519128865634\n",
      "f1 macro of origin 0.6733536988630995\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7860377369006252\n",
      "f1 macro of RW 0.6663897135840146\n",
      "Disparate Impact of train 0.8025331564218297\n",
      "Disparate Impact of DIremover 0.7268491555037856\n",
      "f1 macro of DIremover 0.6654591357890396\n",
      "Disparate Impact of train 0.9788444205952684\n",
      "Disparate Impact of LFR 0.9360140866455608\n",
      "f1 macro of LFR 0.6687727803092367\n",
      "Disparate Impact of train 0.8383036667053125\n",
      "Disparate Impact of origin 0.7668228458192689\n",
      "f1 macro of origin 0.6533751054226751\n",
      "Disparate Impact of train 0.9999999999999998\n",
      "Disparate Impact of RW 0.7773383489792377\n",
      "f1 macro of RW 0.6485126892085248\n",
      "Disparate Impact of train 0.8383036667053125\n",
      "Disparate Impact of DIremover 0.8236274823190955\n",
      "f1 macro of DIremover 0.6618549246000048\n",
      "Disparate Impact of train 0.8831456129433727\n",
      "Disparate Impact of LFR 0.8242753259550551\n",
      "f1 macro of LFR 0.655617562045865\n",
      "Disparate Impact of train 0.8482290464954441\n",
      "Disparate Impact of origin 0.8035858427318998\n",
      "f1 macro of origin 0.6535478179382244\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.8114169708708933\n",
      "f1 macro of RW 0.65566003496706\n",
      "Disparate Impact of train 0.8482290464954441\n",
      "Disparate Impact of DIremover 0.8310976558293147\n",
      "f1 macro of DIremover 0.6555079888293178\n",
      "Disparate Impact of train 0.9375808441623052\n",
      "Disparate Impact of LFR 0.9067267188121201\n",
      "f1 macro of LFR 0.660114156673766\n",
      "Disparate Impact of train 0.8491273692264483\n",
      "Disparate Impact of origin 0.7137788296257486\n",
      "f1 macro of origin 0.6738823659819746\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7473392313200082\n",
      "f1 macro of RW 0.6707535271079528\n",
      "Disparate Impact of train 0.8491273692264483\n",
      "Disparate Impact of DIremover 0.741263282172373\n",
      "f1 macro of DIremover 0.6653512683819496\n",
      "Disparate Impact of train 0.9332846940636707\n",
      "Disparate Impact of LFR 0.8337015519733791\n",
      "f1 macro of LFR 0.6681396172921596\n",
      "Disparate Impact of train 0.8385102597268527\n",
      "Disparate Impact of origin 0.737549099639856\n",
      "f1 macro of origin 0.6731306017857919\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7440982895687787\n",
      "f1 macro of RW 0.6718516500151377\n",
      "Disparate Impact of train 0.8385102597268527\n",
      "Disparate Impact of DIremover 0.7568540145985401\n",
      "f1 macro of DIremover 0.6700681211175464\n",
      "Disparate Impact of train 0.968311019498756\n",
      "Disparate Impact of LFR 0.911780854197349\n",
      "f1 macro of LFR 0.6686550240870615\n",
      "Disparate Impact of train 0.8542487994792626\n",
      "Disparate Impact of origin 0.7578256866656436\n",
      "f1 macro of origin 0.6565022774151792\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7557406636123837\n",
      "f1 macro of RW 0.6565022774151792\n",
      "Disparate Impact of train 0.8542487994792626\n",
      "Disparate Impact of DIremover 0.7853347451276175\n",
      "f1 macro of DIremover 0.655788114634856\n",
      "Disparate Impact of train 0.9583078491335373\n",
      "Disparate Impact of LFR 0.9917210330666086\n",
      "f1 macro of LFR 0.6479354574944999\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv('../data/report_preprocess_compas_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path,var_list,pa):\n",
    "    \"\"\"\n",
    "    Load and clean the Adult dataset, and discretize selected attributes \n",
    "    (age, hours-per-week, capital-gain, capital-loss).\n",
    "\n",
    "    Parameters:\n",
    "        data_path (str): Path to the input data file.\n",
    "        var_list (list of str): List of non-protected attribute names.\n",
    "        pa (str): Name of the protected attribute.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned dataset with discretized attributes.\n",
    "    \"\"\"\n",
    "\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education',\n",
    "                'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "                'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                'native-country', 'Y']\n",
    "    na_values=['?']\n",
    "    pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "    label_dict={'>50K.':1,'>50K':1,'<=50K.':0,'<=50K':0}\n",
    "    train_path = os.path.join(data_path, 'adult.data')\n",
    "    test_path = os.path.join(data_path, 'adult.test')\n",
    "    train = pd.read_csv(train_path, header=None,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    test = pd.read_csv(test_path, header=0,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    messydata = pd.concat([test, train], ignore_index=True)[var_list+[pa,'Y']]\n",
    "    messydata=messydata.rename(columns={pa:'S'})\n",
    "    messydata['S']=messydata['S'].replace(pa_dict)\n",
    "    messydata['Y']=messydata['Y'].replace(label_dict)\n",
    "    messydata=messydata[(messydata['S']==0)|(messydata['S']==1)]\n",
    "    for col in var_list+['S','Y']:\n",
    "        messydata[col]=messydata[col].astype('int64')\n",
    "    messydata['W']=1\n",
    "\n",
    "    # Define bin thresholds for discretizing attributes.\n",
    "    bins_capitalgain=[100,3500,7500,10000]\n",
    "    bins_capitalloss=[100,1600,1900,2200]\n",
    "    bins_age=[26,36,46,56]\n",
    "    bins_hours=[21,36,46,61]\n",
    "\n",
    "    # Apply discretization to attributes using predefined bins.\n",
    "    messydata=categerise(messydata,'age',bins_age)\n",
    "    messydata=categerise(messydata,'hours-per-week',bins_hours)\n",
    "    messydata=categerise(messydata,'capital-gain',bins_capitalgain)\n",
    "    messydata=categerise(messydata,'capital-loss',bins_capitalloss)\n",
    "    \n",
    "    return messydata\n",
    "\n",
    "def categerise(df,col,bins):\n",
    "    # Apply discretization to attributes using predefined bins.\n",
    "    for i in range(len(bins)+1):\n",
    "        if i == 0:\n",
    "            df.loc[df[col] < bins[i], col] = i\n",
    "        elif i == len(bins):\n",
    "            df.loc[df[col] >= bins[i-1], col] = i\n",
    "        else:\n",
    "            df.loc[(df[col] >= bins[i-1])& (df[col] < bins[i]), col] = i        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_x(var_list,messydata):\n",
    "    \"\"\"\n",
    "    Select non-protected attributes to repair based on their \n",
    "    protected-attribute-wise Total Variation distance.\n",
    "\n",
    "    Attributes are selected if their Total Variation distance exceeds a threshold (default: 0.1).\n",
    "\n",
    "    Parameters:\n",
    "        var_list (list of str): List of non-protected attribute names.\n",
    "        messydata (pd.DataFrame): The cleaned dataset.\n",
    "\n",
    "    Returns:\n",
    "        x_list (list of str): List of non-protected attributes that need to be repaired.\n",
    "        tv_dist (dict): Dictionary mapping each non-protected attribute to its \n",
    "                        protected-attribute-wise Total Variation distance.\n",
    "    \"\"\"\n",
    "\n",
    "    tv_dist=dict()\n",
    "    for x_name in var_list:\n",
    "        x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "        dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "        tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    x_list=[]\n",
    "    for key,val in tv_dist.items():\n",
    "        if val>0.1:\n",
    "            x_list+=[key]  \n",
    "    return x_list,tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='..//data//adult'\n",
    "var_list=['hours-per-week','age','capital-gain','capital-loss','education-num'] #,'education-num'\n",
    "pa='race'\n",
    "favorable_label = 1\n",
    "var_dim=len(var_list)\n",
    "\n",
    "messydata = load_data(data_path,var_list,pa)\n",
    "x_list,tv_dist = choose_x(var_list,messydata)\n",
    "messydata=messydata.rename(columns={'S':pa})\n",
    "cd=BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=messydata,label_names='Y',protected_attribute_names=[pa])\n",
    "# train,test = cd.split([0.4], shuffle=True) \n",
    "# valid,test = test.split([0.3], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.5047295646456601\n",
      "Disparate Impact of origin 0.43384447781112045\n",
      "f1 macro of origin 0.6873499495899884\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.424028841499607\n",
      "f1 macro of RW 0.6802092930363968\n",
      "Disparate Impact of train 0.5047295646456601\n",
      "Disparate Impact of DIremover 0.4079993090603388\n",
      "f1 macro of DIremover 0.6738015015640795\n",
      "Disparate Impact of train 0.8233927395305995\n",
      "Disparate Impact of LFR 0.8527292796915192\n",
      "f1 macro of LFR 0.7036787732472928\n",
      "Disparate Impact of train 0.46625508009785355\n",
      "Disparate Impact of origin 0.46116931191508526\n",
      "f1 macro of origin 0.6869889279851386\n",
      "Disparate Impact of train 0.9999999999999999\n",
      "Disparate Impact of RW 0.4671465020563257\n",
      "f1 macro of RW 0.6794516354102634\n",
      "Disparate Impact of train 0.46625508009785355\n",
      "Disparate Impact of DIremover 0.44687666949114396\n",
      "f1 macro of DIremover 0.688378873582636\n",
      "Disparate Impact of train 0.8333115118577075\n",
      "Disparate Impact of LFR 0.8760194063951693\n",
      "f1 macro of LFR 0.6944630127833993\n",
      "Disparate Impact of train 0.44899407505270694\n",
      "Disparate Impact of origin 0.5617860962566845\n",
      "f1 macro of origin 0.674593248560809\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.566770733012306\n",
      "f1 macro of RW 0.6758583678388287\n",
      "Disparate Impact of train 0.44899407505270694\n",
      "Disparate Impact of DIremover 0.5695477439664218\n",
      "f1 macro of DIremover 0.6757713385373311\n",
      "Disparate Impact of train 0.7416242961880221\n",
      "Disparate Impact of LFR 0.9110427079447968\n",
      "f1 macro of LFR 0.7014027154066005\n",
      "Disparate Impact of train 0.4838436718805199\n",
      "Disparate Impact of origin 0.42884658916520924\n",
      "f1 macro of origin 0.6840375019368887\n",
      "Disparate Impact of train 0.9999999999999999\n",
      "Disparate Impact of RW 0.4247636901304325\n",
      "f1 macro of RW 0.682570769514191\n",
      "Disparate Impact of train 0.4838436718805199\n",
      "Disparate Impact of DIremover 0.4204060331773422\n",
      "f1 macro of DIremover 0.6748761723606409\n",
      "Disparate Impact of train 0.7894446033050959\n",
      "Disparate Impact of LFR 0.7459706628575398\n",
      "f1 macro of LFR 0.7021980258210927\n",
      "Disparate Impact of train 0.4989965140417532\n",
      "Disparate Impact of origin 0.3844108729743858\n",
      "f1 macro of origin 0.675129994149087\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.3902666483214089\n",
      "f1 macro of RW 0.6677210068654995\n",
      "Disparate Impact of train 0.4989965140417532\n",
      "Disparate Impact of DIremover 0.3912865913555992\n",
      "f1 macro of DIremover 0.6832078525918874\n",
      "Disparate Impact of train 0.8705276507350648\n",
      "Disparate Impact of LFR 0.728156285605773\n",
      "f1 macro of LFR 0.6986845887974902\n",
      "Disparate Impact of train 0.4795119083794541\n",
      "Disparate Impact of origin 0.4611590565626553\n",
      "f1 macro of origin 0.6676625252579179\n",
      "Disparate Impact of train 0.9999999999999999\n",
      "Disparate Impact of RW 0.45479584131962597\n",
      "f1 macro of RW 0.6670706577144898\n",
      "Disparate Impact of train 0.4795119083794541\n",
      "Disparate Impact of DIremover 0.45766731681583156\n",
      "f1 macro of DIremover 0.6696418595636258\n",
      "Disparate Impact of train 0.5902278097097712\n",
      "Disparate Impact of LFR 0.6687108788839413\n",
      "f1 macro of LFR 0.7020852109844624\n",
      "Disparate Impact of train 0.4632805046182495\n",
      "Disparate Impact of origin 0.43270045198061896\n",
      "f1 macro of origin 0.6679667801110549\n",
      "Disparate Impact of train 0.9999999999999999\n",
      "Disparate Impact of RW 0.4476746337848388\n",
      "f1 macro of RW 0.6600165829197139\n",
      "Disparate Impact of train 0.4632805046182495\n",
      "Disparate Impact of DIremover 0.4550275719231827\n",
      "f1 macro of DIremover 0.6607816540600542\n",
      "Disparate Impact of train 0.8892079607073547\n",
      "Disparate Impact of LFR 0.8368852895903397\n",
      "f1 macro of LFR 0.6876784090353472\n",
      "Disparate Impact of train 0.4928571428571428\n",
      "Disparate Impact of origin 0.4012627875175768\n",
      "f1 macro of origin 0.6841735556346312\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.4092076850405846\n",
      "f1 macro of RW 0.6846050196663407\n",
      "Disparate Impact of train 0.4928571428571428\n",
      "Disparate Impact of DIremover 0.44796697209521535\n",
      "f1 macro of DIremover 0.690715129362118\n",
      "Disparate Impact of train 0.8495085124552575\n",
      "Disparate Impact of LFR 0.8567818163228792\n",
      "f1 macro of LFR 0.7011836318767012\n",
      "Disparate Impact of train 0.48312934355621806\n",
      "Disparate Impact of origin 0.4728994559244468\n",
      "f1 macro of origin 0.6877101261261203\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.4652391453060641\n",
      "f1 macro of RW 0.6854149931294458\n",
      "Disparate Impact of train 0.48312934355621806\n",
      "Disparate Impact of DIremover 0.4582397566445928\n",
      "f1 macro of DIremover 0.6873571780230655\n",
      "Disparate Impact of train 0.8697145969246456\n",
      "Disparate Impact of LFR 0.9460385249800017\n",
      "f1 macro of LFR 0.697018932765774\n",
      "Disparate Impact of train 0.45539818185015213\n",
      "Disparate Impact of origin 0.5082325268817205\n",
      "f1 macro of origin 0.6915403663797755\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.526362881015071\n",
      "f1 macro of RW 0.6887300374581786\n",
      "Disparate Impact of train 0.45539818185015213\n",
      "Disparate Impact of DIremover 0.5384727085999057\n",
      "f1 macro of DIremover 0.7004366132180817\n",
      "Disparate Impact of train 0.6550296428980682\n",
      "Disparate Impact of LFR 0.8693799077821671\n",
      "f1 macro of LFR 0.6991074519111902\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv('../data/report_preprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI of train</th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50473</td>\n",
       "      <td>0.433844</td>\n",
       "      <td>0.68735</td>\n",
       "      <td>0.817828</td>\n",
       "      <td>0.792008</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.424029</td>\n",
       "      <td>0.680209</td>\n",
       "      <td>0.818238</td>\n",
       "      <td>0.789075</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50473</td>\n",
       "      <td>0.407999</td>\n",
       "      <td>0.673802</td>\n",
       "      <td>0.816956</td>\n",
       "      <td>0.785775</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.823393</td>\n",
       "      <td>0.852729</td>\n",
       "      <td>0.703679</td>\n",
       "      <td>0.812343</td>\n",
       "      <td>0.796661</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.466255</td>\n",
       "      <td>0.461169</td>\n",
       "      <td>0.686989</td>\n",
       "      <td>0.818802</td>\n",
       "      <td>0.79297</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.467147</td>\n",
       "      <td>0.679452</td>\n",
       "      <td>0.816751</td>\n",
       "      <td>0.788911</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.466255</td>\n",
       "      <td>0.446877</td>\n",
       "      <td>0.688379</td>\n",
       "      <td>0.819109</td>\n",
       "      <td>0.793689</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.833312</td>\n",
       "      <td>0.876019</td>\n",
       "      <td>0.694463</td>\n",
       "      <td>0.809678</td>\n",
       "      <td>0.792357</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.448994</td>\n",
       "      <td>0.561786</td>\n",
       "      <td>0.674593</td>\n",
       "      <td>0.815419</td>\n",
       "      <td>0.785847</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.566771</td>\n",
       "      <td>0.675858</td>\n",
       "      <td>0.816136</td>\n",
       "      <td>0.786679</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.448994</td>\n",
       "      <td>0.569548</td>\n",
       "      <td>0.675771</td>\n",
       "      <td>0.815213</td>\n",
       "      <td>0.786277</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.741624</td>\n",
       "      <td>0.911043</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>0.81183</td>\n",
       "      <td>0.795774</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.483844</td>\n",
       "      <td>0.428847</td>\n",
       "      <td>0.684038</td>\n",
       "      <td>0.821672</td>\n",
       "      <td>0.793356</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.424764</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.821877</td>\n",
       "      <td>0.792806</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.483844</td>\n",
       "      <td>0.420406</td>\n",
       "      <td>0.674876</td>\n",
       "      <td>0.819109</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.789445</td>\n",
       "      <td>0.745971</td>\n",
       "      <td>0.702198</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.799</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.498997</td>\n",
       "      <td>0.384411</td>\n",
       "      <td>0.67513</td>\n",
       "      <td>0.814957</td>\n",
       "      <td>0.785285</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.390267</td>\n",
       "      <td>0.667721</td>\n",
       "      <td>0.812958</td>\n",
       "      <td>0.78126</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.498997</td>\n",
       "      <td>0.391287</td>\n",
       "      <td>0.683208</td>\n",
       "      <td>0.816803</td>\n",
       "      <td>0.789533</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.870528</td>\n",
       "      <td>0.728156</td>\n",
       "      <td>0.698685</td>\n",
       "      <td>0.811625</td>\n",
       "      <td>0.794028</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.479512</td>\n",
       "      <td>0.461159</td>\n",
       "      <td>0.667663</td>\n",
       "      <td>0.81019</td>\n",
       "      <td>0.778072</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454796</td>\n",
       "      <td>0.667071</td>\n",
       "      <td>0.810703</td>\n",
       "      <td>0.778006</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.479512</td>\n",
       "      <td>0.457667</td>\n",
       "      <td>0.669642</td>\n",
       "      <td>0.81101</td>\n",
       "      <td>0.779274</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.590228</td>\n",
       "      <td>0.668711</td>\n",
       "      <td>0.702085</td>\n",
       "      <td>0.81019</td>\n",
       "      <td>0.793126</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.463281</td>\n",
       "      <td>0.4327</td>\n",
       "      <td>0.667967</td>\n",
       "      <td>0.810498</td>\n",
       "      <td>0.779108</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.447675</td>\n",
       "      <td>0.660017</td>\n",
       "      <td>0.808345</td>\n",
       "      <td>0.774745</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.463281</td>\n",
       "      <td>0.455028</td>\n",
       "      <td>0.660782</td>\n",
       "      <td>0.80896</td>\n",
       "      <td>0.775323</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.889208</td>\n",
       "      <td>0.836885</td>\n",
       "      <td>0.687678</td>\n",
       "      <td>0.808857</td>\n",
       "      <td>0.787069</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.492857</td>\n",
       "      <td>0.401263</td>\n",
       "      <td>0.684174</td>\n",
       "      <td>0.821877</td>\n",
       "      <td>0.793774</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.409208</td>\n",
       "      <td>0.684605</td>\n",
       "      <td>0.821928</td>\n",
       "      <td>0.793979</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.492857</td>\n",
       "      <td>0.447967</td>\n",
       "      <td>0.690715</td>\n",
       "      <td>0.823107</td>\n",
       "      <td>0.797062</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.849509</td>\n",
       "      <td>0.856782</td>\n",
       "      <td>0.701184</td>\n",
       "      <td>0.81875</td>\n",
       "      <td>0.799689</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.483129</td>\n",
       "      <td>0.472899</td>\n",
       "      <td>0.68771</td>\n",
       "      <td>0.818597</td>\n",
       "      <td>0.792782</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0.465239</td>\n",
       "      <td>0.685415</td>\n",
       "      <td>0.817828</td>\n",
       "      <td>0.791485</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.483129</td>\n",
       "      <td>0.45824</td>\n",
       "      <td>0.687357</td>\n",
       "      <td>0.81916</td>\n",
       "      <td>0.792856</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.869715</td>\n",
       "      <td>0.946039</td>\n",
       "      <td>0.697019</td>\n",
       "      <td>0.811728</td>\n",
       "      <td>0.793906</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.455398</td>\n",
       "      <td>0.508233</td>\n",
       "      <td>0.69154</td>\n",
       "      <td>0.821211</td>\n",
       "      <td>0.796484</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526363</td>\n",
       "      <td>0.68873</td>\n",
       "      <td>0.821826</td>\n",
       "      <td>0.795534</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.455398</td>\n",
       "      <td>0.538473</td>\n",
       "      <td>0.700437</td>\n",
       "      <td>0.820134</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.65503</td>\n",
       "      <td>0.86938</td>\n",
       "      <td>0.699107</td>\n",
       "      <td>0.811984</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DI of train        DI  f1 macro  f1 micro f1 weighted     method\n",
       "0      0.50473  0.433844   0.68735  0.817828    0.792008     origin\n",
       "1            1  0.424029  0.680209  0.818238    0.789075         RW\n",
       "2      0.50473  0.407999  0.673802  0.816956    0.785775  DIremover\n",
       "3     0.823393  0.852729  0.703679  0.812343    0.796661        LFR\n",
       "4     0.466255  0.461169  0.686989  0.818802     0.79297     origin\n",
       "5          1.0  0.467147  0.679452  0.816751    0.788911         RW\n",
       "6     0.466255  0.446877  0.688379  0.819109    0.793689  DIremover\n",
       "7     0.833312  0.876019  0.694463  0.809678    0.792357        LFR\n",
       "8     0.448994  0.561786  0.674593  0.815419    0.785847     origin\n",
       "9            1  0.566771  0.675858  0.816136    0.786679         RW\n",
       "10    0.448994  0.569548  0.675771  0.815213    0.786277  DIremover\n",
       "11    0.741624  0.911043  0.701403   0.81183    0.795774        LFR\n",
       "12    0.483844  0.428847  0.684038  0.821672    0.793356     origin\n",
       "13         1.0  0.424764  0.682571  0.821877    0.792806         RW\n",
       "14    0.483844  0.420406  0.674876  0.819109    0.788396  DIremover\n",
       "15    0.789445  0.745971  0.702198    0.8167       0.799        LFR\n",
       "16    0.498997  0.384411   0.67513  0.814957    0.785285     origin\n",
       "17           1  0.390267  0.667721  0.812958     0.78126         RW\n",
       "18    0.498997  0.391287  0.683208  0.816803    0.789533  DIremover\n",
       "19    0.870528  0.728156  0.698685  0.811625    0.794028        LFR\n",
       "20    0.479512  0.461159  0.667663   0.81019    0.778072     origin\n",
       "21         1.0  0.454796  0.667071  0.810703    0.778006         RW\n",
       "22    0.479512  0.457667  0.669642   0.81101    0.779274  DIremover\n",
       "23    0.590228  0.668711  0.702085   0.81019    0.793126        LFR\n",
       "24    0.463281    0.4327  0.667967  0.810498    0.779108     origin\n",
       "25         1.0  0.447675  0.660017  0.808345    0.774745         RW\n",
       "26    0.463281  0.455028  0.660782   0.80896    0.775323  DIremover\n",
       "27    0.889208  0.836885  0.687678  0.808857    0.787069        LFR\n",
       "28    0.492857  0.401263  0.684174  0.821877    0.793774     origin\n",
       "29           1  0.409208  0.684605  0.821928    0.793979         RW\n",
       "30    0.492857  0.447967  0.690715  0.823107    0.797062  DIremover\n",
       "31    0.849509  0.856782  0.701184   0.81875    0.799689        LFR\n",
       "32    0.483129  0.472899   0.68771  0.818597    0.792782     origin\n",
       "33           1  0.465239  0.685415  0.817828    0.791485         RW\n",
       "34    0.483129   0.45824  0.687357   0.81916    0.792856  DIremover\n",
       "35    0.869715  0.946039  0.697019  0.811728    0.793906        LFR\n",
       "36    0.455398  0.508233   0.69154  0.821211    0.796484     origin\n",
       "37           1  0.526363   0.68873  0.821826    0.795534         RW\n",
       "38    0.455398  0.538473  0.700437  0.820134      0.7998  DIremover\n",
       "39     0.65503   0.86938  0.699107  0.811984    0.795812        LFR"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
