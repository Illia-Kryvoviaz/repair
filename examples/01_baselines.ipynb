{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover,Reweighing,LFR\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from aif360.datasets import CompasDataset, AdultDataset\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# TODO: change the import method\n",
    "import sys\n",
    "import os\n",
    "repo_root = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, repo_root)\n",
    "repair_folder = os.path.join(repo_root, \"humancompatible\", \"repair\")\n",
    "sys.path.insert(0, repair_folder)\n",
    "from humancompatible.repair.cost import *\n",
    "from humancompatible.repair.coupling_utils import *\n",
    "from humancompatible.repair.data_analysis import *\n",
    "from humancompatible.repair.group_blind_repair import *\n",
    "from humancompatible.repair.metrics import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "path=os.path.dirname(os.getcwd())\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# if you need \"OptimPreproc\"\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projpreprocess:\n",
    "    \n",
    "    def __init__(self,traindata,x_list,var_list,K,e):\n",
    "\n",
    "        self.K=K\n",
    "        self.e=e\n",
    "        self.x_list=x_list\n",
    "        self.var_list=var_list\n",
    "      \n",
    "        self.var_dim=len(var_list)\n",
    "        self.arg_list=[elem for elem in var_list if elem not in x_list]\n",
    "        self.train = traindata.copy()\n",
    "        self.df = self.train.convert_to_dataframe()[0]\n",
    "        self.pa = self.train.protected_attribute_names[0]\n",
    "        self.pa_index = self.train.feature_names.index(self.pa)\n",
    "        self.label_name = self.train.label_names[0]\n",
    "        self.df=self.df.rename(columns={self.pa:'S',self.label_name:'Y'})\n",
    "\n",
    "        self.df['W'] = self.train.instance_weights\n",
    "        for col in self.var_list+['S','Y']:\n",
    "            self.df[col]=self.df[col].astype('int64')\n",
    "        self.df=self.df[var_list+['S','W','Y']]\n",
    "        if len(x_list)>1:\n",
    "            self.df['X'] = list(zip(*[self.df[c] for c in x_list]))\n",
    "            self.x_range=sorted(set(self.df['X']))\n",
    "            weight=list(1/(self.df[x_list].max()-self.df[x_list].min())) # because ranges of attributes differ\n",
    "            self.C=c_generate_higher(self.x_range,weight)\n",
    "        else:\n",
    "            self.df['X']=self.df[x_list]\n",
    "            self.x_range=sorted(set(self.df['X']))\n",
    "            self.C=c_generate(self.x_range)\n",
    "        self.df = self.df[self.arg_list+['X','S','Y','W']].groupby(by=self.arg_list+['X','S','Y'],as_index=False).sum()\n",
    "        self.distribution_generator()\n",
    "        \n",
    "    def distribution_generator(self):\n",
    "        bin=len(self.x_range)\n",
    "        dist=rdata_analysis(self.df,self.x_range,'X')\n",
    "        dist['v']=[(dist['x_0'][i]-dist['x_1'][i])/dist['x'][i] for i in range(bin)]\n",
    "        dist['t_x']=dist['x'] # #dist['x'] #dist['x_0']*0.5+dist['x_1']*0.5 \n",
    "        self.px=np.matrix(dist['x']).T\n",
    "        self.ptx=np.matrix(dist['t_x']).T\n",
    "        if np.any(dist['x_0']==0): \n",
    "            self.p0=np.matrix((dist['x_0']+1.0e-9)/sum(dist['x_0']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p0=np.matrix(dist['x_0']).T \n",
    "        if np.any(dist['x_1']==0):\n",
    "            self.p1=np.matrix((dist['x_1']+1.0e-9)/sum(dist['x_1']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p1=np.matrix(dist['x_1']).T \n",
    "        self.V=np.matrix(dist['v']).T\n",
    "        # self.tv_origin=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "        # return px,ptx,V,p0,p1\n",
    "    \n",
    "    def _run_method(self, method, C, eps, px, ptx, K, V=None, theta=None):\n",
    "        group_blind = GroupBlindRepair(C, px, ptx, V=V, epsilon=eps, K=K)\n",
    "        if method == \"baseline\":\n",
    "            group_blind.fit_baseline()\n",
    "        elif method == \"partial_repair\":\n",
    "            group_blind.fit_partial(theta)\n",
    "        elif method == \"total_repair\":\n",
    "            group_blind.fit_total()\n",
    "        return group_blind.coupling_matrix()\n",
    "\n",
    "    def coupling_generator(self,method,Theta=1e-2):\n",
    "        if method == 'unconstrained':\n",
    "            coupling=self._run_method(method=\"baseline\", C=self.C, eps=self.e, px=self.px, ptx=self.ptx, K=self.K)\n",
    "        elif method == 'barycentre':\n",
    "            coupling=self._run_method(method=\"baseline\", C=self.C, eps=self.e, px=self.p0, ptx=self.p1, K=self.K)\n",
    "        elif method == 'partial':\n",
    "            coupling=self._run_method(method=\"partial_repair\", C=self.C, eps=self.e, px=self.px, ptx=self.ptx, V=self.V, theta=Theta, K=self.K)\n",
    "        return coupling\n",
    "\n",
    "    def preprocess(self,method,Theta=1e-2):\n",
    "        coupling = self.coupling_generator(method,Theta)\n",
    "        if len(self.x_list)>1:\n",
    "            df_proj=projection_higher(self.df,coupling,self.x_range,self.x_list,self.var_list)\n",
    "        else:\n",
    "            df_proj=projection(self.df,coupling,self.x_range,self.x_list[0],self.var_list)\n",
    "        df_proj = df_proj.groupby(by=self.arg_list+['X','S','Y'],as_index=False).sum()\n",
    "        X=list(zip(*df_proj['X']))\n",
    "        df_proj = df_proj.assign(**{self.x_list[i]:X[i] for i in range(len(self.x_list))})\n",
    "        df_proj=df_proj.drop('X',axis=1)\n",
    "        df_proj=df_proj.rename(columns={'S':self.pa,'Y':self.label_name})\n",
    "        binaryLabelDataset = BinaryLabelDataset(\n",
    "            favorable_label=0,\n",
    "            unfavorable_label=1,\n",
    "            df=df_proj.drop('W',axis=1), \n",
    "            label_names=self.train.label_names,\n",
    "            protected_attribute_names=self.train.protected_attribute_names,\n",
    "            privileged_protected_attributes=[np.array([1.0])],unprivileged_protected_attributes=[np.array([0.])])\n",
    "        binaryLabelDataset.instance_weights = df_proj['W'].tolist()\n",
    "        # return binaryLabelDataset.align_datasets(self.train)\n",
    "        return self.train.align_datasets(binaryLabelDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baselinepreprocess:\n",
    "\n",
    "    def __init__(self,train,test):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.pa = train.protected_attribute_names[0]\n",
    "        self.pa_index = train.feature_names.index(pa)\n",
    "        self.prigroups = [{self.pa: 1}]\n",
    "        self.unprigroups = [{self.pa: 0}]\n",
    "\n",
    "    def preprocessing(self,method):\n",
    "        test_tranf = self.test.copy()\n",
    "        if method == 'RW':\n",
    "            RW = Reweighing(privileged_groups = self.prigroups,unprivileged_groups = self.unprigroups) #DisparateImpactRemover(repair_level = 1)\n",
    "            RW.fit(self.train)\n",
    "            train_tranf = RW.transform(self.train)\n",
    "        elif method == 'DIremover':\n",
    "            di = DisparateImpactRemover(repair_level = 1,sensitive_attribute=pa)\n",
    "            train_tranf = di.fit_transform(self.train)\n",
    "            test_tranf = di.fit_transform(self.test)\n",
    "        elif method == 'LFR':\n",
    "            TR = LFR(privileged_groups = self.prigroups,unprivileged_groups = self.unprigroups,\n",
    "                     Az = 1, Ax = 0.01, Ay = 1,verbose=0)\n",
    "            TR = TR.fit(self.train)\n",
    "            train_tranf = TR.transform(self.train)\n",
    "            test_tranf = TR.transform(self.test)\n",
    "        elif method == 'OP':\n",
    "            optim_options = {\n",
    "                \"distortion_fun\": get_distortion_adult,\n",
    "                \"epsilon\": 0.05,\n",
    "                \"clist\": [0.99, 1.99, 2.99],\n",
    "                \"dlist\": [.1, 0.05, 0]\n",
    "            }\n",
    "            OP = OptimPreproc(OptTools, optim_options)\n",
    "            OP = OP.fit(self.train)\n",
    "            train_tranf = OP.transform(self.train, transform_Y=True)\n",
    "        return train_tranf, test_tranf\n",
    "\n",
    "    def prediction(self,method,para=None):\n",
    "        test_tranf = self.test.copy()\n",
    "        if method == 'origin':\n",
    "            train_tranf = self.train\n",
    "        elif method in ['RW','DIremover','LFR','OP']:\n",
    "            train_tranf,test_tranf = self.preprocessing(method)\n",
    "        else:\n",
    "            K=200\n",
    "            e=0.01\n",
    "            var_list=self.train.feature_names.copy()\n",
    "            var_list.remove(self.pa)\n",
    "            projpre=Projpreprocess(self.train,para['x_list'],var_list,K,e)\n",
    "            train_tranf=projpre.preprocess(method,para['Theta'])\n",
    "\n",
    "        di=self.DisparateImpact(train_tranf)\n",
    "        print('Disparate Impact of train',di)\n",
    "\n",
    "        if method != 'LFR':\n",
    "            X_train = np.delete(train_tranf.features, self.pa_index, axis=1)\n",
    "            y_train = train_tranf.labels.ravel()\n",
    "            weight_train = train_tranf.instance_weights\n",
    "            model=RandomForestClassifier(max_depth=5).fit(X_train,y_train, sample_weight=weight_train)\n",
    "\n",
    "            X_test = np.delete(test_tranf.features, self.pa_index, axis=1)\n",
    "            y_pred = model.predict(X_test)\n",
    "        else:\n",
    "            y_pred = test_tranf.labels\n",
    "        return y_pred,di\n",
    "    \n",
    "    def DisparateImpact(self,data):\n",
    "        di = pd.DataFrame({'S':data.protected_attributes.ravel().tolist(),\n",
    "            'Y':data.labels.ravel().tolist(),\n",
    "            'W':list(data.instance_weights)},columns=['S','Y','W'])\n",
    "        privileged = self.train.privileged_protected_attributes[0][0]\n",
    "        unprivileged = self.train.unprivileged_protected_attributes[0][0]\n",
    "        numerator=sum(di[(di['S']==unprivileged)&(di['Y']==data.favorable_label)]['W'])/sum(di[di['S']==unprivileged]['W'])\n",
    "        denominator=sum(di[(di['S']==privileged)&(di['Y']==data.favorable_label)]['W'])/sum(di[di['S']==privileged]['W'])\n",
    "        if numerator==denominator:\n",
    "            return 1\n",
    "        return numerator/denominator\n",
    "\n",
    "    def assess(self,method,para=None):\n",
    "        if para != None:\n",
    "            y_pred,di_train = self.prediction(method,para)\n",
    "        else:\n",
    "            y_pred,di_train = self.prediction(method)\n",
    "        y_test_pred = self.test.copy()\n",
    "        y_test_pred.labels = y_pred\n",
    "\n",
    "        di=self.DisparateImpact(y_test_pred)\n",
    "        f1_macro = f1_score(self.test.labels, y_pred, average='macro',sample_weight=self.test.instance_weights)\n",
    "        f1_micro = f1_score(self.test.labels, y_pred, average='micro',sample_weight=self.test.instance_weights)\n",
    "        f1_weighted = f1_score(self.test.labels, y_pred, average='weighted',sample_weight=self.test.instance_weights)\n",
    "        print('Disparate Impact of '+str(method),di)\n",
    "        print('f1 macro of '+str(method),f1_macro)\n",
    "\n",
    "        new_row=pd.Series({'DI of train':di_train,'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,'method':method})\n",
    "        return new_row.to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juv_fel_count 0.03210337325453563\n",
      "juv_misd_count 0.04323143324022939\n",
      "juv_other_count 0.021763780679615215\n",
      "priors_count 0.12622233191661625\n",
      "age_cat=25 - 45 0.054431947619680315\n",
      "age_cat=Greater than 45 0.13519019921101838\n",
      "age_cat=Less than 25 0.08075825159133806\n",
      "c_charge_degree=F 0.07840757396162046\n",
      "c_charge_degree=M 0.07840757396162046\n"
     ]
    }
   ],
   "source": [
    "pa = 'race'\n",
    "label_map = {1.0: 'Did recid.', 0.0: 'No recid.'}\n",
    "protected_attribute_maps = {1.0: 'Caucasian', 0.0: 'Not Caucasian'}\n",
    "privileged_groups = [{pa: 1}]\n",
    "unprivileged_groups = [{pa: 0}]\n",
    "cd = CompasDataset(protected_attribute_names=[pa],privileged_classes=[['Caucasian'],[1]], \n",
    "                    metadata={'label_map': label_map,'protected_attribute_maps': protected_attribute_maps},\n",
    "                    features_to_drop=['age', 'sex', 'c_charge_desc'])\n",
    "train,test = cd.split([0.6], shuffle=True) #len(test.instance_names) = 2057\n",
    "var_list = cd.feature_names.copy()\n",
    "var_list.remove(pa)\n",
    "var_dim=len(var_list)\n",
    "\n",
    "# df_train = df.loc[train.instance_names,:].reset_index(drop=True)\n",
    "# df_test = df.loc[test.instance_names,:].reset_index(drop=True)\n",
    "df=cd.convert_to_dataframe()[0]\n",
    "df=df.rename(columns={pa:'S',cd.label_names[0]:'Y'})\n",
    "df['W'] = cd.instance_weights\n",
    "for col in var_list+['S','Y']:\n",
    "    df[col]=df[col].astype('int64')\n",
    "df=df[var_list+['S','W','Y']]\n",
    "\n",
    "tv_dist=dict()\n",
    "for x_name in var_list:\n",
    "    x_range_single=list(pd.pivot_table(df,index=x_name,values=['W'],observed=False)[('W')].index) \n",
    "    dist=rdata_analysis(df,x_range_single,x_name)\n",
    "    tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    print(x_name, tv_dist[x_name])\n",
    "x_list=[]\n",
    "for key,val in tv_dist.items():\n",
    "    if val>0.1:\n",
    "        x_list+=[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.8424474463627828\n",
      "Disparate Impact of origin 0.790925904685439\n",
      "f1 macro of origin 0.653530079580681\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7844142478874869\n",
      "f1 macro of RW 0.6574057247575518\n",
      "Disparate Impact of train 0.8424474463627828\n",
      "Disparate Impact of DIremover 0.833230325126911\n",
      "f1 macro of DIremover 0.6552256501361029\n",
      "Disparate Impact of train 0.9993251080881578\n",
      "Disparate Impact of LFR 1.0077932731747332\n",
      "f1 macro of LFR 0.650567318380582\n",
      "Disparate Impact of train 0.865097247706422\n",
      "Disparate Impact of origin 0.7346051975112989\n",
      "f1 macro of origin 0.6599272077792611\n",
      "Disparate Impact of train 0.9999999999999998\n",
      "Disparate Impact of RW 0.733481234667624\n",
      "f1 macro of RW 0.6606267153514127\n",
      "Disparate Impact of train 0.865097247706422\n",
      "Disparate Impact of DIremover 0.8340233994273879\n",
      "f1 macro of DIremover 0.6430723703759721\n",
      "Disparate Impact of train 0.9673170353678965\n",
      "Disparate Impact of LFR 0.865286044973545\n",
      "f1 macro of LFR 0.6511522796477556\n",
      "Disparate Impact of train 0.8391446038202621\n",
      "Disparate Impact of origin 0.7941204297165585\n",
      "f1 macro of origin 0.6575027515234044\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7965691876481132\n",
      "f1 macro of RW 0.6582188288265896\n",
      "Disparate Impact of train 0.8391446038202621\n",
      "Disparate Impact of DIremover 0.7564085356217378\n",
      "f1 macro of DIremover 0.6561515287254016\n",
      "Disparate Impact of train 0.9406625744304205\n",
      "Disparate Impact of LFR 0.9163028067401915\n",
      "f1 macro of LFR 0.6696478622025175\n",
      "Disparate Impact of train 0.8154470509673174\n",
      "Disparate Impact of origin 0.7845902386353505\n",
      "f1 macro of origin 0.6717618763075475\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.8233969694711284\n",
      "f1 macro of RW 0.6687895538846294\n",
      "Disparate Impact of train 0.8154470509673174\n",
      "Disparate Impact of DIremover 0.8833148039173424\n",
      "f1 macro of DIremover 0.6634097116948107\n",
      "Disparate Impact of train 0.9118724484987376\n",
      "Disparate Impact of LFR 0.9700993571011105\n",
      "f1 macro of LFR 0.6712927581379663\n",
      "Disparate Impact of train 0.874908424908425\n",
      "Disparate Impact of origin 0.7530428922061724\n",
      "f1 macro of origin 0.6526547168493539\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7455250004353958\n",
      "f1 macro of RW 0.6603985579673681\n",
      "Disparate Impact of train 0.874908424908425\n",
      "Disparate Impact of DIremover 0.7845309161832931\n",
      "f1 macro of DIremover 0.6654187453548303\n",
      "Disparate Impact of train 1.0050476955195118\n",
      "Disparate Impact of LFR 0.8376006913495722\n",
      "f1 macro of LFR 0.6643125458500989\n",
      "Disparate Impact of train 0.7946644409843501\n",
      "Disparate Impact of origin 0.7910492945678871\n",
      "f1 macro of origin 0.650291182093387\n",
      "Disparate Impact of train 0.9999999999999998\n",
      "Disparate Impact of RW 0.8031454241354519\n",
      "f1 macro of RW 0.6473941100870189\n",
      "Disparate Impact of train 0.7946644409843501\n",
      "Disparate Impact of DIremover 0.7929807575458748\n",
      "f1 macro of DIremover 0.6540796657422062\n",
      "Disparate Impact of train 0.8992442906442992\n",
      "Disparate Impact of LFR 0.8736669834230809\n",
      "f1 macro of LFR 0.6539475337270824\n",
      "Disparate Impact of train 0.8618514981609826\n",
      "Disparate Impact of origin 0.7909037142609098\n",
      "f1 macro of origin 0.6482913553704037\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7981453687821612\n",
      "f1 macro of RW 0.647244762407772\n",
      "Disparate Impact of train 0.8618514981609826\n",
      "Disparate Impact of DIremover 0.862199101665843\n",
      "f1 macro of DIremover 0.641636004990249\n",
      "Disparate Impact of train 0.8661740558292281\n",
      "Disparate Impact of LFR 0.8647376179245283\n",
      "f1 macro of LFR 0.6559074076020823\n",
      "Disparate Impact of train 0.8524163103355292\n",
      "Disparate Impact of origin 0.8132143035039269\n",
      "f1 macro of origin 0.6722173198415878\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.8174301349278171\n",
      "f1 macro of RW 0.6714246168665977\n",
      "Disparate Impact of train 0.8524163103355292\n",
      "Disparate Impact of DIremover 0.883971285204306\n",
      "f1 macro of DIremover 0.6575324056030841\n",
      "Disparate Impact of train 1.0458537581699348\n",
      "Disparate Impact of LFR 1.0194064009010628\n",
      "f1 macro of LFR 0.6727677036688904\n",
      "Disparate Impact of train 0.8537439813030364\n",
      "Disparate Impact of origin 0.8316329370301505\n",
      "f1 macro of origin 0.649531447107587\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.8277925018412928\n",
      "f1 macro of RW 0.6520102950638845\n",
      "Disparate Impact of train 0.8537439813030364\n",
      "Disparate Impact of DIremover 0.8199867786717403\n",
      "f1 macro of DIremover 0.6523703351796466\n",
      "Disparate Impact of train 0.9570532073657327\n",
      "Disparate Impact of LFR 0.9889801928466253\n",
      "f1 macro of LFR 0.6427420182988957\n",
      "Disparate Impact of train 0.8285977033458537\n",
      "Disparate Impact of origin 0.8022725983291491\n",
      "f1 macro of origin 0.6535269366627694\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.8030062092988035\n",
      "f1 macro of RW 0.6617090671885193\n",
      "Disparate Impact of train 0.8285977033458537\n",
      "Disparate Impact of DIremover 0.7777640156966367\n",
      "f1 macro of DIremover 0.6651871964280327\n",
      "Disparate Impact of train 0.9020631850419084\n",
      "Disparate Impact of LFR 0.9037140924643909\n",
      "f1 macro of LFR 0.6624392594490613\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv(path+'/data/report_preprocess_compas_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path,var_list,pa):\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education',\n",
    "                'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "                'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                'native-country', 'Y']\n",
    "    na_values=['?']\n",
    "    pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "    label_dict={'>50K.':1,'>50K':1,'<=50K.':0,'<=50K':0}\n",
    "    train_path = os.path.join(data_path, 'adult.data')\n",
    "    test_path = os.path.join(data_path, 'adult.test')\n",
    "    train = pd.read_csv(train_path, header=None,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    test = pd.read_csv(test_path, header=0,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    messydata = pd.concat([test, train], ignore_index=True)[var_list+[pa,'Y']]\n",
    "    messydata=messydata.rename(columns={pa:'S'})\n",
    "    messydata['S']=messydata['S'].replace(pa_dict)\n",
    "    messydata['Y']=messydata['Y'].replace(label_dict)\n",
    "    messydata=messydata[(messydata['S']==0)|(messydata['S']==1)]\n",
    "    for col in var_list+['S','Y']:\n",
    "        messydata[col]=messydata[col].astype('int64')\n",
    "    messydata['W']=1\n",
    "    bins_capitalgain=[100,3500,7500,10000]\n",
    "    bins_capitalloss=[100,1600,1900,2200]\n",
    "    bins_age=[26,36,46,56]\n",
    "    bins_hours=[21,36,46,61]\n",
    "\n",
    "    messydata=categerise(messydata,'age',bins_age)\n",
    "    messydata=categerise(messydata,'hours-per-week',bins_hours)\n",
    "    messydata=categerise(messydata,'capital-gain',bins_capitalgain)\n",
    "    messydata=categerise(messydata,'capital-loss',bins_capitalloss)\n",
    "    \n",
    "    return messydata\n",
    "\n",
    "def categerise(df,col,bins):\n",
    "    for i in range(len(bins)+1):\n",
    "        if i == 0:\n",
    "            df.loc[df[col] < bins[i], col] = i\n",
    "        elif i == len(bins):\n",
    "            df.loc[df[col] >= bins[i-1], col] = i\n",
    "        else:\n",
    "            df.loc[(df[col] >= bins[i-1])& (df[col] < bins[i]), col] = i        \n",
    "    return df\n",
    "\n",
    "def choose_x(var_list,messydata):\n",
    "    tv_dist=dict()\n",
    "    for x_name in var_list:\n",
    "        x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "        dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "        tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    x_list=[]\n",
    "    for key,val in tv_dist.items():\n",
    "        if val>0.1:\n",
    "            x_list+=[key]  \n",
    "    return x_list,tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change the obtaining method for the adult data\n",
    "data_path='C://personal//work//repair//.venv//Lib//site-packages//aif360//data//raw//adult'\n",
    "\n",
    "var_list=['hours-per-week','age','capital-gain','capital-loss','education-num'] #,'education-num'\n",
    "pa='race'\n",
    "favorable_label = 1\n",
    "var_dim=len(var_list)\n",
    "\n",
    "messydata = load_data(data_path,var_list,pa)\n",
    "x_list,tv_dist = choose_x(var_list,messydata)\n",
    "messydata=messydata.rename(columns={'S':pa})\n",
    "cd=BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=messydata,label_names='Y',protected_attribute_names=[pa])\n",
    "train,test = cd.split([0.4], shuffle=True) \n",
    "valid,test = test.split([0.3], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.4721119624193565\n",
      "Disparate Impact of origin 0.4126201908164911\n",
      "f1 macro of origin 0.6833016294804953\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.3712113159723642\n",
      "f1 macro of RW 0.6817828962436433\n",
      "Disparate Impact of train 0.4721119624193565\n",
      "Disparate Impact of DIremover 0.40409679754326816\n",
      "f1 macro of DIremover 0.6876913072151577\n",
      "Disparate Impact of train 0.7450433633909597\n",
      "Disparate Impact of LFR 0.593165170696951\n",
      "f1 macro of LFR 0.6814282835266824\n",
      "Disparate Impact of train 0.4904278891177263\n",
      "Disparate Impact of origin 0.4736407041191058\n",
      "f1 macro of origin 0.6878901016863084\n",
      "Disparate Impact of train 0.9999999999999999\n",
      "Disparate Impact of RW 0.4643243085645172\n",
      "f1 macro of RW 0.6890221565382613\n",
      "Disparate Impact of train 0.4904278891177263\n",
      "Disparate Impact of DIremover 0.4839191215970267\n",
      "f1 macro of DIremover 0.6800909091908462\n",
      "Disparate Impact of train 0.8467138092339073\n",
      "Disparate Impact of LFR 0.8415571639378822\n",
      "f1 macro of LFR 0.6899649193307621\n",
      "Disparate Impact of train 0.45836162112369455\n",
      "Disparate Impact of origin 0.4741938756285959\n",
      "f1 macro of origin 0.6849563073391944\n",
      "Disparate Impact of train 0.9999999999999999\n",
      "Disparate Impact of RW 0.4765695264967816\n",
      "f1 macro of RW 0.683883136876381\n",
      "Disparate Impact of train 0.45836162112369455\n",
      "Disparate Impact of DIremover 0.47472771190162494\n",
      "f1 macro of DIremover 0.6841702803569755\n",
      "Disparate Impact of train 0.8685716997183461\n",
      "Disparate Impact of LFR 0.8911466146614662\n",
      "f1 macro of LFR 0.6918225506169082\n",
      "Disparate Impact of train 0.4406240457485496\n",
      "Disparate Impact of origin 0.4644425665623252\n",
      "f1 macro of origin 0.6856118145657764\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.46159266081296163\n",
      "f1 macro of RW 0.6777909798780776\n",
      "Disparate Impact of train 0.4406240457485496\n",
      "Disparate Impact of DIremover 0.46179491297622166\n",
      "f1 macro of DIremover 0.6856894503338293\n",
      "Disparate Impact of train 0.6498612737285753\n",
      "Disparate Impact of LFR 0.6655335422531472\n",
      "f1 macro of LFR 0.7051218445255318\n",
      "Disparate Impact of train 0.47981712023202616\n",
      "Disparate Impact of origin 0.4422495228994842\n",
      "f1 macro of origin 0.6794260143482062\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.4781281078463245\n",
      "f1 macro of RW 0.6786448425553662\n",
      "Disparate Impact of train 0.47981712023202616\n",
      "Disparate Impact of DIremover 0.4554061277813481\n",
      "f1 macro of DIremover 0.6803204952858479\n",
      "Disparate Impact of train 0.881146690752875\n",
      "Disparate Impact of LFR 0.9750359181146364\n",
      "f1 macro of LFR 0.6900350104462505\n",
      "Disparate Impact of train 0.47933718058985103\n",
      "Disparate Impact of origin 0.47972683786505543\n",
      "f1 macro of origin 0.681730584315441\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.46668046357615894\n",
      "f1 macro of RW 0.6808079002687901\n",
      "Disparate Impact of train 0.47933718058985103\n",
      "Disparate Impact of DIremover 0.46413013403836695\n",
      "f1 macro of DIremover 0.6834362203307803\n",
      "Disparate Impact of train 0.76562857869958\n",
      "Disparate Impact of LFR 0.7925493002544529\n",
      "f1 macro of LFR 0.6889567170446571\n",
      "Disparate Impact of train 0.46796498406148435\n",
      "Disparate Impact of origin 0.47502737768070014\n",
      "f1 macro of origin 0.685377419905967\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.4744391747027649\n",
      "f1 macro of RW 0.6786017181746754\n",
      "Disparate Impact of train 0.46796498406148435\n",
      "Disparate Impact of DIremover 0.43656056317407643\n",
      "f1 macro of DIremover 0.6846932216294067\n",
      "Disparate Impact of train 0.8603124095523385\n",
      "Disparate Impact of LFR 0.7564776979226602\n",
      "f1 macro of LFR 0.6983311719417091\n",
      "Disparate Impact of train 0.4555927051377679\n",
      "Disparate Impact of origin 0.45649630512962563\n",
      "f1 macro of origin 0.6769773669499697\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.4362138325854866\n",
      "f1 macro of RW 0.6740090478335485\n",
      "Disparate Impact of train 0.4555927051377679\n",
      "Disparate Impact of DIremover 0.47759399818948806\n",
      "f1 macro of DIremover 0.678686143450598\n",
      "Disparate Impact of train 0.8218358018691851\n",
      "Disparate Impact of LFR 0.8804438999410121\n",
      "f1 macro of LFR 0.7052971089339606\n",
      "Disparate Impact of train 0.4748216443683787\n",
      "Disparate Impact of origin 0.4229904758583063\n",
      "f1 macro of origin 0.6874585072291621\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.4301443475273606\n",
      "f1 macro of RW 0.6859474417963535\n",
      "Disparate Impact of train 0.4748216443683787\n",
      "Disparate Impact of DIremover 0.43933613897493434\n",
      "f1 macro of DIremover 0.6868046842330168\n",
      "Disparate Impact of train 0.8438042757411626\n",
      "Disparate Impact of LFR 0.8528358447654169\n",
      "f1 macro of LFR 0.7013436089640498\n",
      "Disparate Impact of train 0.48968730505302555\n",
      "Disparate Impact of origin 0.45255719270132155\n",
      "f1 macro of origin 0.6782095640596941\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.4859134571262504\n",
      "f1 macro of RW 0.6791051527734024\n",
      "Disparate Impact of train 0.48968730505302555\n",
      "Disparate Impact of DIremover 0.4642808058722474\n",
      "f1 macro of DIremover 0.6768779887865852\n",
      "Disparate Impact of train 0.8250630127892623\n",
      "Disparate Impact of LFR 0.7664727875204362\n",
      "f1 macro of LFR 0.7015941124546272\n"
     ]
    }
   ],
   "source": [
    "para={'x_list':x_list,'Theta':1e-2}\n",
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv(path+'/data/report_preprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI of train</th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.472112</td>\n",
       "      <td>0.41262</td>\n",
       "      <td>0.683302</td>\n",
       "      <td>0.817469</td>\n",
       "      <td>0.789987</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.371211</td>\n",
       "      <td>0.681783</td>\n",
       "      <td>0.818084</td>\n",
       "      <td>0.78957</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.472112</td>\n",
       "      <td>0.404097</td>\n",
       "      <td>0.687691</td>\n",
       "      <td>0.818648</td>\n",
       "      <td>0.792359</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.745043</td>\n",
       "      <td>0.593165</td>\n",
       "      <td>0.681428</td>\n",
       "      <td>0.809114</td>\n",
       "      <td>0.785812</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.490428</td>\n",
       "      <td>0.473641</td>\n",
       "      <td>0.68789</td>\n",
       "      <td>0.818494</td>\n",
       "      <td>0.792384</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464324</td>\n",
       "      <td>0.689022</td>\n",
       "      <td>0.818699</td>\n",
       "      <td>0.792955</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.490428</td>\n",
       "      <td>0.483919</td>\n",
       "      <td>0.680091</td>\n",
       "      <td>0.816495</td>\n",
       "      <td>0.788205</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.846714</td>\n",
       "      <td>0.841557</td>\n",
       "      <td>0.689965</td>\n",
       "      <td>0.81101</td>\n",
       "      <td>0.790227</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.458362</td>\n",
       "      <td>0.474194</td>\n",
       "      <td>0.684956</td>\n",
       "      <td>0.815829</td>\n",
       "      <td>0.789506</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.47657</td>\n",
       "      <td>0.683883</td>\n",
       "      <td>0.815829</td>\n",
       "      <td>0.78904</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.458362</td>\n",
       "      <td>0.474728</td>\n",
       "      <td>0.68417</td>\n",
       "      <td>0.815829</td>\n",
       "      <td>0.789165</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.868572</td>\n",
       "      <td>0.891147</td>\n",
       "      <td>0.691823</td>\n",
       "      <td>0.810549</td>\n",
       "      <td>0.790312</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.440624</td>\n",
       "      <td>0.464443</td>\n",
       "      <td>0.685612</td>\n",
       "      <td>0.817315</td>\n",
       "      <td>0.791469</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.461593</td>\n",
       "      <td>0.677791</td>\n",
       "      <td>0.815111</td>\n",
       "      <td>0.787218</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.440624</td>\n",
       "      <td>0.461795</td>\n",
       "      <td>0.685689</td>\n",
       "      <td>0.81711</td>\n",
       "      <td>0.79142</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.649861</td>\n",
       "      <td>0.665534</td>\n",
       "      <td>0.705122</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.79738</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.479817</td>\n",
       "      <td>0.44225</td>\n",
       "      <td>0.679426</td>\n",
       "      <td>0.817469</td>\n",
       "      <td>0.788193</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478128</td>\n",
       "      <td>0.678645</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.787549</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.479817</td>\n",
       "      <td>0.455406</td>\n",
       "      <td>0.68032</td>\n",
       "      <td>0.817828</td>\n",
       "      <td>0.788725</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.881147</td>\n",
       "      <td>0.975036</td>\n",
       "      <td>0.690035</td>\n",
       "      <td>0.810498</td>\n",
       "      <td>0.789945</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.479337</td>\n",
       "      <td>0.479727</td>\n",
       "      <td>0.681731</td>\n",
       "      <td>0.818033</td>\n",
       "      <td>0.79068</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.46668</td>\n",
       "      <td>0.680808</td>\n",
       "      <td>0.818084</td>\n",
       "      <td>0.790305</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.479337</td>\n",
       "      <td>0.46413</td>\n",
       "      <td>0.683436</td>\n",
       "      <td>0.818033</td>\n",
       "      <td>0.791412</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.765629</td>\n",
       "      <td>0.792549</td>\n",
       "      <td>0.688957</td>\n",
       "      <td>0.812497</td>\n",
       "      <td>0.791496</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.467965</td>\n",
       "      <td>0.475027</td>\n",
       "      <td>0.685377</td>\n",
       "      <td>0.819212</td>\n",
       "      <td>0.7928</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.474439</td>\n",
       "      <td>0.678602</td>\n",
       "      <td>0.816956</td>\n",
       "      <td>0.788994</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.467965</td>\n",
       "      <td>0.436561</td>\n",
       "      <td>0.684693</td>\n",
       "      <td>0.819981</td>\n",
       "      <td>0.792815</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.860312</td>\n",
       "      <td>0.756478</td>\n",
       "      <td>0.698331</td>\n",
       "      <td>0.813573</td>\n",
       "      <td>0.79594</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.455593</td>\n",
       "      <td>0.456496</td>\n",
       "      <td>0.676977</td>\n",
       "      <td>0.817469</td>\n",
       "      <td>0.788434</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.436214</td>\n",
       "      <td>0.674009</td>\n",
       "      <td>0.817161</td>\n",
       "      <td>0.787032</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.455593</td>\n",
       "      <td>0.477594</td>\n",
       "      <td>0.678686</td>\n",
       "      <td>0.817264</td>\n",
       "      <td>0.789088</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.821836</td>\n",
       "      <td>0.880444</td>\n",
       "      <td>0.705297</td>\n",
       "      <td>0.813881</td>\n",
       "      <td>0.798889</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.474822</td>\n",
       "      <td>0.42299</td>\n",
       "      <td>0.687459</td>\n",
       "      <td>0.820596</td>\n",
       "      <td>0.79364</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.430144</td>\n",
       "      <td>0.685947</td>\n",
       "      <td>0.819981</td>\n",
       "      <td>0.792743</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.474822</td>\n",
       "      <td>0.439336</td>\n",
       "      <td>0.686805</td>\n",
       "      <td>0.820032</td>\n",
       "      <td>0.793133</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.843804</td>\n",
       "      <td>0.852836</td>\n",
       "      <td>0.701344</td>\n",
       "      <td>0.812241</td>\n",
       "      <td>0.796074</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.489687</td>\n",
       "      <td>0.452557</td>\n",
       "      <td>0.67821</td>\n",
       "      <td>0.816495</td>\n",
       "      <td>0.787322</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>0.485913</td>\n",
       "      <td>0.679105</td>\n",
       "      <td>0.816187</td>\n",
       "      <td>0.787591</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.489687</td>\n",
       "      <td>0.464281</td>\n",
       "      <td>0.676878</td>\n",
       "      <td>0.815931</td>\n",
       "      <td>0.786519</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.825063</td>\n",
       "      <td>0.766473</td>\n",
       "      <td>0.701594</td>\n",
       "      <td>0.811728</td>\n",
       "      <td>0.795364</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DI of train        DI  f1 macro  f1 micro f1 weighted     method\n",
       "0     0.472112   0.41262  0.683302  0.817469    0.789987     origin\n",
       "1            1  0.371211  0.681783  0.818084     0.78957         RW\n",
       "2     0.472112  0.404097  0.687691  0.818648    0.792359  DIremover\n",
       "3     0.745043  0.593165  0.681428  0.809114    0.785812        LFR\n",
       "4     0.490428  0.473641   0.68789  0.818494    0.792384     origin\n",
       "5          1.0  0.464324  0.689022  0.818699    0.792955         RW\n",
       "6     0.490428  0.483919  0.680091  0.816495    0.788205  DIremover\n",
       "7     0.846714  0.841557  0.689965   0.81101    0.790227        LFR\n",
       "8     0.458362  0.474194  0.684956  0.815829    0.789506     origin\n",
       "9          1.0   0.47657  0.683883  0.815829     0.78904         RW\n",
       "10    0.458362  0.474728   0.68417  0.815829    0.789165  DIremover\n",
       "11    0.868572  0.891147  0.691823  0.810549    0.790312        LFR\n",
       "12    0.440624  0.464443  0.685612  0.817315    0.791469     origin\n",
       "13           1  0.461593  0.677791  0.815111    0.787218         RW\n",
       "14    0.440624  0.461795  0.685689   0.81711     0.79142  DIremover\n",
       "15    0.649861  0.665534  0.705122  0.811779     0.79738        LFR\n",
       "16    0.479817   0.44225  0.679426  0.817469    0.788193     origin\n",
       "17         1.0  0.478128  0.678645    0.8167    0.787549         RW\n",
       "18    0.479817  0.455406   0.68032  0.817828    0.788725  DIremover\n",
       "19    0.881147  0.975036  0.690035  0.810498    0.789945        LFR\n",
       "20    0.479337  0.479727  0.681731  0.818033     0.79068     origin\n",
       "21           1   0.46668  0.680808  0.818084    0.790305         RW\n",
       "22    0.479337   0.46413  0.683436  0.818033    0.791412  DIremover\n",
       "23    0.765629  0.792549  0.688957  0.812497    0.791496        LFR\n",
       "24    0.467965  0.475027  0.685377  0.819212      0.7928     origin\n",
       "25           1  0.474439  0.678602  0.816956    0.788994         RW\n",
       "26    0.467965  0.436561  0.684693  0.819981    0.792815  DIremover\n",
       "27    0.860312  0.756478  0.698331  0.813573     0.79594        LFR\n",
       "28    0.455593  0.456496  0.676977  0.817469    0.788434     origin\n",
       "29         1.0  0.436214  0.674009  0.817161    0.787032         RW\n",
       "30    0.455593  0.477594  0.678686  0.817264    0.789088  DIremover\n",
       "31    0.821836  0.880444  0.705297  0.813881    0.798889        LFR\n",
       "32    0.474822   0.42299  0.687459  0.820596     0.79364     origin\n",
       "33         1.0  0.430144  0.685947  0.819981    0.792743         RW\n",
       "34    0.474822  0.439336  0.686805  0.820032    0.793133  DIremover\n",
       "35    0.843804  0.852836  0.701344  0.812241    0.796074        LFR\n",
       "36    0.489687  0.452557   0.67821  0.816495    0.787322     origin\n",
       "37           1  0.485913  0.679105  0.816187    0.787591         RW\n",
       "38    0.489687  0.464281  0.676878  0.815931    0.786519  DIremover\n",
       "39    0.825063  0.766473  0.701594  0.811728    0.795364        LFR"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.to_csv(path+'/data/report_preprocess_compas_'+str(pa)+'_'+str(para['Theta'])+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grouper for 'W' not 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mBaselinepreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43massess\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpartial\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 82\u001b[39m, in \u001b[36mBaselinepreprocess.assess\u001b[39m\u001b[34m(self, method, para)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34massess\u001b[39m(\u001b[38;5;28mself\u001b[39m,method,para=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m para != \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         y_pred,di_train = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m         y_pred,di_train = \u001b[38;5;28mself\u001b[39m.prediction(method)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mBaselinepreprocess.prediction\u001b[39m\u001b[34m(self, method, para)\u001b[39m\n\u001b[32m     48\u001b[39m     var_list=\u001b[38;5;28mself\u001b[39m.train.feature_names.copy()\n\u001b[32m     49\u001b[39m     var_list.remove(\u001b[38;5;28mself\u001b[39m.pa)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     projpre=\u001b[43mProjpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mx_list\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     train_tranf=projpre.preprocess(method,para[\u001b[33m'\u001b[39m\u001b[33mTheta\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     53\u001b[39m di=\u001b[38;5;28mself\u001b[39m.DisparateImpact(train_tranf)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mProjpreprocess.__init__\u001b[39m\u001b[34m(self, traindata, x_list, var_list, K, e)\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mself\u001b[39m.x_range=\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m.df[\u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m.C=c_generate(\u001b[38;5;28mself\u001b[39m.x_range)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28mself\u001b[39m.df = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marg_list\u001b[49m\u001b[43m+\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mY\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mW\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marg_list\u001b[49m\u001b[43m+\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mY\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m.sum()\n\u001b[32m     33\u001b[39m \u001b[38;5;28mself\u001b[39m.distribution_generator()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\work\\repair\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9186\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9189\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\work\\repair\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\work\\repair\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1038\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1034\u001b[39m     in_axis, name, gpr = \u001b[38;5;28;01mTrue\u001b[39;00m, gpr, obj[gpr]\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gpr.ndim != \u001b[32m1\u001b[39m:\n\u001b[32m   1036\u001b[39m         \u001b[38;5;66;03m# non-unique columns; raise here to get the name in the\u001b[39;00m\n\u001b[32m   1037\u001b[39m         \u001b[38;5;66;03m# exception message\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGrouper for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not 1-dimensional\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1039\u001b[39m     exclusions.add(name)\n\u001b[32m   1040\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m obj._is_level_reference(gpr, axis=axis):\n",
      "\u001b[31mValueError\u001b[39m: Grouper for 'W' not 1-dimensional"
     ]
    }
   ],
   "source": [
    "Baselinepreprocess(train,test).assess('partial',para=para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.6849280344497454\n",
      "Disparate Impact of LFR 0.6593951766356766\n",
      "f1 macro of LFR 0.6898331464937891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI of train</th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.684928</td>\n",
       "      <td>0.659395</td>\n",
       "      <td>0.689833</td>\n",
       "      <td>0.814291</td>\n",
       "      <td>0.79146</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DI of train        DI  f1 macro  f1 micro f1 weighted method\n",
       "0    0.684928  0.659395  0.689833  0.814291     0.79146    LFR"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Baselinepreprocess(train,test).assess('LFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.42841670314617597\n",
      "f1 macro of RW 0.6718433299452754\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI of train</th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.428417</td>\n",
       "      <td>0.671843</td>\n",
       "      <td>0.814701</td>\n",
       "      <td>0.783836</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DI of train        DI  f1 macro  f1 micro f1 weighted method\n",
       "0           1  0.428417  0.671843  0.814701    0.783836     RW"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Baselinepreprocess(train,test).assess('RW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.48968730505302555\n",
      "Disparate Impact of DIremover 0.42532957143552075\n",
      "f1 macro of DIremover 0.6767304414384527\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI of train</th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.489687</td>\n",
       "      <td>0.42533</td>\n",
       "      <td>0.67673</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DI of train       DI f1 macro  f1 micro f1 weighted     method\n",
       "0    0.489687  0.42533  0.67673  0.816239    0.786576  DIremover"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Baselinepreprocess(train,test).assess('DIremover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.48968730505302555\n",
      "Disparate Impact of origin 0.459168098794411\n",
      "f1 macro of origin 0.6858345117489115\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI of train</th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.489687</td>\n",
       "      <td>0.459168</td>\n",
       "      <td>0.685835</td>\n",
       "      <td>0.817674</td>\n",
       "      <td>0.791104</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DI of train        DI  f1 macro  f1 micro f1 weighted  method\n",
       "0    0.489687  0.459168  0.685835  0.817674    0.791104  origin"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Baselinepreprocess(train,test).assess('origin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
