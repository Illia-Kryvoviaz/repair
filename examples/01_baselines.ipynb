{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover,Reweighing,LFR\n",
    "from aif360.datasets import BinaryLabelDataset, CompasDataset\n",
    "\n",
    "from humancompatible.repair.methods.data_analysis import rdata_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baselinepreprocess:\n",
    "    \"\"\"\n",
    "    A class to evaluate fairness and performance of 3 bias mitigation methods\n",
    "    in the AIF360 documentation:https://aif360.readthedocs.io/en/latest/modules/algorithms.html.\n",
    "\n",
    "    This class supports methods like Reweighing, Disparate Impact Remover, and LFR (Learning fair representations)\n",
    "    to preprocess data, train models, and assess fairness metrics of \n",
    "    Disparate Impact and F1 scores.\n",
    "\n",
    "    Parameters:\n",
    "        train, test (CompasDataset): The dataset to be evaluated.\n",
    "        pa (str): The name of the protected attribute (e.g., 'sex', 'race').\n",
    "   \n",
    "    Methods:\n",
    "        preprocessing(method): Preprocess the dataset using the specified method.\n",
    "        prediction(method): Predict outcomes using a random forest on the test data.\n",
    "        assess(method): Compute performance and fairness metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,train,test):\n",
    "        self.train = train \n",
    "        self.test = test\n",
    "        self.pa = train.protected_attribute_names[0]\n",
    "        self.pa_index = train.feature_names.index(self.pa)\n",
    "        self.prigroups = [{self.pa: 1}]\n",
    "        self.unprigroups = [{self.pa: 0}]\n",
    "\n",
    "    def preprocessing(self,method):\n",
    "        \"\"\"\n",
    "        Preprocess training and/or test data for a given fairness method.\n",
    "\n",
    "        Applies preprocessing steps as described in the AIF360 documentation:\n",
    "        https://aif360.readthedocs.io/en/latest/modules/algorithms.html\n",
    "\n",
    "        Parameters:\n",
    "            methods (str): The name of the method to evaluate.\n",
    "                        Must be one of ['origin', 'RW', 'DIremover', 'LFR'].\n",
    "\n",
    "        Returns:\n",
    "            CompasDataset: The processed training and test data.\n",
    "        \"\"\"\n",
    "        test_tranf = self.test.copy()\n",
    "        if method == 'RW':\n",
    "            RW = Reweighing(privileged_groups = self.prigroups,\n",
    "                            unprivileged_groups = self.unprigroups)\n",
    "            RW.fit(self.train)\n",
    "            train_tranf = RW.transform(self.train)\n",
    "        elif method == 'DIremover':\n",
    "            di = DisparateImpactRemover(repair_level = 1,\n",
    "                                        sensitive_attribute=self.pa)\n",
    "            train_tranf = di.fit_transform(self.train)\n",
    "            test_tranf = di.fit_transform(self.test)\n",
    "        elif method == 'LFR':\n",
    "            TR = LFR(privileged_groups = self.prigroups,\n",
    "                     unprivileged_groups = self.unprigroups,\n",
    "                     Az = 1, Ax = 0.01, Ay = 1,verbose=0)\n",
    "            TR = TR.fit(self.train)\n",
    "            train_tranf = TR.transform(self.train)\n",
    "            test_tranf = TR.transform(self.test)\n",
    "        return train_tranf, test_tranf\n",
    "\n",
    "    def prediction(self,method):\n",
    "        \"\"\"\n",
    "        Predict outcomes using a random forest classifier with a given fairness method.\n",
    "\n",
    "        Parameters:\n",
    "            methods (str): The name of the method to evaluate.\n",
    "                        Must be one of ['origin', 'RW', 'DIremover', 'LFR'].\n",
    "\n",
    "        Returns:\n",
    "            y_pred (CompasDataset): Predictions on the test data.\n",
    "            di (float): Disparate Impact computed on the (processed) training data.\n",
    "        \"\"\"\n",
    "        test_tranf = self.test.copy()\n",
    "        if method == 'origin':\n",
    "            train_tranf = self.train\n",
    "        elif method in ['RW','DIremover','LFR','OP']:\n",
    "            train_tranf,test_tranf = self.preprocessing(method)\n",
    "        else:\n",
    "            print('The method does not exist')\n",
    "\n",
    "        di=self.DisparateImpact(train_tranf)\n",
    "        print('Disparate Impact of train',di)\n",
    "\n",
    "        if method != 'LFR':\n",
    "            X_train = np.delete(train_tranf.features, self.pa_index, axis=1)\n",
    "            y_train = train_tranf.labels.ravel()\n",
    "            weight_train = train_tranf.instance_weights\n",
    "            model=RandomForestClassifier(max_depth=5).fit(X_train,y_train, sample_weight=weight_train)\n",
    "\n",
    "            X_test = np.delete(test_tranf.features, self.pa_index, axis=1)\n",
    "            y_pred = model.predict(X_test)\n",
    "        else:\n",
    "            y_pred = test_tranf.labels\n",
    "        return y_pred,di\n",
    "    \n",
    "    def DisparateImpact(self,data):\n",
    "        \"\"\"\n",
    "        Computes Disparate Impact of the given dataset.\n",
    "\n",
    "        Parameters:\n",
    "            data (CompasDataset).\n",
    "        \"\"\"\n",
    "        di = pd.DataFrame({'S':data.protected_attributes.ravel().tolist(),\n",
    "            'Y':data.labels.ravel().tolist(),\n",
    "            'W':list(data.instance_weights)},columns=['S','Y','W'])\n",
    "        privileged = self.train.privileged_protected_attributes[0][0]\n",
    "        unprivileged = self.train.unprivileged_protected_attributes[0][0]\n",
    "        numerator=sum(di[(di['S']==unprivileged)&(di['Y']==data.favorable_label)]['W'])/sum(di[di['S']==unprivileged]['W'])\n",
    "        denominator=sum(di[(di['S']==privileged)&(di['Y']==data.favorable_label)]['W'])/sum(di[di['S']==privileged]['W'])\n",
    "        if numerator==denominator:\n",
    "            return 1\n",
    "        return numerator/denominator\n",
    "\n",
    "    def assess(self,method):\n",
    "        \"\"\"\n",
    "        Calculate performance metrics for a given fairness method.\n",
    "\n",
    "        Computes Disparate Impact and three types of F1 scores of the prediction on (processed) test data.\n",
    "\n",
    "        Parameters:\n",
    "            methods (str): The name of the method to evaluate.\n",
    "                        Must be one of ['origin', 'RW', 'DIremover', 'LFR'].\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing the performance metrics\n",
    "                        for the specified method.\n",
    "        \"\"\"\n",
    "        y_pred,di_train = self.prediction(method)\n",
    "        y_test_pred = self.test.copy()\n",
    "        y_test_pred.labels = y_pred\n",
    "\n",
    "        di=self.DisparateImpact(y_test_pred)\n",
    "        f1_macro = f1_score(self.test.labels, y_pred, average='macro',sample_weight=self.test.instance_weights)\n",
    "        f1_micro = f1_score(self.test.labels, y_pred, average='micro',sample_weight=self.test.instance_weights)\n",
    "        f1_weighted = f1_score(self.test.labels, y_pred, average='weighted',sample_weight=self.test.instance_weights)\n",
    "        print('Disparate Impact of '+str(method),di)\n",
    "        print('f1 macro of '+str(method),f1_macro)\n",
    "\n",
    "        new_row=pd.Series({'DI of train':di_train,'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,'method':method})\n",
    "        return new_row.to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compas dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = 'race'\n",
    "label_map = {1.0: 'Did recid.', 0.0: 'No recid.'}\n",
    "protected_attribute_maps = {1.0: 'Caucasian', 0.0: 'Not Caucasian'}\n",
    "privileged_groups = [{pa: 1}]\n",
    "unprivileged_groups = [{pa: 0}]\n",
    "cd = CompasDataset(protected_attribute_names=[pa],privileged_classes=[['Caucasian'],[1]], \n",
    "                    metadata={'label_map': label_map,'protected_attribute_maps': protected_attribute_maps},\n",
    "                    features_to_drop=['age', 'sex', 'c_charge_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.830888542109992\n",
      "Disparate Impact of origin 0.8121447751174758\n",
      "f1 macro of origin 0.655159989232047\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.8016114057311912\n",
      "f1 macro of RW 0.6569301670588616\n",
      "Disparate Impact of train 0.830888542109992\n",
      "Disparate Impact of DIremover 0.8863396445590057\n",
      "f1 macro of DIremover 0.657932127901629\n",
      "Disparate Impact of train 0.8511079141898066\n",
      "Disparate Impact of LFR 0.9361767819336626\n",
      "f1 macro of LFR 0.6656108951761126\n",
      "Disparate Impact of train 0.8578061409710147\n",
      "Disparate Impact of origin 0.7726617433946519\n",
      "f1 macro of origin 0.6727372350063858\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7858609960238458\n",
      "f1 macro of RW 0.6620872061436354\n",
      "Disparate Impact of train 0.8578061409710147\n",
      "Disparate Impact of DIremover 0.8924482996109674\n",
      "f1 macro of DIremover 0.6521725838411971\n",
      "Disparate Impact of train 0.9908699093188903\n",
      "Disparate Impact of LFR 0.9513729265827789\n",
      "f1 macro of LFR 0.6587317576063509\n",
      "Disparate Impact of train 0.8787747489780156\n",
      "Disparate Impact of origin 0.7808881743970606\n",
      "f1 macro of origin 0.6557664260872818\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.7837296310087416\n",
      "f1 macro of RW 0.6658770958244696\n",
      "Disparate Impact of train 0.8787747489780156\n",
      "Disparate Impact of DIremover 0.8154872746887049\n",
      "f1 macro of DIremover 0.667367078468958\n",
      "Disparate Impact of train 0.9935391990437862\n",
      "Disparate Impact of LFR 0.9291371135768308\n",
      "f1 macro of LFR 0.6803012837787527\n",
      "Disparate Impact of train 0.834026494146642\n",
      "Disparate Impact of origin 0.7477197958026092\n",
      "f1 macro of origin 0.6674298482434634\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.7761243362021607\n",
      "f1 macro of RW 0.6620872061436354\n",
      "Disparate Impact of train 0.834026494146642\n",
      "Disparate Impact of DIremover 0.84893192048012\n",
      "f1 macro of DIremover 0.6528725645380566\n",
      "Disparate Impact of train 0.9266450734001482\n",
      "Disparate Impact of LFR 0.8822476561548764\n",
      "f1 macro of LFR 0.6632628003141703\n",
      "Disparate Impact of train 0.8601249016522423\n",
      "Disparate Impact of origin 0.8215784543325527\n",
      "f1 macro of origin 0.6605900537157579\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.8106025775491731\n",
      "f1 macro of RW 0.6603104236098011\n",
      "Disparate Impact of train 0.8601249016522423\n",
      "Disparate Impact of DIremover 0.860543325526932\n",
      "f1 macro of DIremover 0.6587671094352796\n",
      "Disparate Impact of train 0.9064636478104742\n",
      "Disparate Impact of LFR 0.9449711893248867\n",
      "f1 macro of LFR 0.6672486984868389\n",
      "Disparate Impact of train 0.8154674328216581\n",
      "Disparate Impact of origin 0.8193620844564241\n",
      "f1 macro of origin 0.6619873366435443\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.8199868363317245\n",
      "f1 macro of RW 0.6573174202992843\n",
      "Disparate Impact of train 0.8154674328216581\n",
      "Disparate Impact of DIremover 0.896579784828121\n",
      "f1 macro of DIremover 0.6570644197762842\n",
      "Disparate Impact of train 0.9257420623823545\n",
      "Disparate Impact of LFR 0.9919173476187135\n",
      "f1 macro of LFR 0.6530555150099742\n",
      "Disparate Impact of train 0.8417475787554527\n",
      "Disparate Impact of origin 0.7491391618375746\n",
      "f1 macro of origin 0.6590040259293829\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.746714763255576\n",
      "f1 macro of RW 0.6589915542624128\n",
      "Disparate Impact of train 0.8417475787554527\n",
      "Disparate Impact of DIremover 0.80396575033799\n",
      "f1 macro of DIremover 0.6594362497474238\n",
      "Disparate Impact of train 1.0298556430446193\n",
      "Disparate Impact of LFR 0.9678877970941464\n",
      "f1 macro of LFR 0.6481557032733638\n",
      "Disparate Impact of train 0.8322646527975681\n",
      "Disparate Impact of origin 0.7527835828565556\n",
      "f1 macro of origin 0.6684316745808372\n",
      "Disparate Impact of train 0.9999999999999998\n",
      "Disparate Impact of RW 0.7598249504182902\n",
      "f1 macro of RW 0.6646449806193176\n",
      "Disparate Impact of train 0.8322646527975681\n",
      "Disparate Impact of DIremover 0.7915821047055243\n",
      "f1 macro of DIremover 0.6506096887751922\n",
      "Disparate Impact of train 0.9696511393426093\n",
      "Disparate Impact of LFR 0.9824444629336883\n",
      "f1 macro of LFR 0.6652134920917223\n",
      "Disparate Impact of train 0.8186439174333263\n",
      "Disparate Impact of origin 0.8058576066702289\n",
      "f1 macro of origin 0.6544275613632698\n",
      "Disparate Impact of train 0.9999999999999998\n",
      "Disparate Impact of RW 0.805428671502905\n",
      "f1 macro of RW 0.6535279520698509\n",
      "Disparate Impact of train 0.8186439174333263\n",
      "Disparate Impact of DIremover 0.9408728936772313\n",
      "f1 macro of DIremover 0.6445047510819295\n",
      "Disparate Impact of train 0.8944425807894442\n",
      "Disparate Impact of LFR 0.9097190559484037\n",
      "f1 macro of LFR 0.6595996061700033\n",
      "Disparate Impact of train 0.8586089301680208\n",
      "Disparate Impact of origin 0.8235252919650518\n",
      "f1 macro of origin 0.6604272499248249\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.829248540298814\n",
      "f1 macro of RW 0.6567589952346023\n",
      "Disparate Impact of train 0.8586089301680208\n",
      "Disparate Impact of DIremover 0.987196123192759\n",
      "f1 macro of DIremover 0.6450816039211597\n",
      "Disparate Impact of train 0.911619283065513\n",
      "Disparate Impact of LFR 1.0135598141695703\n",
      "f1 macro of LFR 0.6579450967232867\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv('../data/report_preprocess_compas_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path,var_list,pa):\n",
    "    \"\"\"\n",
    "    Load and clean the Adult dataset, and discretize selected attributes \n",
    "    (age, hours-per-week, capital-gain, capital-loss).\n",
    "\n",
    "    Parameters:\n",
    "        data_path (str): Path to the input data file.\n",
    "        var_list (list of str): List of non-protected attribute names.\n",
    "        pa (str): Name of the protected attribute.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned dataset with discretized attributes.\n",
    "    \"\"\"\n",
    "\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education',\n",
    "                'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "                'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                'native-country', 'Y']\n",
    "    na_values=['?']\n",
    "    pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "    label_dict={'>50K.':1,'>50K':1,'<=50K.':0,'<=50K':0}\n",
    "    train_path = os.path.join(data_path, 'adult.data')\n",
    "    test_path = os.path.join(data_path, 'adult.test')\n",
    "    train = pd.read_csv(train_path, header=None,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    test = pd.read_csv(test_path, header=0,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    messydata = pd.concat([test, train], ignore_index=True)[var_list+[pa,'Y']]\n",
    "    messydata=messydata.rename(columns={pa:'S'})\n",
    "    messydata['S']=messydata['S'].replace(pa_dict)\n",
    "    messydata['Y']=messydata['Y'].replace(label_dict)\n",
    "    messydata=messydata[(messydata['S']==0)|(messydata['S']==1)]\n",
    "    for col in var_list+['S','Y']:\n",
    "        messydata[col]=messydata[col].astype('int64')\n",
    "    messydata['W']=1\n",
    "\n",
    "    # Define bin thresholds for discretizing attributes.\n",
    "    bins_capitalgain=[100,3500,7500,10000]\n",
    "    bins_capitalloss=[100,1600,1900,2200]\n",
    "    bins_age=[26,36,46,56]\n",
    "    bins_hours=[21,36,46,61]\n",
    "\n",
    "    # Apply discretization to attributes using predefined bins.\n",
    "    messydata=categerise(messydata,'age',bins_age)\n",
    "    messydata=categerise(messydata,'hours-per-week',bins_hours)\n",
    "    messydata=categerise(messydata,'capital-gain',bins_capitalgain)\n",
    "    messydata=categerise(messydata,'capital-loss',bins_capitalloss)\n",
    "    \n",
    "    return messydata\n",
    "\n",
    "def categerise(df,col,bins):\n",
    "    # Apply discretization to attributes using predefined bins.\n",
    "    for i in range(len(bins)+1):\n",
    "        if i == 0:\n",
    "            df.loc[df[col] < bins[i], col] = i\n",
    "        elif i == len(bins):\n",
    "            df.loc[df[col] >= bins[i-1], col] = i\n",
    "        else:\n",
    "            df.loc[(df[col] >= bins[i-1])& (df[col] < bins[i]), col] = i        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_x(var_list,messydata):\n",
    "    \"\"\"\n",
    "    Select non-protected attributes to repair based on their \n",
    "    protected-attribute-wise Total Variation distance.\n",
    "\n",
    "    Attributes are selected if their Total Variation distance exceeds a threshold (default: 0.1).\n",
    "\n",
    "    Parameters:\n",
    "        var_list (list of str): List of non-protected attribute names.\n",
    "        messydata (pd.DataFrame): The cleaned dataset.\n",
    "\n",
    "    Returns:\n",
    "        x_list (list of str): List of non-protected attributes that need to be repaired.\n",
    "        tv_dist (dict): Dictionary mapping each non-protected attribute to its \n",
    "                        protected-attribute-wise Total Variation distance.\n",
    "    \"\"\"\n",
    "\n",
    "    tv_dist=dict()\n",
    "    for x_name in var_list:\n",
    "        x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "        dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "        tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    x_list=[]\n",
    "    for key,val in tv_dist.items():\n",
    "        if val>0.1:\n",
    "            x_list+=[key]  \n",
    "    return x_list,tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='..//data//adult'\n",
    "var_list=['hours-per-week','age','capital-gain','capital-loss','education-num'] #,'education-num'\n",
    "pa='race'\n",
    "favorable_label = 1\n",
    "var_dim=len(var_list)\n",
    "\n",
    "messydata = load_data(data_path,var_list,pa)\n",
    "x_list,tv_dist = choose_x(var_list,messydata)\n",
    "messydata=messydata.rename(columns={'S':pa})\n",
    "cd=BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=messydata,label_names='Y',protected_attribute_names=[pa])\n",
    "# train,test = cd.split([0.4], shuffle=True) \n",
    "# valid,test = test.split([0.3], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact of train 0.5000825058028662\n",
      "Disparate Impact of origin 0.4046958269560567\n",
      "f1 macro of origin 0.6663261486871457\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.41016647087093505\n",
      "f1 macro of RW 0.6710584991584593\n",
      "Disparate Impact of train 0.5000825058028662\n",
      "Disparate Impact of DIremover 0.41308181484104006\n",
      "f1 macro of DIremover 0.6699064537921172\n",
      "Disparate Impact of train 0.8755743194114555\n",
      "Disparate Impact of LFR 0.7867481172608234\n",
      "f1 macro of LFR 0.7171789436973832\n",
      "Disparate Impact of train 0.49481626800153516\n",
      "Disparate Impact of origin 0.4553451896164726\n",
      "f1 macro of origin 0.6808057898406992\n",
      "Disparate Impact of train 0.9999999999999999\n",
      "Disparate Impact of RW 0.4376999034707241\n",
      "f1 macro of RW 0.6785408446424354\n",
      "Disparate Impact of train 0.49481626800153516\n",
      "Disparate Impact of DIremover 0.46199936770159533\n",
      "f1 macro of DIremover 0.6810962451451772\n",
      "Disparate Impact of train 0.8488979433944619\n",
      "Disparate Impact of LFR 0.8676206419250193\n",
      "f1 macro of LFR 0.6971965427293818\n",
      "Disparate Impact of train 0.4794055516380791\n",
      "Disparate Impact of origin 0.49040611768772147\n",
      "f1 macro of origin 0.6727629420146823\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.4865683951345476\n",
      "f1 macro of RW 0.6731373094497046\n",
      "Disparate Impact of train 0.4794055516380791\n",
      "Disparate Impact of DIremover 0.4945447373796426\n",
      "f1 macro of DIremover 0.6701077442876013\n",
      "Disparate Impact of train 0.7636359314923148\n",
      "Disparate Impact of LFR 0.7913218384189505\n",
      "f1 macro of LFR 0.7085934441211493\n",
      "Disparate Impact of train 0.4706161476421528\n",
      "Disparate Impact of origin 0.48988840175368675\n",
      "f1 macro of origin 0.6781295289172087\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.4875669793621013\n",
      "f1 macro of RW 0.6856444339655916\n",
      "Disparate Impact of train 0.4706161476421528\n",
      "Disparate Impact of DIremover 0.4972698048220436\n",
      "f1 macro of DIremover 0.6822344066649284\n",
      "Disparate Impact of train 0.8029598671117897\n",
      "Disparate Impact of LFR 0.8237541560411892\n",
      "f1 macro of LFR 0.6865188271234055\n",
      "Disparate Impact of train 0.5118554042399034\n",
      "Disparate Impact of origin 0.4152810984862504\n",
      "f1 macro of origin 0.6824761979533163\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.42351959818615836\n",
      "f1 macro of RW 0.6824452882768672\n",
      "Disparate Impact of train 0.5118554042399034\n",
      "Disparate Impact of DIremover 0.4246876059031638\n",
      "f1 macro of DIremover 0.685859975805122\n",
      "Disparate Impact of train 0.8889084393174116\n",
      "Disparate Impact of LFR 0.7841361739550283\n",
      "f1 macro of LFR 0.7033371808581483\n",
      "Disparate Impact of train 0.49070380706111266\n",
      "Disparate Impact of origin 0.45212193068993295\n",
      "f1 macro of origin 0.6677185872132432\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.4408536522993307\n",
      "f1 macro of RW 0.6753247688396786\n",
      "Disparate Impact of train 0.49070380706111266\n",
      "Disparate Impact of DIremover 0.44022546012786284\n",
      "f1 macro of DIremover 0.6758257460431226\n",
      "Disparate Impact of train 0.76284556111456\n",
      "Disparate Impact of LFR 0.7312221418374977\n",
      "f1 macro of LFR 0.7014029448812058\n",
      "Disparate Impact of train 0.4848859515835507\n",
      "Disparate Impact of origin 0.4663450518290871\n",
      "f1 macro of origin 0.6809845100031624\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.44223358714063127\n",
      "f1 macro of RW 0.6741000352984389\n",
      "Disparate Impact of train 0.4848859515835507\n",
      "Disparate Impact of DIremover 0.4793484544778821\n",
      "f1 macro of DIremover 0.6824549318370572\n",
      "Disparate Impact of train 0.7525065112929712\n",
      "Disparate Impact of LFR 0.87941692999294\n",
      "f1 macro of LFR 0.6967755143118259\n",
      "Disparate Impact of train 0.5032305255867342\n",
      "Disparate Impact of origin 0.4445353918899556\n",
      "f1 macro of origin 0.6788917530707204\n",
      "Disparate Impact of train 0.9999999999999999\n",
      "Disparate Impact of RW 0.4223846093566335\n",
      "f1 macro of RW 0.6688687883421417\n",
      "Disparate Impact of train 0.5032305255867342\n",
      "Disparate Impact of DIremover 0.4335227272727273\n",
      "f1 macro of DIremover 0.6811317054035501\n",
      "Disparate Impact of train 0.8196303579822551\n",
      "Disparate Impact of LFR 0.8048586789554532\n",
      "f1 macro of LFR 0.6871219428219805\n",
      "Disparate Impact of train 0.4890437541679126\n",
      "Disparate Impact of origin 0.45846125386047076\n",
      "f1 macro of origin 0.6767196053283491\n",
      "Disparate Impact of train 1.0000000000000002\n",
      "Disparate Impact of RW 0.4553899528522996\n",
      "f1 macro of RW 0.6760546595527283\n",
      "Disparate Impact of train 0.4890437541679126\n",
      "Disparate Impact of DIremover 0.4507383230909988\n",
      "f1 macro of DIremover 0.6793130220983372\n",
      "Disparate Impact of train 0.8238760202624498\n",
      "Disparate Impact of LFR 0.8364757561229099\n",
      "f1 macro of LFR 0.6815604644751729\n",
      "Disparate Impact of train 0.5067465247328591\n",
      "Disparate Impact of origin 0.42244521288793374\n",
      "f1 macro of origin 0.683855197910967\n",
      "Disparate Impact of train 1\n",
      "Disparate Impact of RW 0.42898137814387494\n",
      "f1 macro of RW 0.6803371747120603\n",
      "Disparate Impact of train 0.5067465247328591\n",
      "Disparate Impact of DIremover 0.4403353942262482\n",
      "f1 macro of DIremover 0.6873717904664444\n",
      "Disparate Impact of train 0.8538532766322166\n",
      "Disparate Impact of LFR 0.8695825056746008\n",
      "f1 macro of LFR 0.6991161132514536\n"
     ]
    }
   ],
   "source": [
    "methods=['origin','RW','DIremover','LFR'] \n",
    "report=pd.DataFrame(columns=['DI of train','DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    train,test = cd.split([0.4], shuffle=True) \n",
    "    valid,test = test.split([0.3], shuffle=True)\n",
    "    \n",
    "    prepro = Baselinepreprocess(train,test)\n",
    "    for method in methods:\n",
    "        report = pd.concat([report,prepro.assess(method)], ignore_index=True)\n",
    "\n",
    "report.to_csv('../data/report_preprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI of train</th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500083</td>\n",
       "      <td>0.404696</td>\n",
       "      <td>0.666326</td>\n",
       "      <td>0.813419</td>\n",
       "      <td>0.781169</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.410166</td>\n",
       "      <td>0.671058</td>\n",
       "      <td>0.814547</td>\n",
       "      <td>0.783678</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500083</td>\n",
       "      <td>0.413082</td>\n",
       "      <td>0.669906</td>\n",
       "      <td>0.814188</td>\n",
       "      <td>0.783034</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.875574</td>\n",
       "      <td>0.786748</td>\n",
       "      <td>0.717179</td>\n",
       "      <td>0.815521</td>\n",
       "      <td>0.80363</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.494816</td>\n",
       "      <td>0.455345</td>\n",
       "      <td>0.680806</td>\n",
       "      <td>0.816905</td>\n",
       "      <td>0.790174</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4377</td>\n",
       "      <td>0.678541</td>\n",
       "      <td>0.816597</td>\n",
       "      <td>0.789083</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.494816</td>\n",
       "      <td>0.461999</td>\n",
       "      <td>0.681096</td>\n",
       "      <td>0.817264</td>\n",
       "      <td>0.790443</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.848898</td>\n",
       "      <td>0.867621</td>\n",
       "      <td>0.697197</td>\n",
       "      <td>0.812087</td>\n",
       "      <td>0.795069</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.479406</td>\n",
       "      <td>0.490406</td>\n",
       "      <td>0.672763</td>\n",
       "      <td>0.817264</td>\n",
       "      <td>0.786043</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.486568</td>\n",
       "      <td>0.673137</td>\n",
       "      <td>0.817161</td>\n",
       "      <td>0.786166</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.479406</td>\n",
       "      <td>0.494545</td>\n",
       "      <td>0.670108</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.784606</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.791322</td>\n",
       "      <td>0.708593</td>\n",
       "      <td>0.817674</td>\n",
       "      <td>0.801471</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.470616</td>\n",
       "      <td>0.489888</td>\n",
       "      <td>0.67813</td>\n",
       "      <td>0.816341</td>\n",
       "      <td>0.787637</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.487567</td>\n",
       "      <td>0.685644</td>\n",
       "      <td>0.817981</td>\n",
       "      <td>0.791541</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.470616</td>\n",
       "      <td>0.49727</td>\n",
       "      <td>0.682234</td>\n",
       "      <td>0.816854</td>\n",
       "      <td>0.789618</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.80296</td>\n",
       "      <td>0.823754</td>\n",
       "      <td>0.686519</td>\n",
       "      <td>0.809473</td>\n",
       "      <td>0.78845</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.511855</td>\n",
       "      <td>0.415281</td>\n",
       "      <td>0.682476</td>\n",
       "      <td>0.816803</td>\n",
       "      <td>0.790041</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.42352</td>\n",
       "      <td>0.682445</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.789987</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.511855</td>\n",
       "      <td>0.424688</td>\n",
       "      <td>0.68586</td>\n",
       "      <td>0.817418</td>\n",
       "      <td>0.791742</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.888908</td>\n",
       "      <td>0.784136</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>0.811318</td>\n",
       "      <td>0.796557</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.490704</td>\n",
       "      <td>0.452122</td>\n",
       "      <td>0.667719</td>\n",
       "      <td>0.812394</td>\n",
       "      <td>0.779397</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.440854</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.81424</td>\n",
       "      <td>0.783498</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.490704</td>\n",
       "      <td>0.440225</td>\n",
       "      <td>0.675826</td>\n",
       "      <td>0.813983</td>\n",
       "      <td>0.78362</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.762846</td>\n",
       "      <td>0.731222</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>0.812241</td>\n",
       "      <td>0.794066</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.484886</td>\n",
       "      <td>0.466345</td>\n",
       "      <td>0.680985</td>\n",
       "      <td>0.817008</td>\n",
       "      <td>0.788541</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.442234</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.815931</td>\n",
       "      <td>0.785107</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.484886</td>\n",
       "      <td>0.479348</td>\n",
       "      <td>0.682455</td>\n",
       "      <td>0.816854</td>\n",
       "      <td>0.789121</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.752507</td>\n",
       "      <td>0.879417</td>\n",
       "      <td>0.696776</td>\n",
       "      <td>0.812343</td>\n",
       "      <td>0.79343</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.503231</td>\n",
       "      <td>0.444535</td>\n",
       "      <td>0.678892</td>\n",
       "      <td>0.815829</td>\n",
       "      <td>0.788065</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.422385</td>\n",
       "      <td>0.668869</td>\n",
       "      <td>0.814188</td>\n",
       "      <td>0.783076</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.503231</td>\n",
       "      <td>0.433523</td>\n",
       "      <td>0.681132</td>\n",
       "      <td>0.816495</td>\n",
       "      <td>0.789297</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.81963</td>\n",
       "      <td>0.804859</td>\n",
       "      <td>0.687122</td>\n",
       "      <td>0.811472</td>\n",
       "      <td>0.789815</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.489044</td>\n",
       "      <td>0.458461</td>\n",
       "      <td>0.67672</td>\n",
       "      <td>0.815624</td>\n",
       "      <td>0.786568</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.45539</td>\n",
       "      <td>0.676055</td>\n",
       "      <td>0.815419</td>\n",
       "      <td>0.786197</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.489044</td>\n",
       "      <td>0.450738</td>\n",
       "      <td>0.679313</td>\n",
       "      <td>0.816392</td>\n",
       "      <td>0.787999</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.823876</td>\n",
       "      <td>0.836476</td>\n",
       "      <td>0.68156</td>\n",
       "      <td>0.80773</td>\n",
       "      <td>0.785465</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.506747</td>\n",
       "      <td>0.422445</td>\n",
       "      <td>0.683855</td>\n",
       "      <td>0.817366</td>\n",
       "      <td>0.789386</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>0.428981</td>\n",
       "      <td>0.680337</td>\n",
       "      <td>0.816444</td>\n",
       "      <td>0.78748</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.506747</td>\n",
       "      <td>0.440335</td>\n",
       "      <td>0.687372</td>\n",
       "      <td>0.817571</td>\n",
       "      <td>0.791004</td>\n",
       "      <td>DIremover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.853853</td>\n",
       "      <td>0.869583</td>\n",
       "      <td>0.699116</td>\n",
       "      <td>0.811933</td>\n",
       "      <td>0.793753</td>\n",
       "      <td>LFR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DI of train        DI  f1 macro  f1 micro f1 weighted     method\n",
       "0     0.500083  0.404696  0.666326  0.813419    0.781169     origin\n",
       "1          1.0  0.410166  0.671058  0.814547    0.783678         RW\n",
       "2     0.500083  0.413082  0.669906  0.814188    0.783034  DIremover\n",
       "3     0.875574  0.786748  0.717179  0.815521     0.80363        LFR\n",
       "4     0.494816  0.455345  0.680806  0.816905    0.790174     origin\n",
       "5          1.0    0.4377  0.678541  0.816597    0.789083         RW\n",
       "6     0.494816  0.461999  0.681096  0.817264    0.790443  DIremover\n",
       "7     0.848898  0.867621  0.697197  0.812087    0.795069        LFR\n",
       "8     0.479406  0.490406  0.672763  0.817264    0.786043     origin\n",
       "9            1  0.486568  0.673137  0.817161    0.786166         RW\n",
       "10    0.479406  0.494545  0.670108  0.816546    0.784606  DIremover\n",
       "11    0.763636  0.791322  0.708593  0.817674    0.801471        LFR\n",
       "12    0.470616  0.489888   0.67813  0.816341    0.787637     origin\n",
       "13           1  0.487567  0.685644  0.817981    0.791541         RW\n",
       "14    0.470616   0.49727  0.682234  0.816854    0.789618  DIremover\n",
       "15     0.80296  0.823754  0.686519  0.809473     0.78845        LFR\n",
       "16    0.511855  0.415281  0.682476  0.816803    0.790041     origin\n",
       "17         1.0   0.42352  0.682445    0.8167    0.789987         RW\n",
       "18    0.511855  0.424688   0.68586  0.817418    0.791742  DIremover\n",
       "19    0.888908  0.784136  0.703337  0.811318    0.796557        LFR\n",
       "20    0.490704  0.452122  0.667719  0.812394    0.779397     origin\n",
       "21           1  0.440854  0.675325   0.81424    0.783498         RW\n",
       "22    0.490704  0.440225  0.675826  0.813983     0.78362  DIremover\n",
       "23    0.762846  0.731222  0.701403  0.812241    0.794066        LFR\n",
       "24    0.484886  0.466345  0.680985  0.817008    0.788541     origin\n",
       "25           1  0.442234    0.6741  0.815931    0.785107         RW\n",
       "26    0.484886  0.479348  0.682455  0.816854    0.789121  DIremover\n",
       "27    0.752507  0.879417  0.696776  0.812343     0.79343        LFR\n",
       "28    0.503231  0.444535  0.678892  0.815829    0.788065     origin\n",
       "29         1.0  0.422385  0.668869  0.814188    0.783076         RW\n",
       "30    0.503231  0.433523  0.681132  0.816495    0.789297  DIremover\n",
       "31     0.81963  0.804859  0.687122  0.811472    0.789815        LFR\n",
       "32    0.489044  0.458461   0.67672  0.815624    0.786568     origin\n",
       "33         1.0   0.45539  0.676055  0.815419    0.786197         RW\n",
       "34    0.489044  0.450738  0.679313  0.816392    0.787999  DIremover\n",
       "35    0.823876  0.836476   0.68156   0.80773    0.785465        LFR\n",
       "36    0.506747  0.422445  0.683855  0.817366    0.789386     origin\n",
       "37           1  0.428981  0.680337  0.816444     0.78748         RW\n",
       "38    0.506747  0.440335  0.687372  0.817571    0.791004  DIremover\n",
       "39    0.853853  0.869583  0.699116  0.811933    0.793753        LFR"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
