{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "from aif360.datasets import BinaryLabelDataset, AdultDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from functions import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path=os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROCpostprocess:\n",
    "    def __init__(self,X_val,y_val,var_list,prediction_model,favorable_label):\n",
    "        self.X_val =X_val\n",
    "        self.y_val =y_val\n",
    "        self.model = prediction_model\n",
    "        self.positive_index = 1 # positive label\n",
    "        self.var_list = var_list\n",
    "        self.var_dim=len(self.var_list)\n",
    "        self.ROC = self.buildROCusingval()\n",
    "        self.favorable_label = favorable_label\n",
    "\n",
    "    def buildbinarydata(self,X,y):\n",
    "        df=pd.DataFrame(np.concatenate((X,y.reshape(-1,1)), axis=1),columns=self.var_list+['S','W','Y'])\n",
    "        binaryLabelDataset = BinaryLabelDataset(\n",
    "                            # favorable_label=self.favorable_label,\n",
    "                            # unfavorable_label=0,\n",
    "                            df=df[self.var_list+['S','W','Y']], #df_test.drop('X',axis=1), #[x_list+['S','W','Y']],\n",
    "                            label_names=['Y'],\n",
    "                            instance_weights_name=['W'],\n",
    "                            protected_attribute_names=['S'],\n",
    "                            privileged_protected_attributes=[np.array([1.0])],\n",
    "                            unprivileged_protected_attributes=[np.array([0.])])\n",
    "        return binaryLabelDataset,df\n",
    "\n",
    "    def buildROCusingval(self):\n",
    "        dataset_val = self.buildbinarydata(self.X_val,self.y_val)[0]\n",
    "        dataset_val_pred = dataset_val.copy(deepcopy=True)\n",
    "        dataset_val_pred.scores = self.model.predict_proba(dataset_val.features[:,0:self.var_dim])[:,self.positive_index].reshape(-1,1)\n",
    "        privileged_groups = [{'S': 1}]\n",
    "        unprivileged_groups = [{'S': 0}]\n",
    "        # Metric used (should be one of allowed_metrics)\n",
    "        metric_name = \"Statistical parity difference\"\n",
    "        # Upper and lower bound on the fairness metric used\n",
    "        metric_ub = 0.05\n",
    "        metric_lb = -0.05\n",
    "        ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                        privileged_groups=privileged_groups, \n",
    "                                        low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                        num_class_thresh=50, num_ROC_margin=10,\n",
    "                                        metric_name=metric_name,\n",
    "                                        metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "        ROC = ROC.fit(dataset_val, dataset_val_pred)\n",
    "        print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "        print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)\n",
    "        return ROC\n",
    "\n",
    "    def postprocess(self,X_test,y_test,tv_origin): # the tv distance won't change\n",
    "        dataset_test_pred,df_test = self.buildbinarydata(X_test,y_test) #.copy(deepcopy=True)\n",
    "        dataset_test_pred.scores = self.model.predict_proba(X_test[:,0:self.var_dim])[:,self.positive_index].reshape(-1,1)\n",
    "        dataset_test_pred_transf = self.ROC.predict(dataset_test_pred)\n",
    "        y_pred = dataset_test_pred_transf.labels\n",
    "        # return dataset_test_pred_transf.convert_to_dataframe()[0]\n",
    "\n",
    "        di = DisparateImpact_postprocess(df_test,y_pred,favorable_label=self.favorable_label)\n",
    "        f1_macro = f1_score(df_test['Y'], y_pred, average='macro',sample_weight=df_test['W'])\n",
    "        f1_micro = f1_score(df_test['Y'], y_pred, average='micro',sample_weight=df_test['W'])\n",
    "        f1_weighted = f1_score(df_test['Y'], y_pred, average='weighted',sample_weight=df_test['W'])\n",
    "        new_row=pd.Series({'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,\n",
    "                           'TV distance':tv_origin,'method':'ROC'})\n",
    "        return new_row.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projpostprocess:\n",
    "    \n",
    "    def __init__(self,X_test,y_test,x_list,var_list,prediction_model,K,e,thresh,favorable_label=1):\n",
    "        self.model = prediction_model\n",
    "        self.K=K\n",
    "        self.e=e\n",
    "        self.x_list=x_list\n",
    "        self.var_list=var_list\n",
    "        self.var_dim=len(var_list)\n",
    "        self.favorable_label = favorable_label\n",
    "\n",
    "        df_test=pd.DataFrame(np.concatenate((X_test,y_test.reshape(-1,1)), axis=1),columns=var_list+['S','W','Y'])\n",
    "        df_test=df_test.groupby(by=var_list+['S','Y'],as_index=False).sum()\n",
    "        if len(x_list)>1:\n",
    "            df_test['X'] = list(zip(*[df_test[c] for c in x_list]))\n",
    "            self.x_range=sorted(set(df_test['X']))\n",
    "            weight=list(1/(df_test[x_list].max()-df_test[x_list].min())) # because 'education-num' range from 1 to 16 while others 1 to 4\n",
    "            self.C=c_generate_higher(self.x_range,weight)\n",
    "        else:\n",
    "            df_test['X']=df_test[x_list]\n",
    "            self.x_range=sorted(set(df_test['X']))\n",
    "            self.C=c_generate(self.x_range)\n",
    "        self.df_test = df_test\n",
    "        self.var_range=list(pd.pivot_table(df_test,index=var_list,values=['S','W','Y']).index)\n",
    "        self.distribution_generator()\n",
    "        \n",
    "        if thresh == 'auto':\n",
    "            self.thresh_generator()\n",
    "        else:\n",
    "            self.thresh=thresh\n",
    "\n",
    "    def distribution_generator(self):\n",
    "        bin=len(self.x_range)\n",
    "        dist=rdata_analysis(self.df_test,self.x_range,'X')\n",
    "        \n",
    "        dist['v']=[(dist['x_0'][i]-dist['x_1'][i])/dist['x'][i] for i in range(bin)]\n",
    "        \n",
    "        dist['t_x']=dist['x'] # #dist['x'] #dist['x_0']*0.5+dist['x_1']*0.5 \n",
    "        self.px=np.matrix(dist['x']).T\n",
    "        self.ptx=np.matrix(dist['t_x']).T\n",
    "        if np.any(dist['x_0']==0): \n",
    "            self.p0=np.matrix((dist['x_0']+1.0e-9)/sum(dist['x_0']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p0=np.matrix(dist['x_0']).T \n",
    "        if np.any(dist['x_1']==0):\n",
    "            self.p1=np.matrix((dist['x_1']+1.0e-9)/sum(dist['x_1']+1.0e-9)).T\n",
    "        else:\n",
    "            self.p1=np.matrix(dist['x_1']).T \n",
    "        self.V=np.matrix(dist['v']).T\n",
    "        self.tv_origin=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "        # return px,ptx,V,p0,p1\n",
    "    \n",
    "    def coupling_generator(self,method,para=None):\n",
    "        if method == 'unconstrained':\n",
    "            coupling=baseline(self.C,self.e,self.px,self.ptx,self.K)\n",
    "        elif method == 'barycentre':\n",
    "            coupling=baseline(self.C,self.e,self.p0,self.p1,self.K)\n",
    "        elif method == 'partial':\n",
    "            # coupling = np.matrix(np.outer(self.px,self.ptx))\n",
    "            coupling=partial_repair(self.C,self.e,self.px,self.ptx,self.V,para,self.K)\n",
    "        return coupling\n",
    "\n",
    "    def postprocess(self,method,para=None):\n",
    "        if method == 'origin':\n",
    "            y_pred=self.model.predict(np.array(self.df_test[self.var_list]))\n",
    "            tv = self.tv_origin\n",
    "        else:\n",
    "            if (method == 'unconstrained') or (method == 'partial'):\n",
    "                coupling = self.coupling_generator(method,para)\n",
    "                y_pred=postprocess(self.df_test,coupling,self.x_list,self.x_range,self.var_list,self.var_range,self.model,self.thresh)\n",
    "                tv=assess_tv(self.df_test,coupling,self.x_range,self.x_list,self.var_list)\n",
    "                if (para != None) and (method == 'partial'):\n",
    "                    method = method+'_'+str(para)\n",
    "            elif method == 'barycentre':\n",
    "                coupling = self.coupling_generator(method,para)\n",
    "                y_pred,tv=postprocess_bary(self.df_test,coupling,self.x_list,self.x_range,self.var_list,self.var_range,self.model,self.thresh)\n",
    "            else:\n",
    "                print('Unknown method')\n",
    "\n",
    "        di = DisparateImpact_postprocess(self.df_test,y_pred,favorable_label=self.favorable_label)\n",
    "        f1_macro = f1_score(self.df_test['Y'], y_pred, average='macro',sample_weight=self.df_test['W'])\n",
    "        f1_micro = f1_score(self.df_test['Y'], y_pred, average='micro',sample_weight=self.df_test['W'])\n",
    "        f1_weighted = f1_score(self.df_test['Y'], y_pred, average='weighted',sample_weight=self.df_test['W'])\n",
    "\n",
    "        new_row=pd.Series({'DI':di,'f1 macro':f1_macro,'f1 micro':f1_micro,'f1 weighted':f1_weighted,\n",
    "                           'TV distance':tv,'method':method})\n",
    "        return new_row.to_frame().T\n",
    "    \n",
    "    def thresh_generator(self):\n",
    "        num_thresh = 10\n",
    "        ba_arr = np.zeros(num_thresh)\n",
    "        ba_arr1 = np.zeros(num_thresh)\n",
    "        class_thresh_arr = np.linspace(0.1, 0.9, num_thresh)\n",
    "        coupling=self.coupling_generator('partial',para=1e-3)\n",
    "    \n",
    "        for idx, thresh in enumerate(class_thresh_arr):\n",
    "            y_pred=postprocess(self.df_test,coupling,self.x_list,self.x_range,self.var_list,self.var_range,self.model,thresh)\n",
    "            ba_arr[idx] = DisparateImpact_postprocess(self.df_test,y_pred,favorable_label=self.favorable_label)\n",
    "            ba_arr1[idx] = f1_score(self.df_test['Y'], y_pred, average='macro',sample_weight=self.df_test['W'])\n",
    "\n",
    "        best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "        best_thresh = class_thresh_arr[best_ind]\n",
    "        print(\"Optional threshold = \",class_thresh_arr)\n",
    "        print(\"Disparate Impact = \",ba_arr)\n",
    "        print(\"f1 scores = \",ba_arr1)\n",
    "        self.thresh = best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path,var_list,pa):\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education',\n",
    "                'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "                'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                'native-country', 'Y']\n",
    "    na_values=['?']\n",
    "    pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "    label_dict={'>50K.':1,'>50K':1,'<=50K.':0,'<=50K':0}\n",
    "    train_path = os.path.join(data_path, 'adult.data')\n",
    "    test_path = os.path.join(data_path, 'adult.test')\n",
    "    train = pd.read_csv(train_path, header=None,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    test = pd.read_csv(test_path, header=0,names=column_names,\n",
    "                    skipinitialspace=True, na_values=na_values)\n",
    "    messydata = pd.concat([test, train], ignore_index=True)[var_list+[pa,'Y']]\n",
    "    messydata=messydata.rename(columns={pa:'S'})\n",
    "    messydata['S']=messydata['S'].replace(pa_dict)\n",
    "    messydata['Y']=messydata['Y'].replace(label_dict)\n",
    "    messydata=messydata[(messydata['S']==0)|(messydata['S']==1)]\n",
    "    for col in var_list+['S','Y']:\n",
    "        messydata[col]=messydata[col].astype('int64')\n",
    "    messydata['W']=1\n",
    "    bins_capitalgain=[100,3500,7500,10000]\n",
    "    bins_capitalloss=[100,1600,1900,2200]\n",
    "    bins_age=[26,36,46,56]\n",
    "    bins_hours=[21,36,46,61]\n",
    "\n",
    "    messydata=categerise(messydata,'age',bins_age)\n",
    "    # messydata=categerise(messydata,'hours-per-week',bins_hours)\n",
    "    messydata=categerise(messydata,'capital-gain',bins_capitalgain)\n",
    "    messydata=categerise(messydata,'capital-loss',bins_capitalloss)\n",
    "    \n",
    "    return messydata\n",
    "\n",
    "def categerise(df,col,bins):\n",
    "    for i in range(len(bins)+1):\n",
    "        if i == 0:\n",
    "            df.loc[df[col] < bins[i], col] = i\n",
    "        elif i == len(bins):\n",
    "            df.loc[df[col] >= bins[i-1], col] = i\n",
    "        else:\n",
    "            df.loc[(df[col] >= bins[i-1])& (df[col] < bins[i]), col] = i        \n",
    "    return df\n",
    "\n",
    "def choose_x(var_list,messydata):\n",
    "    tv_dist=dict()\n",
    "    for x_name in var_list:\n",
    "        x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "        dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "        tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "    x_list=[]\n",
    "    for key,val in tv_dist.items():\n",
    "        if val>0.1:\n",
    "            x_list+=[key]  \n",
    "    return x_list,tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='C://Users//zhouq//anaconda3//Lib//site-packages//aif360//data//raw//adult'\n",
    "var_list=['age','capital-gain','capital-loss','education-num'] #'hours-per-week',\n",
    "pa='sex'\n",
    "favorable_label = 1\n",
    "var_dim=len(var_list)\n",
    "\n",
    "K=200\n",
    "e=0.01\n",
    "\n",
    "if pa == 'sex':\n",
    "    thresh=0.05\n",
    "elif pa == 'race':\n",
    "    thresh=0.1\n",
    "\n",
    "messydata = load_data(data_path,var_list,pa)\n",
    "x_list,tv_dist = choose_x(var_list,messydata)\n",
    "\n",
    "X=messydata[var_list+['S','W']].to_numpy() # [X,S,W]\n",
    "y=messydata['Y'].to_numpy() #[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 0.1010227688866829,\n",
       " 'capital-gain': 0.036924675713792855,\n",
       " 'capital-loss': 0.020068855964263464,\n",
       " 'education-num': 0.07095473385227195}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:166: RuntimeWarning: overflow encountered in exp\n",
      "  fun = lambda z: sum(tmp.item(i,j)*V.item(i)*np.exp(-z*V.item(i)) for i in I)+theta.item(j)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:167: RuntimeWarning: overflow encountered in exp\n",
      "  dfun = lambda z: -sum(tmp.item(i,j)*(V.item(i))**2*np.exp(-z*V.item(i)) for i in I)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:34: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  b=a-fun(a)/dfun(a)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:198: RuntimeWarning: invalid value encountered in divide\n",
      "  rdist['x']= np.array([pivot[i] for i in x_range])/sum([pivot[i] for i in x_range]) #empirical_distribution(rdata,x_range)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:201: RuntimeWarning: invalid value encountered in divide\n",
      "  rdist['x_0']=np.array([pivot0[i] if i in list(pivot0.index) else 0 for i in x_range])/sum([pivot0[i] if i in list(pivot0.index) else 0 for i in x_range]) #empirical_distribution(rdata[rdata['S']==0],x_range)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:204: RuntimeWarning: invalid value encountered in divide\n",
      "  rdist['x_1']=np.array([pivot1[i] if i in list(pivot1.index) else 0 for i in x_range])/sum([pivot1[i] if i in list(pivot1.index) else 0 for i in x_range]) #empirical_distribution(rdata[rdata['S']==1],x_range)\n"
     ]
    }
   ],
   "source": [
    "thresh=0.05\n",
    "x_list = ['age','education-num']\n",
    "methods=['origin','barycentre','partial']\n",
    "report=pd.DataFrame(columns=['DI','f1 macro','f1 micro','f1 weighted','TV distance','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "    \n",
    "    clf=RandomForestClassifier(max_depth=5).fit(X_train[:,0:var_dim],y_train)\n",
    "    projpost = Projpostprocess(X_test,y_test,x_list,var_list,clf,K,e,thresh,favorable_label)\n",
    "    for method in methods[:-1]:\n",
    "        report = pd.concat([report,projpost.postprocess(method)], ignore_index=True)\n",
    "    \n",
    "    for p in [1e-2,1e-3,1e-4]:\n",
    "        report = pd.concat([report,projpost.postprocess('partial',para=p)], ignore_index=True)\n",
    "\n",
    "report.to_csv(path+'/data/E3_postprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>TV distance</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.560671</td>\n",
       "      <td>0.677944</td>\n",
       "      <td>0.811537</td>\n",
       "      <td>0.784761</td>\n",
       "      <td>0.122976</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973587</td>\n",
       "      <td>0.576042</td>\n",
       "      <td>0.676306</td>\n",
       "      <td>0.682216</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064175</td>\n",
       "      <td>0.598993</td>\n",
       "      <td>0.727645</td>\n",
       "      <td>0.715961</td>\n",
       "      <td>0.087166</td>\n",
       "      <td>partial_0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.113045</td>\n",
       "      <td>0.578018</td>\n",
       "      <td>0.697548</td>\n",
       "      <td>0.693674</td>\n",
       "      <td>0.026431</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.113832</td>\n",
       "      <td>0.579263</td>\n",
       "      <td>0.694733</td>\n",
       "      <td>0.69277</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>partial_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.579547</td>\n",
       "      <td>0.69945</td>\n",
       "      <td>0.818345</td>\n",
       "      <td>0.798093</td>\n",
       "      <td>0.127461</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.902633</td>\n",
       "      <td>0.566764</td>\n",
       "      <td>0.678661</td>\n",
       "      <td>0.681659</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.037146</td>\n",
       "      <td>0.615288</td>\n",
       "      <td>0.728515</td>\n",
       "      <td>0.724199</td>\n",
       "      <td>0.087271</td>\n",
       "      <td>partial_0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.039891</td>\n",
       "      <td>0.613875</td>\n",
       "      <td>0.699852</td>\n",
       "      <td>0.708954</td>\n",
       "      <td>0.028237</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.037299</td>\n",
       "      <td>0.616844</td>\n",
       "      <td>0.699442</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>partial_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.547099</td>\n",
       "      <td>0.682235</td>\n",
       "      <td>0.818038</td>\n",
       "      <td>0.791445</td>\n",
       "      <td>0.123847</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.877256</td>\n",
       "      <td>0.536453</td>\n",
       "      <td>0.641603</td>\n",
       "      <td>0.652519</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.094295</td>\n",
       "      <td>0.593795</td>\n",
       "      <td>0.727338</td>\n",
       "      <td>0.716239</td>\n",
       "      <td>0.086755</td>\n",
       "      <td>partial_0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.074207</td>\n",
       "      <td>0.611179</td>\n",
       "      <td>0.715258</td>\n",
       "      <td>0.716937</td>\n",
       "      <td>0.027666</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.611039</td>\n",
       "      <td>0.678609</td>\n",
       "      <td>0.813584</td>\n",
       "      <td>0.786847</td>\n",
       "      <td>0.141578</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.123457</td>\n",
       "      <td>0.531822</td>\n",
       "      <td>0.639351</td>\n",
       "      <td>0.648424</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.016452</td>\n",
       "      <td>0.612386</td>\n",
       "      <td>0.744894</td>\n",
       "      <td>0.730162</td>\n",
       "      <td>0.093664</td>\n",
       "      <td>partial_0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.005709</td>\n",
       "      <td>0.614068</td>\n",
       "      <td>0.716538</td>\n",
       "      <td>0.717413</td>\n",
       "      <td>0.028038</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.072161</td>\n",
       "      <td>0.595851</td>\n",
       "      <td>0.687055</td>\n",
       "      <td>0.695624</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>partial_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.560584</td>\n",
       "      <td>0.662176</td>\n",
       "      <td>0.810718</td>\n",
       "      <td>0.779508</td>\n",
       "      <td>0.127487</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.243626</td>\n",
       "      <td>0.530951</td>\n",
       "      <td>0.660234</td>\n",
       "      <td>0.659932</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.158183</td>\n",
       "      <td>0.580881</td>\n",
       "      <td>0.721861</td>\n",
       "      <td>0.7082</td>\n",
       "      <td>0.082712</td>\n",
       "      <td>partial_0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.196013</td>\n",
       "      <td>0.562539</td>\n",
       "      <td>0.690587</td>\n",
       "      <td>0.686505</td>\n",
       "      <td>0.02772</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.205451</td>\n",
       "      <td>0.562718</td>\n",
       "      <td>0.67687</td>\n",
       "      <td>0.67974</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>partial_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.447383</td>\n",
       "      <td>0.651597</td>\n",
       "      <td>0.813277</td>\n",
       "      <td>0.775472</td>\n",
       "      <td>0.127073</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.939871</td>\n",
       "      <td>0.543641</td>\n",
       "      <td>0.666428</td>\n",
       "      <td>0.667191</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.148476</td>\n",
       "      <td>0.582001</td>\n",
       "      <td>0.725649</td>\n",
       "      <td>0.709896</td>\n",
       "      <td>0.078026</td>\n",
       "      <td>partial_0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.077126</td>\n",
       "      <td>0.593434</td>\n",
       "      <td>0.718227</td>\n",
       "      <td>0.710998</td>\n",
       "      <td>0.025422</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.786714</td>\n",
       "      <td>0.647613</td>\n",
       "      <td>0.780468</td>\n",
       "      <td>0.760544</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>partial_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.57514</td>\n",
       "      <td>0.680526</td>\n",
       "      <td>0.810616</td>\n",
       "      <td>0.784905</td>\n",
       "      <td>0.136441</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.76798</td>\n",
       "      <td>0.542479</td>\n",
       "      <td>0.633874</td>\n",
       "      <td>0.647177</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.094691</td>\n",
       "      <td>0.597989</td>\n",
       "      <td>0.723192</td>\n",
       "      <td>0.712857</td>\n",
       "      <td>0.089826</td>\n",
       "      <td>partial_0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.153382</td>\n",
       "      <td>0.573465</td>\n",
       "      <td>0.685571</td>\n",
       "      <td>0.685425</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.071491</td>\n",
       "      <td>0.59319</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.690783</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>partial_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.532876</td>\n",
       "      <td>0.680857</td>\n",
       "      <td>0.818447</td>\n",
       "      <td>0.790807</td>\n",
       "      <td>0.128285</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.789776</td>\n",
       "      <td>0.544131</td>\n",
       "      <td>0.612735</td>\n",
       "      <td>0.636921</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.111527</td>\n",
       "      <td>0.591737</td>\n",
       "      <td>0.727543</td>\n",
       "      <td>0.715285</td>\n",
       "      <td>0.086332</td>\n",
       "      <td>partial_0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.023641</td>\n",
       "      <td>0.611731</td>\n",
       "      <td>0.716487</td>\n",
       "      <td>0.71755</td>\n",
       "      <td>0.027283</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.022522</td>\n",
       "      <td>0.612679</td>\n",
       "      <td>0.717715</td>\n",
       "      <td>0.71851</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>partial_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.584805</td>\n",
       "      <td>0.674715</td>\n",
       "      <td>0.816246</td>\n",
       "      <td>0.788131</td>\n",
       "      <td>0.130469</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.526866</td>\n",
       "      <td>0.646619</td>\n",
       "      <td>0.652687</td>\n",
       "      <td>0.00051</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.020498</td>\n",
       "      <td>0.611343</td>\n",
       "      <td>0.750064</td>\n",
       "      <td>0.734079</td>\n",
       "      <td>0.088315</td>\n",
       "      <td>partial_0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.087995</td>\n",
       "      <td>0.594405</td>\n",
       "      <td>0.723192</td>\n",
       "      <td>0.715214</td>\n",
       "      <td>0.026109</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.089292</td>\n",
       "      <td>0.592474</td>\n",
       "      <td>0.719814</td>\n",
       "      <td>0.712888</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>partial_0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.424688</td>\n",
       "      <td>0.657783</td>\n",
       "      <td>0.813789</td>\n",
       "      <td>0.777978</td>\n",
       "      <td>0.133646</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.116823</td>\n",
       "      <td>0.495462</td>\n",
       "      <td>0.627118</td>\n",
       "      <td>0.629532</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.069875</td>\n",
       "      <td>0.582237</td>\n",
       "      <td>0.729436</td>\n",
       "      <td>0.711235</td>\n",
       "      <td>0.08553</td>\n",
       "      <td>partial_0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.008519</td>\n",
       "      <td>0.60729</td>\n",
       "      <td>0.729641</td>\n",
       "      <td>0.721316</td>\n",
       "      <td>0.025037</td>\n",
       "      <td>partial_0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.70607</td>\n",
       "      <td>0.659432</td>\n",
       "      <td>0.789528</td>\n",
       "      <td>0.768928</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>partial_0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DI  f1 macro  f1 micro f1 weighted TV distance          method\n",
       "0   0.560671  0.677944  0.811537    0.784761    0.122976          origin\n",
       "1   0.973587  0.576042  0.676306    0.682216    0.001136      barycentre\n",
       "2   1.064175  0.598993  0.727645    0.715961    0.087166    partial_0.01\n",
       "3   1.113045  0.578018  0.697548    0.693674    0.026431   partial_0.001\n",
       "4   1.113832  0.579263  0.694733     0.69277    0.003503  partial_0.0001\n",
       "5   0.579547   0.69945  0.818345    0.798093    0.127461          origin\n",
       "6   0.902633  0.566764  0.678661    0.681659    0.000191      barycentre\n",
       "7   1.037146  0.615288  0.728515    0.724199    0.087271    partial_0.01\n",
       "8   1.039891  0.613875  0.699852    0.708954    0.028237   partial_0.001\n",
       "9   1.037299  0.616844  0.699442    0.709677    0.003718  partial_0.0001\n",
       "10  0.547099  0.682235  0.818038    0.791445    0.123847          origin\n",
       "11  0.877256  0.536453  0.641603    0.652519    0.000997      barycentre\n",
       "12  1.094295  0.593795  0.727338    0.716239    0.086755    partial_0.01\n",
       "13  1.074207  0.611179  0.715258    0.716937    0.027666   partial_0.001\n",
       "15  0.611039  0.678609  0.813584    0.786847    0.141578          origin\n",
       "16  1.123457  0.531822  0.639351    0.648424    0.000056      barycentre\n",
       "17  1.016452  0.612386  0.744894    0.730162    0.093664    partial_0.01\n",
       "18  1.005709  0.614068  0.716538    0.717413    0.028038   partial_0.001\n",
       "19  1.072161  0.595851  0.687055    0.695624    0.003746  partial_0.0001\n",
       "20  0.560584  0.662176  0.810718    0.779508    0.127487          origin\n",
       "21  1.243626  0.530951  0.660234    0.659932    0.000587      barycentre\n",
       "22  1.158183  0.580881  0.721861      0.7082    0.082712    partial_0.01\n",
       "23  1.196013  0.562539  0.690587    0.686505     0.02772   partial_0.001\n",
       "24  1.205451  0.562718   0.67687     0.67974    0.003689  partial_0.0001\n",
       "25  0.447383  0.651597  0.813277    0.775472    0.127073          origin\n",
       "26  0.939871  0.543641  0.666428    0.667191    0.000546      barycentre\n",
       "27  1.148476  0.582001  0.725649    0.709896    0.078026    partial_0.01\n",
       "28  1.077126  0.593434  0.718227    0.710998    0.025422   partial_0.001\n",
       "29  0.786714  0.647613  0.780468    0.760544    0.003814  partial_0.0001\n",
       "30   0.57514  0.680526  0.810616    0.784905    0.136441          origin\n",
       "31   0.76798  0.542479  0.633874    0.647177    0.000086      barycentre\n",
       "32  1.094691  0.597989  0.723192    0.712857    0.089826    partial_0.01\n",
       "33  1.153382  0.573465  0.685571    0.685425    0.026822   partial_0.001\n",
       "34  1.071491   0.59319    0.6825    0.690783    0.003662  partial_0.0001\n",
       "35  0.532876  0.680857  0.818447    0.790807    0.128285          origin\n",
       "36  0.789776  0.544131  0.612735    0.636921    0.000543      barycentre\n",
       "37  1.111527  0.591737  0.727543    0.715285    0.086332    partial_0.01\n",
       "38  1.023641  0.611731  0.716487     0.71755    0.027283   partial_0.001\n",
       "39  1.022522  0.612679  0.717715     0.71851    0.003856  partial_0.0001\n",
       "40  0.584805  0.674715  0.816246    0.788131    0.130469          origin\n",
       "41  0.986207  0.526866  0.646619    0.652687     0.00051      barycentre\n",
       "42  1.020498  0.611343  0.750064    0.734079    0.088315    partial_0.01\n",
       "43  1.087995  0.594405  0.723192    0.715214    0.026109   partial_0.001\n",
       "44  1.089292  0.592474  0.719814    0.712888    0.003668  partial_0.0001\n",
       "45  0.424688  0.657783  0.813789    0.777978    0.133646          origin\n",
       "46  1.116823  0.495462  0.627118    0.629532    0.000253      barycentre\n",
       "47  1.069875  0.582237  0.729436    0.711235     0.08553    partial_0.01\n",
       "48  1.008519   0.60729  0.729641    0.721316    0.025037   partial_0.001\n",
       "49   0.70607  0.659432  0.789528    0.768928    0.003516  partial_0.0001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DI  f1 macro  f1 micro f1 weighted TV distance  method\n",
      "0  0.471475  0.654216  0.813021    0.776355    0.130341  origin\n",
      "         DI  f1 macro  f1 micro f1 weighted TV distance      method\n",
      "0  0.645218  0.567431  0.685315     0.68513    0.000744  barycentre\n",
      "         DI  f1 macro  f1 micro f1 weighted TV distance        method\n",
      "0  0.541425  0.623109  0.803706    0.759091    0.085914  partial_0.01\n",
      "         DI  f1 macro  f1 micro f1 weighted TV distance         method\n",
      "0  0.552295  0.623134  0.803399    0.758986    0.026997  partial_0.001\n",
      "         DI  f1 macro  f1 micro f1 weighted TV distance  method\n",
      "0  0.531239  0.670878  0.814301    0.785454    0.129921  origin\n",
      "         DI  f1 macro  f1 micro f1 weighted TV distance      method\n",
      "0  1.078367  0.531828  0.646926    0.654245     0.00011  barycentre\n",
      "         DI  f1 macro  f1 micro f1 weighted TV distance        method\n",
      "0  0.550629  0.665578  0.813329    0.782802    0.083955  partial_0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[183], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(projpost\u001b[38;5;241m.\u001b[39mpostprocess(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbarycentre\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m---> 16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[43mprojpost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpartial\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# report.to_csv(path+'/data/E3_postprocess_adult_'+str(pa)+'.csv',index=None)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[136], line 69\u001b[0m, in \u001b[0;36mProjpostprocess.postprocess\u001b[1;34m(self, method, para)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munconstrained\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpartial\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 69\u001b[0m         coupling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoupling_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m         y_pred\u001b[38;5;241m=\u001b[39mpostprocess(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_test,coupling,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_list,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_range,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_list,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_range,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthresh)\n\u001b[0;32m     71\u001b[0m         tv\u001b[38;5;241m=\u001b[39massess_tv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_test,coupling,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_range,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_list,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_list)\n",
      "Cell \u001b[1;32mIn[136], line 60\u001b[0m, in \u001b[0;36mProjpostprocess.coupling_generator\u001b[1;34m(self, method, para)\u001b[0m\n\u001b[0;32m     57\u001b[0m     coupling\u001b[38;5;241m=\u001b[39mbaseline(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp0,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpartial\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# coupling = np.matrix(np.outer(self.px,self.ptx))\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     coupling\u001b[38;5;241m=\u001b[39m\u001b[43mpartial_repair\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m coupling\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:162\u001b[0m, in \u001b[0;36mpartial_repair\u001b[1;34m(C, e, px, ptx, V, theta_scale, K)\u001b[0m\n\u001b[0;32m    160\u001b[0m fun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m z: \u001b[38;5;28msum\u001b[39m(tmp\u001b[38;5;241m.\u001b[39mitem(i,j)\u001b[38;5;241m*\u001b[39mV\u001b[38;5;241m.\u001b[39mitem(i)\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mz\u001b[38;5;241m*\u001b[39mV\u001b[38;5;241m.\u001b[39mitem(i)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m I)\u001b[38;5;241m-\u001b[39mtheta\u001b[38;5;241m.\u001b[39mitem(j)\n\u001b[0;32m    161\u001b[0m dfun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m z: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28msum\u001b[39m(tmp\u001b[38;5;241m.\u001b[39mitem(i,j)\u001b[38;5;241m*\u001b[39m(V\u001b[38;5;241m.\u001b[39mitem(i))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mz\u001b[38;5;241m*\u001b[39mV\u001b[38;5;241m.\u001b[39mitem(i)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m I)\n\u001b[1;32m--> 162\u001b[0m nu \u001b[38;5;241m=\u001b[39m \u001b[43mnewton\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdfun\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstepmax\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0e-9\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m I:\n\u001b[0;32m    164\u001b[0m     gamma_dict[loop\u001b[38;5;241m*\u001b[39mL\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m][i,j]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mnu\u001b[38;5;241m*\u001b[39mV\u001b[38;5;241m.\u001b[39mitem(i))\u001b[38;5;241m*\u001b[39mtmp\u001b[38;5;241m.\u001b[39mitem(i,j)\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:34\u001b[0m, in \u001b[0;36mnewton\u001b[1;34m(fun, dfun, a, stepmax, tol)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(fun(a))\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39mtol: \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, stepmax\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 34\u001b[0m     b\u001b[38;5;241m=\u001b[39ma\u001b[38;5;241m-\u001b[39m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mdfun(a)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(fun(b))\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39mtol:\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m b\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:160\u001b[0m, in \u001b[0;36mpartial_repair.<locals>.<lambda>\u001b[1;34m(z)\u001b[0m\n\u001b[0;32m    158\u001b[0m gamma_dict[loop\u001b[38;5;241m*\u001b[39mL\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mcopy(tmp)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m Jplus:\n\u001b[1;32m--> 160\u001b[0m     fun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m z: \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mI\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m-\u001b[39mtheta\u001b[38;5;241m.\u001b[39mitem(j)\n\u001b[0;32m    161\u001b[0m     dfun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m z: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28msum\u001b[39m(tmp\u001b[38;5;241m.\u001b[39mitem(i,j)\u001b[38;5;241m*\u001b[39m(V\u001b[38;5;241m.\u001b[39mitem(i))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mz\u001b[38;5;241m*\u001b[39mV\u001b[38;5;241m.\u001b[39mitem(i)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m I)\n\u001b[0;32m    162\u001b[0m     nu \u001b[38;5;241m=\u001b[39m newton(fun,dfun,\u001b[38;5;241m0\u001b[39m,stepmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m,tol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0e-9\u001b[39m) \n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:160\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    158\u001b[0m gamma_dict[loop\u001b[38;5;241m*\u001b[39mL\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mcopy(tmp)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m Jplus:\n\u001b[1;32m--> 160\u001b[0m     fun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m z: \u001b[38;5;28msum\u001b[39m(\u001b[43mtmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m I)\u001b[38;5;241m-\u001b[39mtheta\u001b[38;5;241m.\u001b[39mitem(j)\n\u001b[0;32m    161\u001b[0m     dfun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m z: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28msum\u001b[39m(tmp\u001b[38;5;241m.\u001b[39mitem(i,j)\u001b[38;5;241m*\u001b[39m(V\u001b[38;5;241m.\u001b[39mitem(i))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mz\u001b[38;5;241m*\u001b[39mV\u001b[38;5;241m.\u001b[39mitem(i)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m I)\n\u001b[0;32m    162\u001b[0m     nu \u001b[38;5;241m=\u001b[39m newton(fun,dfun,\u001b[38;5;241m0\u001b[39m,stepmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m,tol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0e-9\u001b[39m) \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "thresh=0.3\n",
    "x_list = ['age','education-num']\n",
    "methods=['origin','barycentre','partial'] # Place ROC in the end\n",
    "report=pd.DataFrame(columns=['DI','f1 macro','f1 micro','f1 weighted','TV distance','method'])\n",
    "for ignore in range(5):\n",
    "    # train val test 4:2:4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    # X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "    clf=RandomForestClassifier(max_depth=5).fit(X_train[:,0:var_dim],y_train)\n",
    "    projpost = Projpostprocess(X_test,y_test,x_list,var_list,clf,K,e,thresh,favorable_label)\n",
    "    \n",
    "    print(projpost.postprocess('origin'))\n",
    "    print(projpost.postprocess('barycentre'))\n",
    "    for t in range(2,4):\n",
    "        print(projpost.postprocess('partial',para=10**(-t)))\n",
    "\n",
    "# report.to_csv(path+'/data/E3_postprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optional threshold =  [0.1        0.18888889 0.27777778 0.36666667 0.45555556 0.54444444\n",
      " 0.63333333 0.72222222 0.81111111 0.9       ]\n",
      "Disparate Impact =  [0.66900341 0.65569828 0.65472977 0.65570698 0.6399922  0.6399922\n",
      " 0.64740833 0.67114259 0.6775284  0.67792388]\n",
      "f1 scores =  [0.66179706 0.66264053 0.66297696 0.66308919 0.66321851 0.66321851\n",
      " 0.65267297 0.64056642 0.63902052 0.63649243]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valpost = Projpostprocess(X_val,y_val,x_list,var_list,clf,K,e,'auto')\n",
    "valpost.thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m projpost \u001b[38;5;241m=\u001b[39m Projpostprocess(X_test,y_test,x_list,var_list,clf,K,e,thresh,favorable_label)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m methods[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# report = pd.concat([report,projpost.postprocess(method,para=1e-2)], ignore_index=True)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     report \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([report,\u001b[43mprojpost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpara\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m ROCpost \u001b[38;5;241m=\u001b[39m ROCpostprocess(X_val,y_val,var_list,clf,favorable_label) \u001b[38;5;66;03m# use validation set to train a ROC model\u001b[39;00m\n\u001b[0;32m     15\u001b[0m report \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([report,ROCpost\u001b[38;5;241m.\u001b[39mpostprocess(X_test,y_test,tv_origin\u001b[38;5;241m=\u001b[39mprojpost\u001b[38;5;241m.\u001b[39mtv_origin)], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[77], line 69\u001b[0m, in \u001b[0;36mProjpostprocess.postprocess\u001b[1;34m(self, method, para)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munconstrained\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpartial\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     68\u001b[0m     coupling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoupling_generator(method,para)\n\u001b[1;32m---> 69\u001b[0m     y_pred\u001b[38;5;241m=\u001b[39m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcoupling\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_list\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_range\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_range\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     tv\u001b[38;5;241m=\u001b[39massess_tv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_test,coupling,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_range,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_list,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_list)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (para \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpartial\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:287\u001b[0m, in \u001b[0;36mpostprocess\u001b[1;34m(df, coupling_matrix, x_list, x_range, var_list, var_range, clf, thresh)\u001b[0m\n\u001b[0;32m    285\u001b[0m sub\u001b[38;5;241m=\u001b[39msub[var_list]\n\u001b[0;32m    286\u001b[0m totalweight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28msum\u001b[39m(coupling[loc,:])\n\u001b[1;32m--> 287\u001b[0m pred\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28msum\u001b[39m(coupling[loc,:]\u001b[38;5;241m/\u001b[39mtotalweight\u001b[38;5;241m*\u001b[39m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvar_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m>\u001b[39mthresh)\n\u001b[0;32m    288\u001b[0m pred_repaired\u001b[38;5;241m.\u001b[39mupdate({var_range[i]:pred})\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# prob=clf.predict_log_proba(np.array(sub).reshape(-1,var_dim)) #log is better\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# prob0=sum(prob[:,0]*coupling[loc,:]/totalweight)\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;66;03m# prob1=sum(prob[:,1]*coupling[loc,:]/totalweight)\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;66;03m# pred_repaired.update({var_range[i]:int(prob0<prob1)})\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    800\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:873\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    868\u001b[0m all_proba \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    869\u001b[0m     np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], j), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[0;32m    871\u001b[0m ]\n\u001b[0;32m    872\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m--> 873\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[0;32m    879\u001b[0m     proba \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:650\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[0;32m    644\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;124;03m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \n\u001b[0;32m    647\u001b[0m \u001b[38;5;124;03m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;124;03m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 650\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[0;32m    652\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:923\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.predict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    921\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    922\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[1;32m--> 923\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    926\u001b[0m     proba \u001b[38;5;241m=\u001b[39m proba[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "methods=['origin','unconstrained','barycentre','partial','ROC'] # Place ROC in the end\n",
    "report=pd.DataFrame(columns=['DI','f1 macro','f1 micro','f1 weighted','TV distance','method'])\n",
    "for ignore in range(10):\n",
    "    # train val test 4:2:4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "    clf=RandomForestClassifier(max_depth=5).fit(X_train[:,0:var_dim],y_train)\n",
    "    projpost = Projpostprocess(X_test,y_test,x_list,var_list,clf,K,e,thresh,favorable_label)\n",
    "    for method in methods[:-1]:\n",
    "        # report = pd.concat([report,projpost.postprocess(method,para=1e-2)], ignore_index=True)\n",
    "        report = pd.concat([report,projpost.postprocess(method,para=1e-3)], ignore_index=True)\n",
    "\n",
    "    ROCpost = ROCpostprocess(X_val,y_val,var_list,clf,favorable_label) # use validation set to train a ROC model\n",
    "    report = pd.concat([report,ROCpost.postprocess(X_test,y_test,tv_origin=projpost.tv_origin)], ignore_index=True)\n",
    "\n",
    "report.to_csv(path+'/data/report_postprocess_adult_'+str(pa)+'.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 0.04744857663969924,\n",
       " 'education-num': 0.056762405582129784,\n",
       " 'capital-gain': 0.021127950774052707,\n",
       " 'capital-loss': 0.011363681253224836,\n",
       " 'hours-per-week': 0.04445283428803036}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa = 'race'\n",
    "label_map = {1.0: '>50K', 0.0: '<=50K'}\n",
    "privileged_groups = [{pa: 1}]\n",
    "unprivileged_groups = [{pa: 0}]\n",
    "if pa == 'sex':\n",
    "    thresh=0.05\n",
    "    protected_attribute_maps = [{1.0: 'Male', 0.0: 'Female'}]\n",
    "    cd = AdultDataset(protected_attribute_names=[pa],privileged_classes=[['Male'],[1.0]], \n",
    "        metadata={'label_map': label_map,'protected_attribute_maps': protected_attribute_maps},\n",
    "        # categorical_features=['workclass', 'marital-status', 'occupation', 'relationship', 'native-country']\n",
    "        features_to_drop=['race','fnlwgt','education','relationship',\n",
    "                          'native-country','workclass','marital-status','occupation'])\n",
    "elif pa == 'race':\n",
    "    thresh=0.1\n",
    "    protected_attribute_maps = [{1.0: 'White', 0.0:'Non-white'}]\n",
    "    cd = AdultDataset(protected_attribute_names=[pa],privileged_classes=[['White'],[1.0]],\n",
    "        metadata={'label_map': label_map,'protected_attribute_maps': protected_attribute_maps}, #\n",
    "        features_to_drop=['sex','fnlwgt','education','relationship',\n",
    "                          'native-country','workclass','marital-status','occupation'])\n",
    "    #,'workclass','marital-status','occupation','relationship',\n",
    "\n",
    "# train,test = cd.split([0.6], shuffle=True) #len(test.instance_names) = 2057\n",
    "var_list = cd.feature_names.copy()\n",
    "var_list.remove(pa)\n",
    "var_dim=len(var_list)\n",
    "\n",
    "K=200\n",
    "e=0.01\n",
    "bins_capitalgain=[100,3500,7500,10000]\n",
    "bins_capitalloss=[100,1600,1900,2200]\n",
    "\n",
    "messydata=cd.convert_to_dataframe()[0]\n",
    "messydata=messydata.rename(columns={pa:'S',cd.label_names[0]:'Y'})\n",
    "messydata=messydata[(messydata['S']==1)|(messydata['S']==0)]\n",
    "for col in var_list+['S','Y']:\n",
    "    messydata[col]=messydata[col].astype('int64')\n",
    "messydata['W']=cd.instance_weights\n",
    "# project 0-100 to {0,1,...,5}\n",
    "messydata['age']=np.floor((messydata['age'].to_numpy()-17)/15)\n",
    "messydata['hours-per-week']=np.floor(messydata['hours-per-week'].to_numpy()/20)\n",
    "messydata=categerise(messydata,'capital-gain',bins_capitalgain)\n",
    "messydata=categerise(messydata,'capital-loss',bins_capitalloss)\n",
    "\n",
    "X=messydata[var_list+['S','W']].to_numpy() # [X,S,W]\n",
    "y=messydata['Y'].to_numpy() #[Y]\n",
    "tv_dist=dict()\n",
    "for x_name in var_list:\n",
    "    x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "    dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "    tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "x_list=[]\n",
    "for key,val in tv_dist.items():\n",
    "    if val>0.045:\n",
    "        x_list+=[key]        \n",
    "tv_dist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
